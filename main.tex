\documentclass[A4,12pt,twoside]{book}
\usepackage{amd}

% %--------------------------------------------------------------------------
% %         General Setting
% %--------------------------------------------------------------------------

\graphicspath{{Images/}{../Images/}} %Path of figures
\setkeys{Gin}{width=0.85\textwidth} %Size of figures
\setlength{\cftbeforechapskip}{3pt} %space between items in toc
\setlength{\parindent}{0.5cm} % Idk
\input{theorems.tex} % Theorems styles and colors
\usepackage[english]{babel} %Language

\setlist[itemize]{itemsep=5pt} % Adjust the length as needed
\setlist[enumerate]{itemsep=5pt} % Adjust the length as needed


\usepackage[ruled,vlined]{algorithm2e}
% \usepackage{lmodern} %  Latin Modern font
% \usepackage{newtxtext,newtxmath}




% %--------------------------------------------------------------------------
% %         General Informations
% %--------------------------------------------------------------------------
\newcommand{\BigTitle}{
    A MATHEMATICAL TEMPLATE
    }

\newcommand{\LittleTitle}{
    For Mathematical Peoples
    }

    
\begin{document}








\section{Backround}
For a function $f: \mathbb{R}^m \to \mathbb{R}^n$ the Jacobi-Matrix at point $x_0$ is given by
$$
\frac{\partial }{\partial x} f(x_0) := \begin{pmatrix}
    \frac{\partial }{\partial x_1} f_1 (x_0) & \cdots & \frac{\partial }{\partial x_m} f_1 (x_0)  \\
    \vdots &\ddots &\vdots \\
    \frac{\partial }{\partial x_1} f_n (x_0) & \cdots & \frac{\partial }{\partial x_m} f_n (x_0) 
\end{pmatrix} \in \mathbb{R}^{n \times m}
$$
and the derivative of $f$ at $x_0$ is then the mapping
$$
f^\prime (x_0) : \mathbb{R}^m \to \mathbb{R}^n, x \mapsto \frac{\partial }{\partial x} f(x_0) \cdot x.
$$


\defn{}{
    We call the mapping \[
    \phi: (0,\infty) \times \mathbb{R}/(2\pi \mathbb{R}) \to \mathbb{R}^2 , \quad (r,\theta) \mapsto \phi (r,\theta) := (r \cos (\theta), t \sin (\theta))
    \]
    polar coordinates.
}
It holds at point $(r_0,\theta_0)$ that
\[
| det ( \frac{\partial }{\partial x} \phi (r_0,\theta_0) ) | =r_0.???
\]
\defn{}{
    For a set $M$ and an equivalenz relation $\sim$ we call
    \[
    [m] := \{n \in M \mid n \sim m \} \subset M
    \]
    an equivalenz class. We call $M/\sim$ the set of equivalenz classes from $M$ wrt. $\sim$. It is also called quotient set.
}
Note that 
\[
M = \bigcup_{ [a] \in M/\sim} [a]
\]
and that the mapping
\[ 
M \to M/\sim, \quad m \mapsto [m]
\]
is canonical, meaning that every element in $M$ is mapped to a unique equivalenz class.
\rmkb{
    One can show that the mapping\[
    \mathbb{R} \to \mathbb{R} / (2 \pi \mathbb{Z})
    \]
    is a group homomorphism and its kernel is $2 \pi \mathbb{Z}$. Further, one can show that $\mathbb{R}/(2 \pi \mathbb{Z})$ is isomorphic to $S^1 := \{ x \in \mathbb{R}^2 \mid ||x||_2 =1 \}$. 
}








\chapter{First order PDEs}

\defn{}{
We call $F: ???$
$$
F(D^k u(x),...,Du(x),u(x),x)=0, \quad k \in \mathbb{N}^n_0
$$
PDE of order $|k|:= \sum_{i=1}^n k_i$ and $D^ku = (\partial^{k_1} \cdots \partial^{k_n})u$ 
}

\defn{}{
Classical Solution???
}

\rmkb{
Some Notation:\\
We write $\dot{u} := \frac{\partial}{\partial t} u$ and if $u: \Omega\times \mathbb{R}_+ \to \mathbb{R}$, where $\Omega \subset \mathbb{R}^d$ we write $(1,b) \nabla u = \dot{u}+b \nabla_xu$.\\
We also often write $b \nabla u:= \langle b,\nabla u \rangle$.
}

\section{Homogeneous Transport}
Consider the PDE
$$
\dot{u} + b \nabla u =0
$$
which is called linear transport equation. We first assume that $u$ is differentiable and satisfies the equation above, i.e. is a classical solution. For fixed initial values $(x_0,t_0) \in \mathbb{R}^n \times \mathbb{R}$ the function
$$
z(s) := u(x_0 + sb,t_0+s)
$$
is differentiable (because $u$ is). One can now show that its derivative vanishes
$$
z^\prime (s) = b \nabla_x u(x_0 + sb,t_0+s) +\underbrace{ \frac{\partial}{\partial t} u(x_0 + sb,t_0+s)}_{=\dot{u}(x_0 + sb,t_0+s) } \cdot 1 \stackrel{PDE}{=}0.
$$
Thus $u$ is constant on the linear function $x(s) := x_0 + sb$. Therefore, $u$ is constant along all lines with direction $(b,1)$. Further, $u$ is completely determined by all values on these parallel lines??? (WHy not $z(s,t) = u(x_0 + sb,t_0 +t)$???)

\defn{}{
We call for such a transport equation the following
$$
\dot{u}+f(u)=0, \quad u(x,0)=u_0(x)
$$
Cauchy problem. Here $\dot{u}+f(u)=0$ is called conservation law and $f$ is the flux (stems from inflow and outflow) function.
}
For initial values $(x_0,t_0)$ we can now solve the PDE, this is because the solution $u$ is constant on $x(t)$ and thus
$$
u(x(t),t)= u(x_0 +tb,t) \stackrel{const}{=} u(x_0,0) = g(x_0) = g(x-tb)
$$
where we used that $x=x_0+tb$ is equivalent to $x_0 =x-tb$. This if $g$ is differentiable on $\mathbb{R}^n$ then the above solves the PDE. If $g$ is not differentiable there does not exist a solution in a classical sense!
\section{Inhomogenous linear transport Equation}
We now consider 
$$
\dot{u} + b \nabla u =f
$$
with initial values $(x_0,0) \in \mathbb{R}^n \times \mathbb{R}$ and again we define $z(s) := u(x_0 + sb,s)$ yielding
$$
z^\prime (s) = b \nabla u(x_0+sb,s) + \dot{u}(x_0+sb,s) \stackrel{PDE}{=} f(x_0+sb,s)
$$
Because we now $z(0) = u(x_0,0)=g(x_0)$ we actually have to solve the IVP of an ODE
$$
z^\prime (s)= f(x_0+sb,s), \quad z(0) =g(x_0).
$$
We can integrate and determine $z(s)$ completely??? Only if the ODE is solvable???\\
The solution to the ODE tells us the value $z(s) = u(x_0 +sb,s)$ on the line $x(t) := s_0 + sb$. Using this, we can now write the solution down explicitly
\begin{align*}
    u(x(t),t) = z(t)  &= z(0) + \int_0^t z^\prime (s) ds \\
    &=g(x_0)+ \int_0^t f(x_0+sb,s) ds\\
    &= g(x-tb) + \int_0^t\underbrace{ f(x-tb-sb,s)}_{=f(x+(s-t)b,s)} ds
\end{align*}
which looks like the variation of constant approach from ODEs. In the following chapters, we want to generalize this approach for solving PDEs using ODEs.
\section{Scalar Conservation Law}
A scalar conservation law is a homogeneous non-linear transport equation with one space dimension
$$
\dot{u}(x,t) + \frac{\partial }{\partial x} f(u(x,t)) \stackrel{(*)}{=} \dot{u}(x,t) + f^\prime (u(x,t)) \frac{\partial }{\partial x} u(x,t) =0,
$$
where (*) only works if $f$ is differentiable. THen we have on every compact interval $[a,b]$ (why???) that
\begin{align*}
    \frac{d}{dt} \int_a^b u(x,t) dx = \int_a^b \dot{u}(x,t) dx \stackrel{PDE}{=} - \int_a^b \frac{\partial}{\partial x} f(u(x,t)) dx = f(u(a,t))- f(u(b,t)).
\end{align*}
The change of a quantity in an interval $[a,b]$ thus soly depends on the in- and outflow of that quantity at the boundary with speed $f$ at time $t$.???


\section{Reminder}

\defn{}{
A set $X$ and a system of sets $\mathcal{O} \subseteq \mathcal{P}(X) = \{ A \mid A \subseteq X \}$ with
\begin{itemize}
    \item $\emptyset, X \in \mathcal{O}$
    \item $\mathcal{O}^\prime \subset \mathcal{O}$ $\Rightarrow$ $\bigcup_{U \in \mathcal{O}^\prime} U \in \mathcal{O}$
    \item $U,V \in \mathcal{O}$ $\Rightarrow$ $U \cap V \in \mathcal{O}$
\end{itemize}
is called topology on $X$ and $(X, \mathcal{O})$ is called topological space.
}

\defn{}{
We call a topological space $(X, \mathcal{O})$ second countable if there exists a family $\mathcal{B} \subset \mathcal{O}$, that is a basis of $\mathcal{O}$, i.e.
$$
\forall U \in \mathcal{O} \forall x \in U \exists B \in \mathcal{B}: \quad x \in B \subset U.
$$
}
A topological space $(X,\mathcal{O})$ is called Hausdroff, if
$$
\forall x,y \in X \text{ with } x \neq y \exists U_x,U_y \text{ open areas around $x$ and $y$ repectively:} \quad U_x \cap U_y = \emptyset.
$$

\defn{}{
A $C^r-$Atlas of dimension $m$ on a Set $X$ is a family of Maps $(U_i, \varphi_i)_{i \in \mathbb{N}}$ with $U_i \subset X$ and $\bigcup_{i \in \mathbb{N}} U_i =X$ and homöormorphismen $\varphi:i : U_i \to \Omega \subset \mathbb{R}^n$ open such that for all $i,j \in \mathbb{N}$ with $U_i \cap U_j \neq \emptyset$ we have that
$$
\varphi_i \circ \varphi_j^{-1}: \varphi_i (U_i \cap U_j) \to \varphi_j(U_i \cap U_j) 
$$
is in $C^{1,r} := \{ u \in C^r \mid D^\alpha u \in C^r , |\alpha| \leq r \}$.
}

\defn{}{
A $C^{r,1}$ Manifold $X$ of dimension $m$ is a Hausdorff, second countable topological space with a at most $C^{1,r}$-Atlas $\{(U_i, \varphi_i)_{i \in \mathbb{N}} \}$ where $\varphi_i: U \to \Omega \subset \mathbb{R}^m$ are Homöomorphism are and 
}

\defn{}{
A topological space $(X, \mathcal{O})$ is called connected if the only subsets of $X$, that are open and closed are $\emptyset$ and $X$ itself. Local Connected means that for every $x \in X$ every ball around $x$ contains a connected area of $X$.
}

\thm{}{
1. Non empty subsets $X$ of $\mathbb{R}$ are connected $\iff$ $X$ is a bounded or unbounded intervall.\\
2. $\mathbb{R}$ is connected and also locally connected.
}
\pf{
1. Let $X \subset \mathbb{R}$ be connected and not empty. Assume that there exists an intervall in $X$, where there is an element, that is not in $X$, i.e.
$$
\exists a,b \in X \text{ with } a<b: \quad x\in (a,b) \text{ with } x \notin X.
$$
Then we have that
$$
U:= (-\infty,x) \cap X= (-\infty,x] \cap X, \quad \text{ and }\quad V:= (x, \infty) \cap X = [x, \infty) \cap X.
$$
Both equalities above hold, because we assumed that $x \notin X$. Because $U$ and $V$ are open and closed at the same time we get that we can make a disjoint decomposition of open sets: $X = U \cup V$, which leads to a contradiction, because $X$ is no longer connected! \\
This yields that the above constructed $x \notin X$ cannot exist. Thus, all elements in $(a,b) \subset X$ have to be in $X$.\\
2. Global:\\
Choose $\inf A=- \infty$ and $\sup A = \infty$. Then 
$$
 \forall x \in (\inf X,\sup X) \exists a,b \in X:\quad x \in (a,b)
$$
i.e. its always contained in an interval. This yields
$$
(\inf X, \sup X) \subset X \subset [\inf X,\sup X]
$$
which leads to the conclusion that $X$ has to be either
$(\inf X, \sup X) ,[\inf X, \sup X),(\inf X, \sup X]$ or $[\inf X,\sup X]$.\\
2. Local:\\
We can use that a interval $I$ is connected $\iff$ $I = A \cup B$ of non empty subsets where at least one is not open. \\
Let $a \in A , b \in B$ with $a<b$ and define $c := \inf B \cap [a,b]$. If $A$ is open then $c \in B$ and thus $[a,c) \subset A$. Because $c \notin A$ we get that $B$ is not open and thus $I$ is connected.
}

\defn{}{
A mapping $f: V \to U$ between two open vector spaces is called Diffemorphism if
\begin{itemize}
    \item Bijective
    \item everywhere continuous differentiable
    \item the inverse $f^{-1}$ everywhere continuous differentiable.
\end{itemize}
}

\defn{}{
A Homöorphism is a bijective mapping $\varphi$ that is continuous and its inverse $\varphi^{-1}$ is continuous.
}

\defn{}{
Let $X$ be a topological space, then we call a Homöormorphism $\phi: U \to V$, where $U \subset X$ open and $V \subset \mathbb{R}^n$ open, a Map. We call $U$ definition space and $n$ the dimension of the Map.
}
Intuition: A Map assigns to every point $x \in U$ a unique coordinate $\phi(x) := (x_1,...,x_n) \in V \subset \mathbb{R}^n$ and for every coordinate we can reconstruct a unique point.
\defn{}{
On a topological space $(X, \mathcal{O})$ we call two maps $\phi_1 : U_1 \to V$ and $\phi_2: U_2 \to V$, with $U_1,U_2 \subset X$ open and $V \subset \mathbb{R}^n$ open compatible, if 
$$
(\phi_1 \circ \phi_2^{-1} )\big|_{U_1 \cap U_2} \text{ is a diffeomorphism, i.e. bijective, continuous and its inverse is continuous.}
$$
}
The reasoning behind the diffeomorphism (???) is that we dont want information to be lost.
\rmkb{
Note that $(\phi_1 \circ \phi_2^{-1})^{-1} = \phi_2 \circ \phi_1^{-1}$, i.e. no matter the order $\phi_1 \circ \phi_2^{-1}$ and $\phi_2 \circ \phi_1^{-1}$ we get a continuous bijective mapping from on of the definition spaces $U_1$ to the other $U_2$, because
$$
\phi_1 \circ \phi_2^{-1}: U_1 \to U_2 \text{ and } \phi_2 \circ \phi_1^{-1}: U_2 \to U_1.
$$
}
\defn{}{
For a topological space $(X, \mathcal{O})$ we call a family of maps $\phi_i : U_i \to \mathbb{R}^n$ such that $X \subset \bigcup_{i=1}^n U_i$ is a cover of $X$ an Atlas, if the maps are pairwise compatible.
}

\rmkb{
We only want to consider Hausdorff spaces, because ???.\\
The topological space 
$$
X := \bigcup_{i \in \mathbb{N}} O_i \cup (\{0^*\} \cup 0) \cup (\{0^*\} \cup ( O \setminus \{0\}))
$$
where $\bigcup_{i \in \mathbb{N}} O_i $ is an open cover of $\mathbb{R}$ and $0^*$ is some element, that is not in $\mathbb{R}$, and $O \subset \mathbb{R}$ is an open area around $0$. The two maps
$$
\phi_1: \mathbb{R}\setminus \{0^*\} \to \mathbb{R}, x \mapsto 1 \text{ and } \phi_2: ( \mathbb{R} \setminus \{0^*\} ) \cup \{0^*\} \to \mathbb{R}, x \mapsto \textbf{1}_{\mathbb{R} \setminus \{0\}} + 0 \textbf{1}_{\{0^*\}}
$$
are an Atlas of $X$, as their definition space is a cover of $X$. \\
This is space, that we do not want to consider, because its not a Hausdorff space, because for arbitrary $V \subset \mathbb{R}$ open area of $0$ and $W \subset X$ open area of $0^*$ there exists $O \subset \mathbb{R}$ open area of $0$ with $0^* \in O$.
}
\defn{Manifold}{
We call a topological Hausdorff space with an Atlas differentiable Manifold. 
}
The Idea here is that using an open cover of the topological space $X$, for each open set, we map using a map to an open subset of euklidean space, i.e. this what we call locally euklidean. 

\section{Non-characteristic Hypersurfaces}
We now consider $F: W \to \mathbb{R}$ with $W \subset \mathbb{R}^n \times \mathbb{R} \times \Omega$ open as the first order PDE
$$
F(\nabla u(x),u(x),x)=0
$$
where the solution $u:\Omega \to  \mathbb{R}$ is defined on the open domain $\Omega \subseteq \mathbb{R}^n$ and has the boundary condition
$$
u(y) = g(y), \quad \forall y \in \Sigma := \{ x \in \Omega \mid \varphi (x) = \varphi (x_0)  \}
$$
on the level set of a function $\varphi$.\\
In this section we will show that we can reformulate the boundary condition of the Cauchy problem as
$$
u(y) = g(y), \quad \forall y \in \Omega \cap H, \text{ where } H:= \{ x \in \mathbb{R}^n \mid xe_n =x_0 e_n =0 \}
$$
is the unique hyperplane through $x_0 \in \Omega$ that is orthogonal to $e_n =(0,....,0,1)$.\\
If $\nabla \varphi (x_0)\neq 0$ we can assume w.l.o.g that $\frac{\partial}{\partial x_n} \varphi (x_0) \neq 0$ which leads wit the inverse function theorem to the conclusion that
$$
x \mapsto \Phi(x) := (x_1,...,x_{n-1},\varphi(x))
$$
is continuous differentiable and for every $x$ in an open neighborhood of $x_0$ it holds that $x = \Phi^{-1} (x).$ Then it holds that 
$$
\varphi (x) = \varphi (x_0) \quad \iff \quad y e_n =  (\Phi (x))_n =\varphi (x).
$$
We call this straightening of the boundary at $x_0$. Then for a function $v: \Omega^\prime \to \mathbb{R}$ and $u:= v \circ \Phi$ we get that 
$$
\nabla u(x) = \nabla v (\Phi (x)) = \nabla v (y) \Phi^\prime (\Phi^{-1}(y)),
$$
where $\Phi^\prime$ is the Jacobi Matrix. Thus, we get the relation that $u$ is a solution of $F(\nabla u(x), u(x) ,x)=0$ $\iff$ $v$ is a solution of 
$$
G(\nabla v(y),y(y),y) := F(\nabla v(y) \Phi^\prime (\Phi^{-1}(y)),v(y) , \Phi^{-1}(y))=0
$$
Next, we ask ourselves the question what information we can gather about $u$ using the Hyperplane $H$? Due to the fact that the Hyperplane is orthogonal to $e_n$, we can compute the partial derivatives of $u$ on the hyperplane in $n-1$ directions, i.e. for $x_0 \in H$:
$$
\frac{\partial}{\partial x_i} u(x_0) = \lim_{h \to 0} \frac{u(x_0+he_i)-u(x_0)}{h} \stackrel{Boundray}{=} \lim_{h \to 0} \frac{g(x_0+he_i)-g(x_0)}{h} = \frac{\partial }{\partial x_i} g(x_0), i=1,...,n-1.
$$
This does not work for $\frac{\partial}{\partial x_n} g(x_0)$, because $g$ is only defined on $H \cap \Omega$ which is orthogonal to $e_n$. 
\rmkb{
For future purposes we define
$$
p_{0,i} := \frac{\partial}{\partial x_i} u(x_0), \quad p_i := \frac{\partial}{\partial x_i} u(x), \quad p_0:= (p_{0,1},...,p_{0,n}), \quad p:=(p_1,...,p_n)
$$
and 
$$
z = u(x), \quad z_0:= u(x_0).
$$
We then only write
$$
F(\nabla u(x_0) , u(x_0) ,x_0)= F(p_0, g(x_0) ,x_0)=0.
$$
}
Whether or not the PDE has a solution hence depends on $F$ and the initial condition $g$. Next, follows a simple criterion for the existence of a solution.
\defn{}{
Consider the PDE $F(p,z,x)=0$ with $2n+1$ variables and suppose there exists a solution $(p_0,z_0,x_0)$. We call the hyperplane $H := \{ x \mid x_n =x_{0,n} \}$ non-characteristic at $x_0 := (x_{0,1},...,x_{0,n})$ if
$$
\frac{\partial}{\partial p_n} F(p_0,z_0,x_0)\neq 0.
$$
}
\exm{}{
Consider 
$$
\frac{\partial u}{\partial x_1} =0, \quad u(x_1,0)=g(x_1)
$$
i.e. the PDE is for $n=2$ given by $F(p_1,p_2,z,x_1,x_2)=p_1=0$. We then see that
$$
\frac{\partial}{\partial p_2} F(p,z,x)= \frac{\partial}{\partial p_2} p_1 =0
$$
which implies that the non-characteristic property does not hold. This now leads to two observations
\begin{itemize}
    \item The PDE and the initial condition are only compatible if $g$ is constant, i.e. we need 
    $$
    \frac{\partial}{\partial x_1} g(x)=0, \quad x \in H \cap \Omega.
    $$
    to hold
    \item ???
\end{itemize}
}
 
\thm{}{
Let $F: W \to \mathbb{R}$, $g : H \to \mathbb{R}$ be continuous differentiable and $x_0 \in \Omega \cap H$, $z_0 := g(x_0)$ and
$$
\forall i=1,..,n-1: \quad p_{0,i} := \frac{\partial}{\partial x_i} g(x_0).
$$
If there exists a $p_{0,n}$ with $F(p_0,z_0,x_0)=0$ and $H$ is non-characteristic at $x_0$, then for $\Omega_{x_0} \subset \Omega$ open neighborhood of $x_0$ we have that 
$$
\exists x \in \Omega_{x_0} \cap H: \quad F(q(x),g(x),x)=0, \quad q_i (x) = \frac{\partial}{\partial x_i} g(x), i=1,...,n-1, \quad q(x_0)= p_0.
$$
}
\pf{
We define the function $l: (x,q_n) \mapsto F(q_1 (x),...,q_{n-1}(x),q_n,g(x),x)$, then by assumption of the PDE we have that
$$
l(x_0,p_{0,n})=0 \quad \text{ and } \quad \frac{\partial}{\partial x_n} l(x_0,p_{0,n}) \neq 0
$$
although the second condition stems from the fact that we assumed that $H$ is not characteristic at $x_0$.  The non negativity then yields that the inverse exists wrt. the partial derivative and we can apply the implicit theorem, i.e. there exist $\Omega_{x_0} \subset \Omega \cap H$, $W \subset \mathbb{R}$, $O \subset (\Omega \cap H)\times \mathbb{R}  $ open neighborhoods around $x_0/l(x_0,p_{0,n}) / (x_0,p_{0,n})$, then there exists a $q_n: V \times W \to Y$ such that
$$
\forall z \in W: \quad l^{-1}( \{ z\}) \cap O = Graph(q_n(\cdot,z)).
$$
???
}

\section{Method of Characteristics}
We now want to find a more general approach for the chartacteristics. Up to now we have done it in every example by hand. In general, we want to solve the PDE on some curve along the domain. These curvers will be later ODEs. Let $x(s)$ be some curve on the domain and define $z(s) := u(x(s))$ as the solution along that curve. We also need to consider $p(s) := \nabla u(x(s))$, the gradient along this curve, as this appears in the PDE $F$. The big question is now, how we should choose this curve $s \mapsto x(s)$? We begin by noticing that
$$
p_i^\prime (s) = \frac{d}{ds} \frac{\partial u(x(s))}{\partial x_i} = \sum_{j=1}^n \frac{\partial^2 u(x(s))}{\partial x_j \partial x_i} x_j^\prime (s).
$$
Using this we now want to reformulate the total derivative of $F(\nabla u(x),u(x),x)$:
\begin{align*}
    0 &= \frac{d}{ds} F(\nabla u(x), u(x) ,x) \\
    &= \sum_{j=1}^n \frac{\partial}{\partial p_j} F(p,u(x),x) \frac{\partial}{\partial x_i} p_j + \frac{\partial}{\partial u} F(p,u(x),x) \frac{\partial}{\partial x_i} u(x) + \frac{\partial}{\partial x_i} F(p,u(x),x).
\end{align*}
Due to commutivity $\partial_i \partial_j u= \partial_j \partial_i u$ and the above equality with zero we get that the above is equivalent to
$$
\sum_{j=1}^n \frac{\partial}{\partial p_j} F(p,u(x),x) \frac{\partial}{\partial x_j} p_i = - \frac{\partial}{\partial u} F(p,u(x),x) \frac{\partial}{\partial x_i} u(x) - \frac{\partial}{\partial x_i} F(p,u(x),x).
$$
Next, we want to eliminate the explicit dependence of $u$. As the curve $x$ was chosen up to now as arbitrary, if one compares with the equation with $p_i^\prime$, we can simplify, if we choose
$$
x_j^\prime (s) := \frac{\partial F(p,u(x),x)}{\partial p_j}
$$
i.e. yielding
$$
p_i^\prime (s)= \sum_{j=1}^n \underbrace{\frac{\partial}{\partial p_j} F(p,u(x),x)}_{=x_j^\prime(s)} \frac{\partial}{\partial x_j} p_i = - \frac{\partial}{\partial u} F(p,u(x),x) \frac{\partial}{\partial x_i} u(x) - \frac{\partial}{\partial x_i} F(p,u(x),x).
$$


\chapter{General Concepts}



\section{Divergence Theorem}
Now follows a generalization of fundamental theorem of calculus, i.e. partial integration to higher dimensions. In order for this to be feasible, we assume that $\Omega \subseteq \mathbb{R}^n$ is some compact space which then implies that $\partial \Omega \subseteq \mathbb{R}^{n-1}$. We can show that its a submanifold, which we now define.  
\defn{}{
For $U \subset \mathbb{R}^k$ and $f: U \to \mathbb{R}^{n-k}$ the Graph of $f$ is defined as
$$
graph(f) := \{ (x,y) \in U \times \mathbb{R}^{n-k} \mid y= f(x) \} \subset \mathbb{R}^n.
$$
}
We neglect the order of the components in $\mathbb{R}^n$???
\defn{}{
A subset $A \subset \mathbb{R}^n$ is called $k$-dimensional submanifold if it is a $k$-dimensional graph locally, i.e. 
$$
\forall x \in A \exists O_x \subset \mathbb{R}^n \text{ open area around }x: \quad A \cap O_x \text{ is a $k$-dimensional Graph.}
$$
}
\defn{}{
A Graph or submanifold is in $C^l$ if the function $f$ of the Graph is in $f \in C^l$.
}

\rmkb{
The Graph $(x,f(x))$ of a function $f: \mathbb{R}^m \to \mathbb{R}^n$ can be written as a parametrization 
$$
\phi:U \to graph (f) , x \mapsto (x,f(x)), \quad U \subset \mathbb{R}^m, graph(f) \subset \mathbb{R}^{m+n}
$$
and for $f \in C^1 (\mathbb{R}^m,\mathbb{R}^n)$ the Jacobian of the parametrization is
$$
\frac{\partial}{\partial x} \phi(x_0) = \begin{pmatrix}
    1 &0 &\cdots& &0 \\
    0 &1 & 0 &\cdots &0\\
    \vdots && \ddots &&\vdots\\
    0 &&\cdots &&1\\
    \frac{\partial}{\partial x_1} f_{1} (x_0) &&\cdots&& \frac{\partial}{\partial x_m} f_{1} (x_0) \\
    \vdots &&\ddots &&\vdots\\
    \frac{\partial}{\partial x_1} f_{n} (x_0) && \cdots &&\frac{\partial}{\partial x_m} f_{n} (x_0) 
\end{pmatrix}
$$
and is of full rank, due to the identity matrix.
}

\exm{}{
Counterexample of regular parametrization.
}

\defn{}{
Let $A \subset \mathbb{R}^n$ be a subset with regular parametrization $\phi: U \to A$ with $U \subset \mathbb{R}^k$ and $f \in C^0 (A,\mathbb{R}^m???)$, then we define
$$
\int_A f d \sigma := \int_U f \circ \phi \cdot det ((\phi^\prime)^T \phi^\prime) d \mu
$$
}
We will now show that the choice of parametrisation is independend of this Integral, which is indeed what is what we want to hold true. Further, one can interpret $det ((\phi^\prime)^T \phi^\prime)$ as a correction of the distortion of the parametrization.

\lem{}{
Let $A := graph(\lambda)$, then $\int_A f d\sigma$ is independent of the choice of the regular parametrization.
}
\pf{
First, consider the parametrization of the graph, i.e.
$$
\phi: U \to graph (f), x \mapsto (x,f(x)), \quad U \subset \mathbb{R}^m, graph(f) \subset \mathbb{R}^{n+m}.
$$
and second another Parametrization
$$
\psi: V \to graph(f), \quad V \subset \mathbb{R}^m.
$$
We then define $\Upsilon:= \phi^{-1}\circ \psi : U \to V$, which we need to show is continuously differentiable, which is not trivial (*). Then we get that
\begin{align*}
    \int_A f d \sigma &= \int_U f \circ \phi \cdot det ((\phi^\prime)^T \phi^\prime) d \mu\\
    & \stackrel{\substack{Jacobi\\Trafo}}{=} \int_V det(\Upsilon^\prime) \left( (f \circ \phi) \sqrt{det( (\phi^\prime)^T \phi^\prime )} \right) \circ \Upsilon d\mu \\
    &= \int_V   (f \circ \phi \circ \Upsilon) \sqrt{det( (\phi^\prime)^T \phi^\prime )} det(\Upsilon^\prime)  d\mu \\
    &= \int_V   (f \circ \phi \circ \Upsilon) \sqrt{det( (\phi^\prime)^T \phi^\prime ) det(\Upsilon^\prime)^2}  d\mu \\
    &= \int_V   (f \circ \phi \circ \Upsilon) \sqrt{det( (\phi^\prime)^T \phi^\prime ) det((\Upsilon^\prime)^T \Upsilon^\prime)}  d\mu \\
    &= \int_V   (f \circ \phi \circ \Upsilon) \sqrt{det( (\phi^\prime)^T \phi^\prime \cdot (\Upsilon^\prime)^T \Upsilon^\prime)}  d\mu \\
    &= \int_V   (f \circ \phi \circ \Upsilon) \sqrt{det( ((\phi \circ \Upsilon)^\prime )^T (\phi \cdot \Upsilon)^\prime )}  d\mu \\
    &= \int_V   (f \circ \psi) \sqrt{det( (\psi^\prime )^T \psi^\prime )}  d\mu
\end{align*}
In the Jacobi transformation we need that $\Upsilon$ is continuously differentiable and bijective on open sets and $\Upsilon^\prime $ is invertible.\\
Continuously differentiable: For $\Upsilon := \phi^{-1} \circ \psi$ the continuously differentiability it is not clear, because $\phi^{-1}$ is only defined on $A$ which is non-euclidean space, i.e. the chain rule does not apply directly. Hence, define $$
\Pi: \mathbb{R}^n \to \mathbb{R}^k, (x,y) \mapsto x 
$$
then it holds that $\Pi \circ \phi (x) = \Pi (x,\lambda(x))= x$, i.e. $\Pi \circ \phi = Id$ which implies that 
$$
\Pi \big|_{A} = \phi^{-1}, \quad \text{ as $\Phi^{-1}$ is only defined on $A$}.
$$
which in turn implies that $\Upsilon = \phi^{-1} \circ \psi = \Pi_A \circ \psi$ which is by definition a composition of continuous differentiable functions.
}


\section{Distributions}
If a differentiable function is a dsitribtion, the two types of derivatives are equal. Furtherm distributions are differentiable (even infinitely often). The price we pay for that is that two distributions cannot be multiplied.\\
An important tool will be a familiy of functions $(\lambda_\epsilon)_{\epsilon \geq 0}$ called mollifier with the two properties that
$$
supp \lambda_\epsilon = \overline{B_\epsilon(0)}, \quad \text{ and }\quad \int \lambda_\epsilon d\mu =1.
$$
An example for such a mollifier is
$$
\lambda (x) := \begin{cases}
    C e^{\frac{1}{|x|^2 -1}} &, |x|<1\\
    0&,|x|\geq 1
\end{cases}
$$
which is smooth on $\mathbb{R}^n$, its support is $\overline{B_\epsilon(0)}$ and it is non-negative. Note that this example already proves the existence of a test function, because we can choose $C$ in such a way that its integral is $1$. If we rescale $x$ and $\lambda$ we get the mollifier
$$
\lambda_\epsilon (x) := \epsilon^{-n} \lambda (x/\epsilon)
$$
which satisfies the properties??? We call it standard mollifier.\\
We also call mollifiers approximate identity, because of the following: For any $f \in C^0(\Omega;\mathbb{R})$ with $0 \in \Omega$ it holds with continuity that
$$
\forall x \in B_\epsilon(0): \quad f(x) \approx f(0).
$$
This implies that
$$
\int_\Omega f \lambda_\epsilon d\mu = \int_{B_\epsilon (0)} f \lambda_\epsilon d\mu \approx \int_{B_\epsilon (0)} f(0) \lambda_\epsilon d\mu = f(0).
$$
In the next Lemma we show that there is even an equality as $\epsilon \searrow 0$.
\lem{}{
Let $f \in C(\Omega)$ and $(\lambda_\epsilon)_{\epsilon \geq 0}$ a mollifier. The following family
$$
f_\epsilon (x) := \int_\Omega f(y) \lambda_\epsilon (x-y) d^n y
$$
is smooth and converges uniformly on any compact subset of $\Omega$ to $f$ as $\epsilon \searrow 0$. Same for derivatives???
}
\pf{
1.\\
Let $A \subset \Omega$ be compact then it holds that
$$
\exists \epsilon >0 \forall x \in A: \quad B_\epsilon (0) \subset \Omega.
$$
Then we have that
\begin{align*}
    | f_\epsilon (x) - f(x) | &= |\int_\Omega f(y) \lambda_\epsilon (x-y) d^n y- f(x) | \\
    &= |\int_\Omega f(y) \lambda_\epsilon (x-y) d^n y- \underbrace{\int_\Omega \lambda_\epsilon (x-y) d^n y}_{=1}  f(x) | \\
    &= |\int_\Omega (f(y)-f(x)) \lambda_\epsilon (x-y) d^n y \\
    &\leq \sup_{y \in B_\epsilon (0)} |f(y)-f(x)|.
\end{align*}
Due to the fact that continuous functions are uniformly continuous on a compact subset we get convergence $f_\epsilon \to f$ as $\epsilon \searrow 0$.
2.\\
If $f$ is smooth we can compute the derivatives of $f_\epsilon$ in the following way: Warum $2\epsilon$ ball???
}
For $f,g \in C_0^\infty (\mathbb{R}^n)$ we define the convolution as
$$
(g * f)(x) := \int_{\mathbb{R}^n} g(x-y) f(y) d^n y = \int_{\mathbb{R}^n} g(z)f(x-z) d^n z,
$$
which can be shown to be linear, commutative and associative. 
\rmkb{
The advantage of convolution compared to pointwise multiplication is that it behaves nicely with differentiation. One can show that
$$
\partial^\alpha (g *f) = (\partial^\alpha g) *f = g * (\partial^\alpha f).
$$
Further one can show that convolution is volume preserving under the coordinate transform $z=y-x$ and $y=y$:
\begin{align*}
    \int_{\mathbb{R}^n} (f*g)(x) dx &= \int_{\mathbb{R}^n} \int_{\mathbb{R}^n} f(x-y) g(y) dx dy= \int_{\mathbb{R}^n} \int_{\mathbb{R}^n} -(-1) f(z) g(y) dz dy \\
    &=\left( \int_{\mathbb{R}^n} f(z) dz\right) \left( \int_{\mathbb{R}^n}   g(y) dy \right).
\end{align*}
}
\lem{}{
Suppose $f $ and $g$ are rotationally symmetric around symm. around $a$ and $b$ respectively, i.e. for every $O$ orthogonal transformation holds $f(a+x) = f(a+Ox)$. It then follows that $f *g$ is rotationally symmetric around $a+b$.
}
\pf{
\begin{align*}
    (f* g)(a+b+Ox) &= \int_{\mathbb{R}^n} f(a+b+Ox-y) g(y) dy \\
    &\stackrel{(*)}{=} \int_{\mathbb{R}^n} f(a+b+Ox-(Oz+b)) g(Oz+b) dz \\
    &=  \int_{\mathbb{R}^n} f(a+O(x-z)) g(Oz+b) dz \\
    & \stackrel{VSS}{=}  \int_{\mathbb{R}^n} f(a+x-z) g(b+z) dz \\
    &=  \int_{\mathbb{R}^n} f(a+x-(y^\prime -b )) g(b+y^\prime -b) dy^\prime \\
    &=  \int_{\mathbb{R}^n} f(a+x-y^\prime +b ) g(b+y^\prime -b) dy^\prime \\
    &= (f*g) (a+b+x)
\end{align*}
Although we used in $(*)$ that $dy=dz$. This is due to $y(z) := Oz+b$ has the jacobian $\frac{\partial}{\partial z} y(z_0) = O$ and thus with the Jacobi-transformation theorem we have $det (O)=1$. 
}
For every $f \in L_{loc}^1(\Omega)$ we define
$$
F_f : C_0^\infty (\Omega) \to \mathbb{R}, \phi \mapsto \int_\Omega f \phi d \mu
$$
and will see that information wrt. derivatives is retained in this linear form. The idea of distributions is to consider not just functions integrated against test functions, but all linear forms $F$ defined on $C_0^\infty (\Omega)$???
To evade the difficulty of defining the topology on $C^\infty (\Omega)$, we use an equivalent criterion. $\mathcal{D}(\Omega)$ is the set of functions $f \in C_0^\infty (\Omega)$ that satisfy $f_n \to f \in C_0^\infty (\Omega)$ $: \iff$
\begin{itemize}
    \item $\exists K \subset \Omega$ compact $\forall n \in \mathbb{N}$: $supp f_n \subset K$
    \item $\forall \alpha \in \mathbb{N}_0^n$: $sup_K |\partial^\alpha f_n - \partial^\alpha f| \to 0$, $n \to \infty$.
\end{itemize}
\rmkb{
We define the seminorm 
$$
\| \cdot \|_{K,\alpha} : C_0^\infty (\Omega) \to \mathbb{R}, \phi \mapsto \| \phi \|_{K,\alpha} := \sup_{x \in K} |\partial^\alpha \phi (x)|.
$$
It is a seminorm, as constant functions $f \equiv const.$ have $\| f \|_{K,\alpha} =0$, but they are not zero! \\
Note that convergence $\| f_n -f \|_{K,\alpha} \to 0$ is stronger than $\| f_n -f \|_{\infty}$. This can be seen by the following counterexample.
}
\exm{}{
Define $f_n (x) := \frac{1}{n} \sin (nx) \textbf{1}_{[-1,1]}(x)$. Then we have that
$$
\| f_n (x) \| \leq \frac{1}{n}.
$$
and because $\frac{1}{n}$ converges to zero, we get converge in $\| \cdot \|_\infty$.
But on the other hand for $\alpha =1$ and $n=1$ we have
\begin{align*}
     \sup_{x \in [-1,1]} |\partial_x f_n (x)| &= \sup_{x \in [-1,1]} |\cos (nx) \textbf{1}_{[-1,1]}(x) + \frac{1}{n} \sin (nx) \frac{\partial}{\partial x} \textbf{1}_{[-1,1]}(x)| \\
     &\geq \sup_{x \in [-1,1]} |\cos (nx) | =1, 
\end{align*}
i.e. it is bounded by below by $1$ for all $n \in \mathbb{N}$ and thus not convergent to zero.
}


\defn{}{
On an open $\Omega \subseteq \mathbb{R}^n$ we define $\mathcal{D}^\prime (\Omega)$ the space of all linear maps 
$$
F: \mathcal{D}(\Omega) \to \mathbb{R}
$$
which are continiuous wrt. seminorms $\| \cdot \|_{K,\alpha}$ as the space of distributions, i.e.
$$
\forall K \subset \Omega \text{ compact } \exists \alpha_1,...,\alpha_M, M< \infty, C_1,...,C_M>0 \forall \phi \in \mathcal{D}(\Omega): |F(\phi)| \leq C_1 \| \phi \|_{K,\alpha_1} +...+ C_M \| \phi \|_{K,\alpha_M}.
$$
}
Note that with continuity we get that
$$
\phi_n \to \phi \text{ in } \mathcal{D}(\Omega) \quad \Rightarrow \quad F(\phi_n) \to F(\phi) \text{ in } \mathbb{R}.
$$
and 
$$
\forall \phi\in D(\Omega): \quad  F_n (\phi) \to F(\phi) \quad \Rightarrow \quad F_n \to F \text{ in } \mathcal{D}(\Omega).
$$

\exm{}{
First, we show that $F: L_{loc}^1 (\Omega) \to \mathbb{R}$ is a distribution. We show continuity: \\
$\forall K \subset \Omega$ compact and $\forall \phi \in \mathcal{D}(\Omega)$ with $supp \phi \subset K$:
$$
|F_f (\phi)| \leq \int_K
 |f||\phi| dx \leq \sup_{x \in K} |\phi (x)| \int_K |f|dx= \sup_{x \in K} |\phi (x)| \underbrace{ \|f\|_{L^1 (K)}}_{\leq const.}
 $$
 Next, one can show that 
 $$
 \delta: \mathcal{D}(\mathbb{R}^n) \to \mathbb{R}, \quad \phi \mapsto \phi(0)
 $$
 is a distribution.???
}

\lem{}{
If $f \in L_{loc}^1(\Omega)$ satisfies $F_f (\phi) \geq 0$ $\forall \phi \in C_0^\infty (\Omega)$ then it follows $f \geq 0$ a.e. and $L_{loc}^1 (\Omega) \to \mathcal{D}^\prime (\Omega),$ $f \mapsto F_f$ is injective.
}
\pf{
For a mollifier $(\lambda_\epsilon)_{\epsilon >0}$ it holds that
\begin{align*}
    \| \lambda_\epsilon *f -f \|_1 &= \int_{\mathbb{R}^n} \left| \int_{B_\epsilon(0)} \lambda_\epsilon (y) f(x-y) d^n y -f(x) \right| d^n x \\
    &\leq \int_{\mathbb{R}^n}  \int_{B_\epsilon(0)} \lambda_\epsilon (y)\left|  f(x-y) -f(x) \right| d^n y d^n x \\
    &\leq \int_{B_\epsilon(0)}\int_{\mathbb{R}^n}   \lambda_\epsilon (y)\left|  f(x-y) -f(x) \right| d^n x d^n y \\
    &\leq \sup_{ y \in B_\epsilon(0)}\int_{\mathbb{R}^n}   \lambda_\epsilon (y)\left|  f(x-y) -f(x) \right| d^n x \\
    &\leq \sup_{ y \in B_\epsilon(0)}  \lambda_\epsilon (y)\|   f(\cdot-y) -f(\cdot) \|_{L^1(\Omega)}
\end{align*}
For step functions
$$
f (x) := \sum_{i=1}^n a_i \textbf{1}_{Q_i} (x), \quad \bigcup_{i=1}^n Q_i =???
$$
Then using triangle inequality we get
$$
\| \lambda_\epsilon * f-f \|_1 \leq \sum_{i=1}^n \| \lambda_\epsilon * a_i -a_i \|_{L^1(Q_i)} \leq \sum_{i=1}^n \sup_{y \in B_\epsilon(0)}  \|   a_i -a_i \|_{L^1(Q_i)} ???
$$
and because the step function lie dense in $L^1 (\Omega)$ in the limit and choosing $\epsilon>0$ sufficiently small we get that the supremum gets arbitrary small. Nur lim inf gegen Null gezeigt??? Muss schnell genug gegen 0???.
}


Let $\Omega^\prime \subset \Omega$ then every test function on $\Omega^\prime$ is also a test function on $\Omega$. If we restrict a distribution on $\Omega$ only to $\Omega^\prime$ it is again a distribution. We call this restriction. Using restrictions we can define the support of a distribution. The compliment of the support of a distribution is the union over all stes on which the distribution/restriction vanishes:
$$
(supp F)^C = \bigcup_{\Omega^\prime \in \mathcal{P} (\Omega)} \{\Omega^\prime \subset \Omega \mid F(\phi) =0, \forall \phi \in \mathcal{D}(\Omega^\prime) \}
$$
The support of a delta distribution is $\{0\}$ and for a $L_{loc}^1(\Omega)$ is the support in the classical sense.\\
We now want to define as many operations as possible on distributions and thus extend operations on functions. The idea is to compare $F_f$ and $F_{Af}$, where $A$ is some operation. If we can write the operation in a way that only depends on the distribution and not directly on the function it is a suitable definition of be generalized.\\
First, we consider the multiplication by a smooth function $g \in C^\infty (\Omega)$ and $F: L_{loc}^1(\Omega) \to \mathbb{R}$
$$
F_{fg} (\phi) = \int_\Omega (gf) \phi dx = \int_\Omega f(g \phi) dx = F_f (g\phi).
$$
Thus we define the multiplication by a smooth function $g \in C^\infty (\Omega)$ in the following way.
\defn{}{
For $g \in C^\infty (\Omega)$ define
$$
gF: \mathcal{D}(\Omega) \to \mathbb{R}, \quad \phi \mapsto F(g \phi).
$$
}
\rmkb{
Remember that for two topoligical spaces $X$ and $Y$ the mapping $f: X \to Y$ is called an embedding of two topological spaces, if it is bijective, continuous and its inverse is continuous. ...???
}
Note that the producti of a distribution with a non-smooth function is not defined, because then $g \phi$ is not a test function.\\
The most important operation for distributions is its derivative. Integrating by parts yields
$$
F_{\partial_i f}(\phi) = \int_\Omega \partial_i f \phi d^n x= - \int_\Omega f\partial_i\phi d^n x=- F_f (\partial_i \phi).
$$
\defn{}{
For all $F \in \mathcal{D}^\prime (\Omega)$ we define
$$
\partial_i F: \mathcal{D}^\prime \to \mathbb{R}, \quad \phi \mapsto - F(\partial_i \phi).
$$
}
Hence, test functions are infinitely differentiable.
\rmkb{
These two new operations are distributions again and are clearly linear. One would need to show as well that they obey the continuity definition.
}
We now want to extend convolutions to distributions. Observe that
\begin{align*}
F_{g *f} (\phi) &= \int_{\mathbb{R}^n} (g *f) \phi d^n x = \int_{\mathbb{R}^n} \int_{\mathbb{R}^n} g(x-y) f(y) \phi(x) d^n y d^nx \\
&\stackrel{Fubini}{=} \int_{\mathbb{R}^n} \int_{\mathbb{R}^n} \phi(x) g(x-y) d^n x f(y) d^ny= F_f (\phi*Pg),
\end{align*}
although $(Pg)(z) := g(-z)$ is the point reflection operator.

\defn{}{We define for $g \in C_0^\infty (\mathbb{R}^n)$ and $F \in \mathcal{D}^\prime (\mathbb{R}^n)$
$$
g*F: \mathcal{D}(\mathbb{R}^n) \to \mathbb{R}, \quad \phi \mapsto F(\phi * Pg).
$$
}
One would need to check that this is again a distribution and it is even a regular distribution, i.e. $\phi * Pg \in \left( L_{loc}^1 (\Omega) \right)^\prime$.
\lem{}{
Let $g \in C_0^\infty (\mathbb{R}^n)$ be a test function and a distribution $F \in \mathcal{D}^\prime (\mathbb{R}^n)$, then their convolution satisfy
$$
g * F \in C^\infty (\mathbb{R}^n)
$$
and we can write it as
$$
g*F: \mathbb{R}^n \to \mathbb{R}, \quad x \mapsto F(T_x Pg),
$$
where $(T_x \phi)(y) := \phi (y-x)$ is the translation operator. \\
Finally, it holds that $supp g*F \subset supp g + suppF$.
}
\pf{
We first show existence and continuity of $g*F$.\\
Existence:\\
\begin{align*}
    supp T_x Pg & = \{ y \in \mathbb{R}^n \mid y \in supp Pg (\cdot -x) \} = \{ y \in \mathbb{R}^n \mid y \in supp g (x- \cdot ) \} \\
    & = \{ y \in \mathbb{R}^n \mid x-y \in supp g ( \cdot ) \} = x -supp \;g
\end{align*}
Thus, $\forall x \in \mathbb{R}^n$ and $F \in \mathcal{D}^\prime (\mathbb{R}^n)$ we have that $F(T_x Pg)$ is well defined, because $supp \;g$ is well defined.\\
Continuity:\\
Fist, we see that $(T_x Pg)(y) = Pg(y-x) = g(x-y)$, $g$ is continuous and continuity implies uniform continuity on a compact subset, we have that $x \mapsto T_x Pg$ is continuous wrt. $\| \cdot \|_{K,0}$. Remember, that $K \subset supp \; T_x Pg$ is compact. We now need to show that
$$
\frac{T_{x+\epsilon h} -T_x}{\epsilon} g \stackrel{uniformly}{\to} T_x \left( \sum_{i=1}^n -h_i \partial_i g \right), \quad \epsilon \to 0, \text{ on } \mathbb{R}^n.
$$
This is due to the following: Remember that with Taylor and the mean value theorem
$$
\frac{g(x-\epsilon h)-g(x)}{\epsilon} \stackrel{uniformly}{\to} - h \langle h, \nabla g(y)\rangle, \quad \epsilon \to 0
$$
Using the fact that
$$
\frac{T_{x+\epsilon h} -T_x}{\epsilon} g = T_x \frac{T_{\epsilon h} -Id}{\epsilon} g= T_x\frac{T_{\epsilon h} g -g}{\epsilon} = T_x \frac{g(\cdot - \epsilon h)-g(\cdot)}{\epsilon}
$$
it follows that
$$
\frac{T_{x+\epsilon h} -T_x}{\epsilon} g  \stackrel{uniformly}{\to} T_x \langle h,\nabla g(x) \rangle = T_x\left( \sum_{i=1}^n -h_i \partial_i g \right).
$$
Due to the fact that $F$ is a distribution, i.e. continuous we get that
$$
\forall x \in \mathbb{R}^n: \quad F(\frac{T_{x+\epsilon h} -T_x}{\epsilon} g ) \to F(T_x\left( \sum_{i=1}^n -h_i \partial_i g \right)), \quad \epsilon \to 0.
$$
which means that $x \mapsto F(\frac{T_{x+\epsilon h} -T_x}{\epsilon} g )  \in C^\infty (\mathbb{R}^n;\mathbb{R})$, for $F \in \mathcal{D}^\prime (\mathbb{R}^n)$.\\
We now show the equality. Above it was shown that $x \mapsto T_x Pg$ is smooth on $\mathcal{D}(\mathbb{R}^n)$, i.e. wrt. the semi-norm $\| \cdot \|_{K,\alpha}$. We choose
$$
K \subset supp \; T_xPg = x-supp\; g
$$
as a compact subset. Thus a finite disjoint decomposition exists 
$$
K := \bigcup_{i=1}^n E_i.
$$
Then the Riemann sum is given by
$$
S_n := \sum_{i=1}^n (T_{x_j} Pg)(\cdot) \phi (x_i) |E_i|.
$$
Due to $supp \;T_x Pg = x- supp \; g$ we have that $T_x Pg \in \mathcal{D}(\mathbb{R}^n)$. Multiplying with constants and a finite sum still leads to $S_n \in \mathcal{D}(\mathbb{R}^n)$. It then follows that for $x \in supp \phi$
\begin{align*}
    \| \int_{\mathbb{R}^n} (T_x Pg)(\cdot) \phi(x) d^n x -S_n \|_{K,\alpha} &\leq \sum_{i=1}^n |E_i| \int_{\mathbb{R}^n} \| (T_x Pg)(\cdot) \phi(x) - (T_{x_i} Pg)(\cdot) \phi (x_i)\|_{K,\alpha} d^n x
\end{align*}


}

\chapter{Laplace equation}
We begin by solving the Laplace equation that is given by 
\[
\Delta u = f
\]
....
\section{Fundamendal Solution}
This equation is invaraint wrt. all rotations and translations. This leads to the notion that our solution should also have these conditions. We defeine $r:= |x| := \sqrt{x^T x}$ which defines the length of the position vector, i.e. the solution should only depend on this $r$. Further, define $u(x) := v(r) $. Then for $w(r) := v^\prime (r)$
\[
\nabla_x u(x) = v^\prime (r)  \nabla_x r = v^\prime(r) \frac{2x}{2|x|}
\]
which leads to
\[
\Delta_x u(x) = \nabla_x \cdot \nabla_x u(x)= \nabla_x \cdot (v^\prime(r) \frac{x}{|x|} )= v^{\prime \prime} (r) + \frac{n-1}{r} v^\prime (r)=0.
\]
We see that this is only an ODE in $r$. Solving it is not hard: First it can be seen that
\[
v^{\prime \prime} (r) + \frac{n-1}{r} v^\prime (r) =0 \quad \iff \quad (r^{n-1} v^\prime (r) )^\prime= \frac{v^\prime (r)}{n-1} r^{n-2} + v^{\prime \prime} r^{n-1}  =0.
\]
Then we define $C_1 := r^{n-1} v^\prime (r)$ which can also be written as $v^\prime (r) =C_1 r^{1-n}$. This formulation now leads t0
\[
v(r) = \begin{cases}
    C_2 + \frac{C_1}{2-n} r^{2-n} &, n \neq 2\\
    C_2 + C_1 \log r &, n=2.
\end{cases}
\]
Note that for the solution the constant $C_2$ can be chosen arbitrarly as it will vanish whilst applying the Laplace operator. With this in mind we define
\[
\Phi (x) := \begin{cases}
    \frac{C_1}{2-n} r^{2-n} &, n \neq 2\\
    C_1 \log r &, n=2.
\end{cases}
\] 
We now need to determine $C_1$.
\defn{}{
    The solution of the Laplace equation is 
    \[
    \Phi (x) :=\begin{cases}
    -\frac{1}{2\pi} \log |x| &, n=2\\
    \frac{1}{n(n-2) \omega_n} \frac{1}{|x|^{n-2}} &, n \geq 3
    \end{cases}
\]
where $\omega_n$ denotes the volume of the n-dimensional unit ball.

}



\thm{}{
    For $f \in C_0^1 (\mathbb{R}^n)$ the solution of the Poisson equation $-\Delta u = f$ is given by the convolution
    \[
    u(x) =(\Phi * f)(x)= \int_{\mathbb{R}^n} \Phi (x-y ) f(y) d^n y  = \int_{\mathbb{R}^n} \Phi (z) f(x-z) d^n z.
    \]
}
\pf{
The first equality in the theorem comes from the substitution $z=x-y$. Note that the second integral is twice continuous differentiable, because we can pull in in the derivative in the Integral due to the fact that $f \in C^2_0 (\mathbb{R}^n)$:
\[
\frac{\partial^2}{\partial x_i \partial x_j} u(x) = \int_{\mathbb{R}^n} \Phi (z) \frac{\partial^2}{\partial x_i \partial x_j} f(x-z) d^n z.
\]
We will now write $\Delta_x u(x) = \int_{\mathbb{R}^n} \Phi (y) \Delta_x f(x-y) d^n y$. The trick now will be to decompose the integral into a open area around zero (where there is a singularity) and everything else. Then we will let the radius of that open area go to zero. Then the integral evaluated at the singularity will be zero, as it will be a zero set. Define for $\epsilon >0$:
\[
\Delta_x u(x) = \underbrace{\int_{\mathbb{R}^n\setminus B_\epsilon (0)} \Phi (y) \Delta_x f(x-y) d^n y}_{=:J_\epsilon} + \underbrace{ \int_{B_\epsilon (0)} \Phi (y) \Delta_x f(x-y) d^n y}_{=:I_\epsilon}
\]
\textbf{Step 1 $I_\epsilon$:}\\
We want to show that the integral 
\[
| I_\epsilon |:= |\int_{B_\epsilon (0)} \Phi (x) \Delta_y f(y-x) d^n x| \leq \| \Delta_y f\|_{L^\infty (\mathbb{R}^n)} \int_{B_\epsilon (0)} |\Phi (x) |d^n x 
\]
is finite and converges to zero. Note that using the Co-Area theorem we have that
\[
B_\epsilon (0) := \{ x \in \mathbb{R}^n \mid l(x) := |x| < \epsilon \}
\]
and due to $1= |\nabla l(x)|$ we get that
\[
\int_{B_\epsilon(0)} \phi (x) d^n x = \int_{B_\epsilon(0)} \phi (x) |\nabla l(x) | d^n x = \int_0^\epsilon \int_{\partial B_r (0)} \phi d\sigma dr .
\]
We now want to do a Jacobain transformation to the space of $S^{n-1}$. For this define the map $T: S^{n-1} \to \partial B_r (0), s \mapsto T(s) := rs$. But, we have the problem, that the Jabobian is only defined for subsets for euclidean spaces! Thus we need to introduce two new maps. First, $\psi:  V \subset \mathbb{R}^{n-1} \to \partial B_r(0)$ and $\phi: U \subset \mathbb{R}^{n-1} \to S^{n-1}$, where $U,V$ are open subsets.  Both are regular parametrizations. Then the write for the composition
\[
F:= \psi^{-1} \circ T \circ \phi : U \to V.    
\]
Its Jacobian we do can calculate. Fist, using the chain rule
\[
DF(x) = D(\psi^{-1})(T(\phi(x)) ) DT(\phi(x)) D\phi (x) .    
\]
Then we use that for $y \in U$:
\[
Id = D(\psi \circ \psi^{-1}) (y) = D \psi (\psi^{-1}(y)) D\psi^{-1} (y) \quad \iff \quad  D\psi^{-1} (y) = ( D\psi ( \psi^{-1}(y) ))^{-1}.
\]
Using this in the above we get that
\begin{align*}
DF(x) & = D(\psi^{-1})(T(\phi(x)) ) DT(\phi(x)) D\phi (x) \\
&= (D\psi ( \psi^{-1}(T(\phi(x)) ) ) )^{-1} DT(\phi(x)) D\phi (x) \\
&= (D\psi ( F(x) ))^{-1} DT(\phi(x)) D\phi (x) \\
\end{align*}
We then have that 
\[
DF(x) = (D\psi ( F(x) ))^{-1} DT(\phi(x)) D\phi (x)  \iff D\psi ( F(x) )  DF(x) =  DT(\phi(x)) D\phi (x) 
\]
We now use the general fact that $AB=C$ implies that
\[
( AB )^T AB = B^T A^T AB =C^T C \]
which leads to
\[
\det (B^T B) \det(A^T A) = \det (C^T C) \iff \det (A^T A) = \frac{\det((C^T C))}{\det ((B^T B))}.
\]
We do this so complicated, as the images are manifolds, i.e. n-1 dimensional subspaces in $\mathbb{R}^n$ and thus we cannot calculate the determinant, as their Jacobians are not square matrices. Now using $D T(\phi (x)) = Id \cdot r $ we get that
\[
\det(DF^T DF) = \frac{ \overbrace{\det (Id \cdot r)^2}^{=r^{2(n-1)}} \det ( D\phi^T D\phi) }{ \det ( D \psi (F) ^T D \psi (F)  ) }.
\]
Due to the fact that $F$ has a quadratic Jaconian we have 
\begin{equation}
\label{Eq: DetDF}
| \det(DF) |= r^{n-1} \sqrt{ \frac{\det ( D\phi^T D\phi) }{ \det ( D \psi (F) ^T D \psi (F)  ) } }
\end{equation}
Let $A_i$ be a cover of $\partial B_r (0)$ and $O_i$ a cover of $S^{n-1}$, then due to $\psi \circ F= T \circ \phi $ the following calculation holds for any $f \in C^1 (\mathbb{R}^n)$:
\begin{align*}
    \int_{B_\epsilon (0)} f(x) d^n x &\stackrel{Co-Area}{=} \int_0^\epsilon \int_{\partial B_r (0)} f d \sigma dr \\
    &= \int_0^\epsilon \sum_i \int_{A_i} \underbrace{h_i f}_{=:f_i} d \sigma dr \\
    &= \int_0^\epsilon \sum_i \int_{V_i} f_i \circ \psi \sqrt{ \det ( D\psi^T D\psi) } d\mu_{\mathbb{R}^{n-1}} dr \\
   & \stackrel{JacobiTransform}{=} \int_0^\epsilon \sum_i \int_{U_i} (f_i \circ \psi \circ F) \sqrt{ \det ( (D\psi(F))^T D\psi(F)) } |\det (DF)|  d\mu_{\mathbb{R}^{n-1}} dr \\
   &= \int_0^\epsilon \sum_i \int_{U_i} (f_i \circ T \circ \phi) \sqrt{ \det ( (D\psi(F))^T D\psi(F)) } |\det (DF)|  d\mu_{\mathbb{R}^{n-1}} dr \\
   &\stackrel{Eq. \ref{Eq: DetDF}}{=} \int_0^\epsilon \sum_i \int_{U_i} (f_i \circ T \circ \phi) \sqrt{ \det ( (D\psi(F))^T D\psi(F)) }  r^{n-1} \sqrt{ \frac{\det ( D\phi^T D\phi) }{ \det ( D \psi (F) ^T D \psi (F)  ) } } d\mu_{\mathbb{R}^{n-1}} dr \\
   &= \int_0^\epsilon \sum_i \int_{U_i} (f_i \circ T \circ \phi)   r^{n-1} \sqrt{ \det ( D\phi^T D\phi) }  d\mu_{\mathbb{R}^{n-1}} dr \\
   &= \int_0^\epsilon \sum_i \int_{O_i} (f_i \circ T)   r^{n-1}   d\sigma dr \\
   &= \int_0^\epsilon  \int_{S^{n-1}} (f \circ T)   r^{n-1}   d\sigma dr \\
\end{align*}

Then it holds that
\[
\int_{B_\epsilon (0)} |\Phi (y) | d^n y \stackrel{above}{=} \int_0^\epsilon \int_{S^{n-1}} |\Phi \circ T| d \sigma r^{n-1} dr = \int_0^\epsilon \int_{S^{n-1}} |\Phi (r x )| d \sigma(x) r^{n-1} dr.
\]
We see that for all $x \in S^{n-1}$ it follows $|x|=1$ and thus
\[
\Phi (x r) = \Phi (r e), \quad \text{where } e \text{ is any unit vector.}
\]
Due to the fact that
\begin{align*}
    \int_{S^{n-1}} 1 d \sigma (x) &= \int_{S^{n-1}} |x|^2 d \sigma (x) = \int_{S^{n-1}} F \nu d\sigma = \int_{B_1 (0)} div F d^n x \\
    &= \int_{B_1 (0)} \sum_{i=1}^{n} \frac{\partial}{\partial x_i} x_i d^n x = n \lambda^{n} (B_1(0)) =: n \omega_n
\end{align*}
it finally follows
\begin{align*}
\int_{B_\epsilon (0)} |\Phi (y) | d^n y& = \int_0^\epsilon \int_{S^{n-1}} |\Phi (r x )| d \sigma(x) r^{n-1} dr = \int_0^\epsilon r^{n-1} | \Phi (r e) | \int_{S^{n-1}} 1 d \sigma (x) dr \\
&= \int_0^\epsilon r^{n-1} | \Phi (r e) | n \omega_n dr \\
&= \begin{cases}
    \int_0^\epsilon r |\log (r)| dr &, n=2 \\
    \int_0^\epsilon r^{n-1} \frac{1}{ (n-2) r^{n-2}} dr &, n \geq 3
\end{cases}\\
&= \begin{cases}
    \frac{\epsilon^2}{2} ( | \log (\epsilon) | + \frac{1}{2}) &, n=2 \\
    \int_0^\epsilon r \frac{1}{ n-2} dr = \frac{\epsilon^2}{2 (n-2)} &, n \geq 3
\end{cases}
\end{align*}
Note that in the case $n=2$ we have $\omega_n = \pi$. Both terms are finite! And because the upper bounds depend on $\epsilon$ it follows that $I_\epsilon \to 0$ as $\epsilon \to 0$. \\
\textbf{Step 2 $J_\epsilon$:}\\
First notice that for $z:= x-y$ it holds that $\sum_j \partial f(z) \frac{\partial}{\partial x_i} z = \partial_i f (x-z) =- \sum_j \partial f(z) \frac{\partial}{\partial y_i} z$ and thus $|\Delta_x f(x-y) | = |\Delta_y f(x-y)|$. It follows
\begin{align*}
    |J_\epsilon | &\leq  \int_{\mathbb{R}^n \setminus B_\epsilon (0)} |\Phi (y)| | \Delta_y f(x-z) | d^n y \\
    &\stackrel{\phi \Delta f = (\phi \nabla f)^\prime - \nabla \phi \nabla f}{=}  \int_{\mathbb{R}^n \setminus B_\epsilon (0)} | \nabla_y \Phi (y)| | \nabla f(x-z) | d^n y - \int_{\mathbb{R}^n \setminus B_\epsilon (0)} (|  \Phi (y)| | \nabla f(x-z) | )^\prime  d^n y \\
    &= \int_{\mathbb{R}^n \setminus B_\epsilon (0)} | \nabla_y \Phi (y)| | \nabla f(x-z) | d^n y - \int_{\partial B_\epsilon (0)} |  \Phi (y)| | \nabla f(x-z) | N d \sigma (y) \\
    &=: K_\epsilon - L_\epsilon.
\end{align*}
First with the same arguments as above it follows
\[
|L_\epsilon| \leq \| f \|_{L^\infty (\mathbb{R}^d)} \int_{\partial B_\epsilon (0)} |\Phi (y)| d \sigma (y) \leq \begin{cases}
    C \epsilon |\log (\epsilon)| &, n=2\\
    C \epsilon &, n \geq 3
\end{cases}
\]
This clearly converges to zero as $\epsilon \to 0$. For $K_\epsilon$ we have that
\begin{align*}
    K_\epsilon &= \int_{\mathbb{R}^n \setminus B_\epsilon (0)} \nabla_y \Phi (y) \nabla_y f(x-y) d^n y \\
    &= \underbrace{ \int_{\mathbb{R}^n} \setminus B_\epsilon (0) \Delta_y \Phi (y) f(x-y) d^n y }_{=0} - \int_{\mathbb{R}^n \setminus B_\epsilon (0)} (\nabla_y \Phi(y) f(x-y))^\prime d^n y \\
    &= - \int_{\partial B_\epsilon (0)} \nabla_y \Phi(y) f(x-y) N d \sigma( y).
\end{align*}
Note that $\nabla \Phi (y) = - \frac{y}{n \omega_n |y|^n }$ and $N= - \frac{y}{|y|}$. Further, due to the fact that
\begin{align*}
r^n n \omega_n &= n \int_{B_r (0)} 1 d^n x = \int_{B_r (0) } \nabla \cdot x d^n x = \int_{\partial B_r (0)} x N d\sigma (x) \\
&= \int_{\partial B_r (0)} x \frac{x}{|x|} d\sigma (x) = \int_{\partial B_r (0)} |x| d \sigma (x) =r \int_{\partial B_r (0)} d\sigma (x) = r \sigma_n (r)
\end{align*}
The above is equivalent to $\sigma_n (r) = n \omega_n r^{n-1}$. This finally leads to
\begin{align*}
    K_\epsilon &= - \int_{\partial B_\epsilon (0)} \nabla_y \Phi (y) f(x-y) N d \sigma (y) \\
    &=  \int_{\partial B_\epsilon (0)} \frac{y}{n \omega_n |y|^n } f(x-y) (-1)\frac{y}{|y|} d \sigma (y) \\
    &=-  \int_{\partial B_\epsilon (0)} \frac{|y|}{n \omega_n \epsilon^n } f(x-y)  d \sigma (y) \\
    &=-\frac{\epsilon}{n \omega_n \epsilon^n }  \int_{\partial B_\epsilon (0)}  f(x-y)  d \sigma (y) \\
    &=-\underbrace{\frac{1}{\sigma_n (\epsilon)}}_{\to 1, \epsilon \to 0}  \underbrace{\int_{\partial B_\epsilon (0)}  f(x-y)  d \sigma (y)}_{\to -f(x) , \epsilon \to 0} \to - f(x), \quad \epsilon \to 0,
\end{align*}
because $f$ is continuous. Thus in total we have shown that\[
\Delta_x u(x) = J_\epsilon + I_\epsilon = J_\epsilon + K_\epsilon - L_\epsilon \leq |J_\epsilon| + K_\epsilon +| L_\epsilon|  \to -f(x) , \quad \epsilon \to 0.
\]
}
Thus due to the fact that we can write for every $\phi \in C_0^\infty (\mathbb{R}^n):$
\begin{align*}
    (f* \delta_0 )(\phi) &= \delta_0 (\phi * Pf) =\int_{\mathbb{R}^n} (\phi * Pf) (x) d \delta_0 (x) \\
    &= (\phi * Pf) (0) = \int_{\mathbb{R}^n } f(x) \phi (x) d^n x \\
    &= \int_{\mathbb{R}^n } (-\Delta_x u(x) ) \phi (x) d^n x = \int_{\mathbb{R}^n } -\Delta_x (\Phi * f)(x)  \phi (x) d^n x \\
    &= \int_{\mathbb{R}^n } ((-\Delta_x \Phi) * f)(x)  \phi (x) d^n x \\
    &= (f* (-\Delta_x \Phi) ) (\phi),
\end{align*}
it follows that $-\Delta_x \Phi = \delta_0$ in the distributional sense.

\section{Mean Value Property}
The value of $u$ at the center of any $B_r (0)$ with compact closure $(\bar{A}:= \{ x \in \Omega \mid \forall \epsilon>0: \mathcal{U}_\epsilon (x) \cap A \neq \emptyset \}$, i.e. open balls, that are close to $A$ are also have a overlap with $A$) in $\Omega$ is equal to the mean of $u$ on the boundary of the ball. In the following we will show that this porperatry holds for any harmonic function. Remember, these were functions that satisfy $\Delta u =0$. One can also show that if this mean value property holds for a function $u$ then it is harmonic. We will also show that the mean on $B_r (x)$ is the mean over the means of $u$ on $\partial B_{r^\prime } (x)$ for all $r^\prime \in [0,r]$. I.e. after having shown both directions, the mean value property is equivalent to functions beeing harmonic.


\lem{}{
    \begin{itemize}
        \item Let $u \in C^2 (\Omega)$ be harmonic on an open domain $\Omega \subset \mathbb{R}^n$ containing $\overline{B_r (x)}$. THe mean of $u$ on $B_r (x)$ and on $\overline{B_r (x)}$ is equal to $u(x)$, i.e. the center.
        \item If for $u \in C^2 (\Omega)$ the means on all Balls $B_r (x)$ with compact closure in $\Omega$ or all means on the boundaries of such balls is equal to $u(x)$ then $u$ is harmonic.
    \end{itemize}
}
    \pf{
        Define for $x \in \Omega$ the mean of $u$ on $\partial B_r (x) \subseteq \Omega$ as 
        \begin{align*}
            S_x (r) &:= \frac{1}{r^{n-1} n \omega_n} \int_{\partial B_r (x)} u(y) d \sigma (y) = \frac{1}{r^{n-1} n \omega_n} \int_{\partial B_1 (x)} (u \circ T) (y) r^{n-1} d \sigma (y) \\
            &= \frac{1}{n \omega_n} \int_{\partial B_1 (0)} (u \circ G) (ry)  d \sigma (y) = \frac{1}{n \omega_n} \int_{\partial B_1 (0)} u  (x+ry)  d \sigma (y)
        \end{align*}
        where $T: \partial B_1 (x) \to \partial B_r (x), y \mapsto ry$ and $G: \partial B_r (0) \to \partial B_r (x), y \mapsto x+y$. The transformation with $T$ has already been discussed. Transforming with $G$ is only a translation and its Jabobian is trivially $Id$. Note that one would need to use parametrizations in order to calculate the Jacobian on euclidean spaces.\\
        With the divergence theorem we get
        \[
        \frac{d}{dr} S_x (r) = \frac{1}{n \omega_n} \int_{\partial B_1 (0)}\frac{d}{dr}  u  (x+ry)  d \sigma (y) =  \frac{1}{n \omega_n} \int_{\partial B_1 (0)} \nabla u (x+ry) y d \sigma (y)
        \]
        Note that $y$ is on $\partial B_1 (0)$ a normal vector, i.e. $|y| =1$ and if we consider $B_1 (0)$ then it is an outward pointing normal vector. If we now transform back to $\partial B_r (x)$ then $\frac{y-x}{r} = \frac{y-x}{|y-x|}$ is an outward pointing normal vector! Thus we get
        \begin{align*}
        \frac{d}{dr} S_x (r) &= \frac{1}{n \omega_n} \int_{\partial B_1 (0)} \nabla u (x+ry) y d \sigma (y) = \frac{1}{n \omega_n} \int_{\partial B_1 (0)} \nabla u (x+ry) y d \sigma (y) \\
        &= \frac{1}{r^{n-1} n \omega_n} \int_{\partial B_r (x)} \nabla u (y) \underbrace{\frac{y-x}{|y-x|}}_{=N} d \sigma (y) = \frac{1}{r^{n-1} n \omega_n} \int_{B_r (x)} \underbrace{ \nabla \cdot \nabla u (y)}_{= \Delta u(y)} d^n y.
        \end{align*}
        The above only holds for $\overline{B_r (x)}$ compact in $\Omega$, because ???. If $u$ is harmonic, i.e. by definition $\Delta u \equiv 0$, then it follows that $\frac{d}{dr} S_x (r) =0$ for all such $r$, i.e. $S_x (r)$ is constant in $r$. This just means that the average on $\partial B_r (x)$ does not depend on $r$. Further, because $u$ is continuous it follows that $S_x (r) \to u(x) , r \to 0$. THus means that the mean is the center value, because $S_x (0) = u(x)$ and $S_x (\cdot ) $ is constant.\\
        Now it holds that 
        \[
        \int_{B_r (x) } u(y) d^n y = \int_{B_r (0)} u(x+y) d^n y = \int_{B_r (0) \cap \{ y_n >0 \}} u(x+y) d^n y + \int_{B_r (0) \cap \{ y_n <0 \}} u(x+y) d^n y + \underbrace{ \int_{B_r (0) \cap \{ y_n =0 \}} u(x+y) d^n y}_{=0}.
        \]
        In order to calculate these two integrals we need to do a Jacobi tranformation. We take the mapping \[
        \phi_+: \{ (z,s) \in B_r^{n-1} (0) \times (0,r) \mid |z| < s \} \to B_r (0) \cap \{ y_n >0\},  (z,s) \mapsto \left( z, \sqrt{s^2 -|z|^2} \right)
        \]
        and \[
        \phi_-: \{ (z,s) \in B_r^{n-1} (0) \times (0,r) \mid |z| < s \} \to B_r (0) \cap \{ y_n >0\},  (z,s) \mapsto \left( z,- \sqrt{s^2 -|z|^2} \right).
        \]
        which gives us
        \[
        \int_{B_r (0) \cap \{ y_n >0 \}} u(x+y) d^n y = \int_0^r \int_{B_s^{n-1} (0)} u \left( x+ \left( z, \sqrt{s^2 -|z|^2} \right) \right) \underbrace{|\det (D\phi_+ (z,s))|}_{\stackrel{(*)}{=} \frac{s}{\sqrt{s^2-|z|^2}}} d^{n-1} z ds.
        \]
        We now need to find a parametrization $\psi$ that satisfies $det((\psi^\prime)^T \psi^\prime) = \frac{s}{\sqrt{s^2-|z|^2}} $ and then we can write it as an integral over a manifold. Fot that define
        \[
        \psi_+: B_s^{n-1}(0) \to \partial B_s^n (0) \cap \{ y_n >0  \} , z \mapsto \left( z, \sqrt{s^2 -|z|^2} \right).
        \] 
        This gives us 
        \begin{align*}
        \int_{B_r (0) \cap \{ y_n >0 \}} u(x+y) d^n y &= \int_0^r \int_{B_s^{n-1} (0) \cap \{ y_n >0 \} } u \left( x+ \underbrace{ \left( z, \sqrt{s^2 -|z|^2} \right)}_{=\psi_+ (z)} \right) |\det((\psi_+^\prime)^T \psi_+^\prime)| d^n z ds\\
        &= \int_0^r \int_{\partial B_s^{n-1} (0)\cap \{ y_n >0 \} } u(x+y) d \sigma (y) ds.
        \end{align*}
        Doing this analougously for $\phi_-$ and defining an respective $\psi_-$ we get in total that
        \begin{align*}
            \int_{B_r (x)} u(y) d^n y &=  \int_{B_r (0) \cap \{ y_n >0 \}} u(x+y) d^n y + \int_{B_r (0) \cap \{ y_n <0 \}} u(x+y) d^n y \\
            &= \int_0^r \int_{\partial B_s^{n-1} (0)\cap \{ y_n >0 \} } u(x+y) d \sigma (y) ds + \int_0^r \int_{\partial B_s^{n-1} (0)\cap \{ y_n <0 \} } u(x+y) d \sigma (y) ds \\
            &= \int_0^r \int_{\partial B_s^{n-1} (0) } u(x+y) d \sigma (y) ds \\
            &= \int_0^r \int_{\partial B_s^{n-1} (x) } u(y) d \sigma (y) ds 
        \end{align*}
        altough we used in the last step a translation on manifolds, which has Jacobain $Id$. \\
        Now we can finally show that due to the fact that $S(\cdot)\equiv u(x)$ is constant we get
        \begin{align*}
            \frac{1}{r^n \omega_n} \int_{B_r (x)} u (y ) d^n y &= \frac{n}{r^n n \omega_n} \int_0^r \frac{s^{n-1}}{s^{n-1}} \int_{\partial B_s^{n-1} (x) } u(y) d \sigma (y) ds \\
            &= \frac{n}{r^n } \int_0^r s^{n-1} \frac{1}{s^{n-1} n \omega_n} \int_{\partial B_s^{n-1} (x) } u(y) d \sigma (y) ds \\
            &= \frac{n}{r^n } \int_0^r s^{n-1} S(s) ds = u(x) \frac{n}{r^n } [\frac{1}{n} s^n]_0^r = u(x).
        \end{align*}       
        Now we show the other direction: \\
        Let $\overline{B_r (x)} \subset \Omega$ for every $r>0$ be compact and assume the mean value property holds, i.e.
        \[
        u(x) = \frac{1}{\omega_n r^n} \int_{B_r (x)} u(y) d^n y = \frac{1}{\omega_n r^n} \int_{B_r (x)} u(y) d^n y \stackrel{above}{=} \frac{n}{r^n} \int_0^r s^{n-1} S_x (s) ds.
        \]
        Because $u$ is constant in $r$ it follows that 
        \begin{align*}
        0&= \frac{d}{dr} \frac{n}{r^n} \int_0^r s^{n-1} S_x (s) ds  \\
        &= -\frac{n^2}{r^{n+1}} \int_0^r s^{n-1} S_x (s) ds + \frac{n}{r^n} \frac{d}{dr}   \int_0^r s^{n-1} S_x (s) ds \\
        &\stackrel{???}{=} -\frac{n^2}{r^{n+1}} \int_0^r s^{n-1} S_x (s) ds + \frac{n}{r^n} r^{n-1}  S_x (r)  \\
        &= -\frac{n^2}{r^{n+1}} \frac{1}{n} r^{n} S_x (r)  + \frac{n}{r}  S_x (r) ds = -\frac{n}{r^{n}} S_x (r)  + \frac{n}{r}  S_x (r)  \\
        & \iff u(x) = S_x (r).
        \end{align*}
        The above shows that the mean on $\partial B_r (x)$ is equalt to $u(x)$. We have shown that $S^\prime (r)$ is the mean of $\Delta u$ on $B_r (x)$ and because $S(\cdot)$ is constant it follows
        \[
        S^\prime (r) = 0 \quad \iff \quad \int_{B_r (x)} \Delta u d^n y=0.
        \]
        Finally, $S(\cdot)$ is twice differentiable, because $u \in C^2(\Omega)$. \\
        We now want to show that $\Delta u \equiv 0$. For that, assume $\exists x \in \Omega$ such that $\Delta u(x) \neq 0$. Because $\Delta u$ is continuous 
        \[
        \forall \xi >0 \exists y \in B_\epsilon (x) : \quad |\Delta u (y) - \Delta u (x)| < \xi.
        \]
        Choose $\xi := \frac{|\Delta u (x)|}{2}.$ It follows
        \[
        |\Delta u (y) - \Delta u (x)| < \frac{|\Delta u (x)|}{2}.
        \]
        \begin{itemize}
            \item Case 1: $\Delta u(x) >0$\\
            \begin{align*}
                \Delta u(y) \geq \Delta (x) - |\Delta u (y) - \Delta u (x)|> \Delta u(x) - \frac{|\Delta u (x)|}{2} = \frac{\Delta u (x) }{2}>0.
            \end{align*}
            \item Case 2: $\Delta u(x) <0$\\
            \begin{align*}
                \Delta u (y) = \Delta u (X) - \Delta u (x) + \Delta u (y) < \Delta u(x) + |\Delta u (y) - \Delta u (x)| \leq \Delta u(x) + \frac{|\Delta u (x)|}{2} = \frac{\Delta u (x)}{2} <0.
            \end{align*}
        \end{itemize}
        In total it was shown that $\frac{|\Delta u (x)|}{2} >0$ and 
        \[
        \forall y \in B_\epsilon (x) : |\Delta u(y) | \geq \frac{|\Delta u (x) |}{2}.
        \]
        Ultimiately this leads to
        \[
        \left| \int_{B_r (x)} \Delta u (y) d^n y  \right| \geq \frac{|\Delta u (x) }{2} \int_{B_r (x) } d^n y > 0,
        \]
        which is a contradiction. Thus it follows that $\Delta u \equiv 0$.
        


        \textbf{(*)}\\

       \[
        D\phi_+ (z,x) = \begin{pmatrix}
            1 &0&\cdots & 0 &0 \\
            0 &1 &0 & \cdots \\
            \vdots & \ddots & && \vdots \\
            \frac{2|z|}{\sqrt{s^2 - |z|^2}} & \cdots & \frac{2|z|}{\sqrt{s^2 - |z|^2}} & \frac{s}{\sqrt{s^2 - |z|^2}}
        \end{pmatrix} = \begin{pmatrix}
            Id & && 0 \\
            \frac{2|z|}{\sqrt{s^2 - |z|^2}} & \cdots & \frac{2|z|}{\sqrt{s^2 - |z|^2}} & \frac{s}{\sqrt{s^2 - |z|^2}}
        \end{pmatrix}
        \]

        This yields
        \begin{align*}
        \det (D\phi_+ (z,x)) &= \frac{2|z|}{\sqrt{s^2 - |z|^2}} \det ( \begin{pmatrix}
            0 & \cdots & 0 \\
            &Id& 
        \end{pmatrix})
         + \cdots +\frac{2|z|}{\sqrt{s^2 - |z|^2}} \det (\begin{pmatrix}
            &Id& \\
            0 & \cdots & 0
        \end{pmatrix} ) + \frac{s}{\sqrt{s^2 - |z|^2}} \det (Id) \\
        &= \frac{s}{\sqrt{s^2 - |z|^2}}.
        \end{align*}
    }


    \cor{
        Let $u$ be a smooth harmonic function on an open domain $\Omega \subset \mathbb{R}^n$ and $B_r (x) $ with closure in $\Omega$. Then $\forall \alpha \in \mathbb{N}_0^n$ it holds that
        \[
        |\partial^\alpha u(x)| \leq C(n,|\alpha|) r^{-|\alpha|} \| u \|_{L^\infty (\overline{B_r (x)})}, \quad C(n,|\alpha|) = 2^{|\alpha| (1+ |\alpha|)} n^{|\alpha|}.
         \]
    }
    \pf{
        First, its clear that all partial derivatives of a harmonic function are harmonic again. We show the assertion via induction but only consider the induction start:
        \begin{align*}
            |\partial _i \partial^\alpha u (x)| &\stackrel{mean value}{=} | \frac{2^n}{\omega_n r^n} \int_{B_{r/2} (x)} \partial_i \partial^\alpha u d^n x | \\
            &\stackrel{Div.Thm.}{=} | \frac{2^n}{\omega_n r^n} \int_{\partial B_{r/2} (x)}  \partial^\alpha u N d \sigma  | \\
            & \leq | \frac{2^n}{\omega_n r^n}| \| \partial^\alpha u \|_{L^\infty (\partial B_{r/2}(x))} |\overbrace{\int_{\partial B_{r/2} (x)}  \underbrace{1_{n-1} N}_{=1} d \sigma}^{= n \omega_n (r/2)^{n-1} }  | \\
            &= \| \partial^\alpha u \|_{L^\infty (\partial B_{r/2}(x))} \frac{2n}{r}, \quad \forall i=1,...,n.
        \end{align*}
        This shows the assertion for $|\alpha|=1$, i.e. the induction start is $C(n,1)=2n$.
    }
    \thm{Liouvilles}{
        On $\mathbb{R}^n$ a bounded harmonic function is constant.
    }
    \pf{
        The previous corolarry has shown that a smooth (???) harmonic function is bounded in the following way
        \[
        |\partial^\alpha u (x) | \leq C(n,|\alpha|) r^{-|\alpha|} \| u \|_{L^\infty (\overline{B_r (x)})} .
        \]
        This goes to zero as $r \to \infty$, i.e. all partial derivatives of order $\alpha$ dissapear. Thus $u$ is constant.
    }
    We now want to transfer the mean value property to distributions. Let $u \in C^2 (\Omega)$ be harmonic, then $\forall B_r (x) \subset \Omega$ and $\psi \in C_0^\infty (\Omega)$ it holds 
    \begin{align*}
        &\int_{B_r (x)} u(y) \frac{\psi (|y-x|)}{n |y-x|^{n-1} \omega_n} d^n y = \int_0^r \int_{\partial B_s (x)} u(y) \frac{\psi (|y-x|)}{n |y-x|^{n-1} \omega_n} d \sigma (y) ds \\
        &= \int_0^r \frac{\psi (s)}{n s^{n-1} \omega_n} \int_{\partial B_s (x)} u(y) d \sigma (y) ds = \int_0^r \psi (s) u(x) ds = u(x) \int_0^r \psi (s) ds.
    \end{align*}

\thm{Weak Mean Value Property}{
    Let $U \in \mathcal{D}^\prime (\Omega)$ be a harmonic distribution on an open domain $\Omega \subset \mathbb{R}^n$. For each ball $B_r (x) \subset \Omega$ and each $\psi \in C_0^\infty ((0,r))$ with $\int_0^r \psi d\mu =0$ the distribution $U$ vanishes on the followsing test function $f \in C_0^\infty (\Omega)$ with 
    \[
    y \mapsto f(y) := \frac{\psi (|y-x|)}{n |y-x|^{n-1} \omega_n}, \quad supp \; f \subset B_r (x) \subset \Omega,
    \]
    i.e. $U_f =0$.
}

\pf{
    Due to the fact that $U$ is harmonic it holds that 
    \[
    0= (\Delta U)_g = U_{\Delta g} = U_f,
    \]
    if we show that $\exists g \in C_0^\infty (\Omega)$ with $\Delta g =f$. \\
    Because by assumption $\psi$ is integrable ($\int_\Omega \psi d \mu = \int_0^r \psi d \mu =0$) there exists a $\Psi \in C_0^\infty ((0,r))$ such that $\Psi^\prime = \psi$. Now define 
    \[
    g(y) := v (|y-x|), \quad v(t) := \int_r^t \frac{\Psi (s)}{n s^{n-1} \omega_n} ds.
    \]
    This function has compact support in $B_r (x) \subset \Omega$, because of the following. As we defined $\Psi \in C_0^\infty ((0,r))$ it holds that $\Psi (s) =0$ for all $s \geq r$ and $\exists \epsilon >0$ such that $\Psi (s) =0$ for all $s \leq \epsilon$. Finally, we get that for $y \neq x$
    \begin{align*}
        &\Delta_y g(y) = \nabla_y \cdot \left( \frac{\partial}{\partial y_i} |y-x| v^\prime (y)  \right) = \nabla_y \cdot \frac{y-x}{|y-x|} v^\prime (y) \\
        &= \sum_{i=1}^n \left( \frac{1}{|y-x|} v^\prime (y) + v^{\prime \prime} (y) \frac{y_i-x_i}{|y-x|}  \right) \\
        &= \frac{n-1}{|y-x|} v^\prime (y) + v^{\prime \prime }(y) \\
        &=  \frac{n-1}{|y-x|} v^\prime (y) + \frac{\psi (s)}{n s^{n-1} \omega_n} + \frac{\Psi (s)}{n s^{n-1} \omega_n} \frac{1-n}{|y-x|} \\
        &= \frac{n-1}{|y-x|} v^\prime (y) + \frac{\psi (s)}{n s^{n-1} \omega_n} - \frac{\Psi (s)}{n s^{n-1} \omega_n} \frac{n-1}{|y-x|} \\
        &= \frac{\psi (s)}{n s^{n-1} \omega_n} = f(y).
    \end{align*}
}

\lem{}{
    On an open domain $\Omega \subset \mathbb{R}^n$ for each harmonic distribution $U \in \mathcal{D}^\prime (\Omega)$ there exists $u\in C^\infty (\Omega)$ harmonic such that $H=F_u$.
}
\pf{
    First, we shall find a $u$ as it was proposed in the lemma. For every $x \in \Omega$ choose a ball $B_r (x) \subset \Omega$ and a test function $\phi \in C_0^\infty ((0,r))$ with $\int_0^r \phi (s)ds =1$. Then we define 
    \[
    u(x) := u(g_x), \quad g_x (y) := \frac{\phi (|y-x|)}{n |y-x|^{n-1} \omega_n}.
    \]
Now we need to show that $u$ is well defined, i.e. independent of the choice of $r$ and $\phi$. For that define 
\[
g_{x,1} (y) := \frac{\phi_1 (|y-x|)}{n |y-x|^{n-1} \omega_n}, \quad g_{x,2} (y) := \frac{\phi_2 (|y-x|)}{n |y-x|^{n-1} \omega_n}, 
\]
for $\phi_1 \in C_0^\infty ((0,r_1))$ and $\phi_2 \in C_0^\infty ((0,r_2))$. We want to show that $U(g_{x,1})= U(g_{x,2})$ which is equivalent by linearity to $U(g_{x,1}-g_{x,2})=0$. For ease of notation define 
\[
f(y) := \frac{\phi_1 (|y-x|)- \phi_2 (|x-y|) }{n |y-x|^{n-1} \omega_n}.
\]
Thus we need to show that $U(f)=0$, where $\phi := \phi_1 -\phi_2$. We do this by showing that the conditions from the mean value theorem are satisfied. It holds that 
\[
\int_0^{\max {r_1,r_2}} \phi ds = \int_0^{r_1} \phi ds - \int_0^{r_2} \phi_2 ds = 1-1=0.
\]
Thus $u$ is independent from $\phi$ and $r$. Additionally it holds that 
\[
g_x (y) = g_0 (y-x) = (T_x g_0 ) (y)
\]
which leads to 
\[
u(x) = U(g_x) = U(T_x g_0 ) = U (t_x P g_0) = (g_0 * U )(x)
\]
due to the fact that $g_0(\cdot)$ is symmetric, i.e. $g_0 = P g_0$. Thus because we can write any distribution as a function
\[
g * F: \mathbb{R}^n \to \mathbb{R}^n, \quad x \mapsto F(T_x P g)
\]
that is in $C^\infty$ it follows that $u$ is smooth.\\
Next, we show that the distribution $\tilde{U}=F_u$ satisfies the weak Mean value property. With the above $\tilde{U} =F_u = g_0 * U$???\\

Note that the function that we characterized in the mean value property theorem satisfies the following three properties
\begin{itemize}
    \item [1.] It only depends on the distance $|y-x|$ to the center $x \in \Omega$
    \item  [2.] $supp \; f \subset B_x (r)$
    \item [3.] $U(f)=0$
 \end{itemize}
 Clearly the first property is equivalent to $f$ is invariant under all rotains around the center. Remember that we have shown that for two functions $f$ and $g$ that are rotationally symmetric around $a$ and $b$ repsectively (i.e. for any orthonagonal transformation $O \in O(n,\mathbb{R})$ it holds $f(a+b)=f(a+Ox)$) follows 
 \[
 (f * g) (a+b+x) = (f*g) (a+b+Ox),
 \]
 i.e. rotationally symmetric wrt. $a+b$. Thus, if we take $g_0 * f$ it is rotationally symmetric around the same center as $f$, because $g_0$ is rotaionally symmetric around $0$.\\
 Since $\phi \in C_0^\infty ((0,r))$ the function
 \[
 f(y) = \frac{\phi (|y-x|)}{n |y-x|^{n-1} \omega_n}
 \]
 vanishes on for all $y \in B_\epsilon^n (\epsilon)$, if we choose $\epsilon>0$ small enough. \\
 Note that we used different test functions for $f$ and $g_0$. For the first we have $\psi \in C_0^\infty ((0,r))$ with $\int \psi d\mu=0$ and for the second we have $\phi \in C_0^\infty ((0,r))$ with $\int \phi d \mu =1$. If $g_0$ has its support on $B_\xi (0)$ with $\xi < \epsilon$ then $supp \; B_\xi (x)$. This and the fact that $\int_\Omega \phi (x) \psi (y-x) d\mu =0$ gives us all the conditions we need to to use the weak mean value property in order for the following calculation
 \[
 \tilde{U} (f) = (g_0 * U) (f) = U (f*Pg_0) = U(f* g_0) =0.
 \]
 Thus, $\tilde{U}$ satisfies the weak mean value property.\\
 The next step is to show that $u$ is harmonic.\\
 Let $\phi_\epsilon \in C_0^\infty (\mathbb{R})$ be a mollifier. Because $B_r (x)$ has compact closure in $\Omega$ $\exists R>r$ such that $B_R (x) \subset \Omega$. Further, for any $0<r_1<r_2 < R$ and $\epsilon>0$ small enough the function
 \[
 \varphi (t) := \phi_\epsilon (t-r_1) - \phi_\epsilon (t-r_2),
 \]
 has compact support in $(0,R)$ and a vanishing integral
 \[
 \int \varphi(t) d \mu = \int \phi_\epsilon (t-r_1) d \mu - \int \phi_\epsilon (t-r_2) d \mu  =1-1=0.
 \]
 We define
 \[
 f_x^\epsilon (y) := \frac{\varphi (|y-x|)}{n|y-x|^{n-1} \omega_n}, \quad y \in B_\epsilon (x).
 \]
For sufficiently small $\epsilon >0$ $f_x^\epsilon$ has compact support in $\Omega$ and is symmetric wrt. $x$. Since satisfies all the conditions from the weak mean value theorem, as $\epsilon \to 0$, it follows that with
\begin{align*}
   0\leftarrow \tilde{U} (f_x^\epsilon) &= \int_\Omega u(y) f_x^\epsilon (y) dy = \int_\Omega u(y)\frac{\varphi (|y-x|)}{n|y-x|^{n-1} \omega_n} dy \\
    &= \frac{1}{n\omega_n} \int_{B_\epsilon (x) } u(y) \frac{\varphi (|y-x|)}{|y-x|^{n-1} } dy = \frac{1}{n\omega_n} \int_0^\epsilon \int_{\partial B_r (x) } u(y) \frac{\varphi (|y-x|)}{|y-x|^{n-1} } d\sigma ( y)  dr\\
    &= \int_0^\epsilon \varphi (r) \frac{1}{nr^{n-1}\omega_n} \int_{\partial B_r (x) } u(y)  d\sigma ( y)  dr \\
    &= \int_0^\epsilon \varphi (r) S_x (r)  dr \\
    &= \int_0^\epsilon \phi_\epsilon (r-r_1) S_x (r)  dr  - \int_0^\epsilon \phi_\epsilon (r-r_2) S_x (r)  dr  \\
    & \to  S_x (r_1) -  S_x (r_2), \quad \epsilon \to 0.
\end{align*}
we get $0=S_x (r_1 ) - S_x (r_2)$. In the limit we have
\[
S_x (r_1) = S_x (r_2)  \to u(x), t \to 0.
\]
Thus $u$ satisfies the mean value property and is thus equivalently harmonic.\\
Finally, we show that $U = \tilde{U}$. For that define
\[
\eta (t) := \phi_{\epsilon/3} (t- \frac{2}{3} \epsilon), \quad \text{ has support }(\epsilon/3,\epsilon)
\]
and $\int \eta d \mu =1$. Define the mollifier
\[
f_x^{\eta,\epsilon} (y) := \frac{\eta (|y-x|)}{n |y-x|^{n-1} \omega_n}.
\]
Then $(f_0^{\eta,\epsilon} (\cdot ))_{\epsilon \geq 0}$ is a sequence of smooth mollifiers. It then finally follows with $W := \tilde{U} - U$ that for any test function $\psi \in C_0^\infty (\mathbb{R}^n)$: 
\begin{align*}
    &\tilde{U}(\psi) = \lim_{\epsilon \to 0} \tilde{U} (\psi * f_0^{\eta, \epsilon}) = \lim_{\epsilon \to 0} \int_\Omega u(y) (\psi (y) * f_0^{\eta, \epsilon} )(y) dy \\
    &= \lim_{\epsilon \to 0} \int_\Omega u(y) \int_\Omega \psi (x)  f_0^{\eta, \epsilon} (y-x) dx dy \\
    &= \lim_{\epsilon \to 0} \int_\Omega \psi (x) \int_\Omega  u(y) f_0^{\eta, \epsilon} (y-x)  dy dx \\
    &= \lim_{\epsilon \to 0} \int_\Omega \psi (x) \tilde{U} (f_x^{\eta,\epsilon} ) dx \\
    &= \int_\Omega \psi (x) u(x) dx \\
    &= \int_\Omega \psi (x) U(g_x) dx \\
    &= \lim_{\epsilon \to 0} \int_\Omega \psi (x) U(f_x^{\eta,\epsilon} ) dx \\
    &= \lim_{\epsilon \to 0} \int_\Omega \psi (x) U(f_0^{\eta,\epsilon} (\cdot -x) ) dx \\
    &= \lim_{\epsilon \to 0} \psi * U(f_0^{\eta,\epsilon}  ) \\
    &= \lim_{\epsilon \to 0}  U(\psi *f_0^{\eta,\epsilon}  ) = U(\psi)
\end{align*}
Although we used that for a mollifier $(\lambda_\epsilon)_{\epsilon \geq 0}$ it holds
\[
\lim_{\epsilon \to 0} \psi * \lambda_\epsilon = \psi, \quad \psi \in C_0^\infty (\mathbb{R}^n).
\]

}


\thm{Harnack}{
    Let $\Omega^\prime$ be an open path-connected domaina, i.e.
    \[
    \forall x,y \in \Omega^\prime \exists \gamma : [0,1] \to \Omega^\prime \text{ continuous: } \gamma(0) =x \text{ and } \gamma (1) =y, 
    \]
    with compact closure in the open domain $\Omega \subset \mathbb{R}^n$. Then there exists $C(\Omega,\Omega^\prime) >0$ such that any non-negative harmonic function $u$ on $\Omega$ satisfies 
    \[
    \sup_{x \in \Omega^\prime} u(x) \leq C \inf_{x \in \Omega^\prime u(x)}
    \]
    and
    \[
    \forall x,y \in \Omega^\prime: \frac{1}{C} u(y) \leq u (x) \leq C (y).
    \]
}
\pf{
    Let $\Omega^\prime$ be an open domain that is path connected and has compact slosure in the open domain $\Omega \subset \mathbb{R}^n$. Define
    \[
    g(x) := \inf_{y \in \partial \Omega} \| y -x \|
    \]
    Since $\bar{\Omega}^\prime$ is compact in $\Omega$ it is disjoint from $\partial \Omega$ which implies that $g>0$. Let
    \[
    r:= \frac{1}{2} \min_{x \in \bar{\Omega}^\prime} g(x).
    \]
    By construction it holds that for any $x \in \bar{\Omega}^\prime$ we have $B_{2r} (x) \subset \Omega$. Next, let $x,y \in \Omega^\prime$ be arbitrary with $\| x-y \| <r$. It the follows that for any $ z \in B_r (y)$ it holds
    \[
    \| z - x \| \leq \| z -y \| + \| y - x \| <2r.
    \]
    Thus $B_r (y) \subset B_{2r} (x)$. Since $u$ is harmonic and non-negative it follows 
    \[
    u(x) = \frac{1}{2^n r^n \omega_n} \int_{B_{2r} (x)} u d \mu  \geq \frac{2^{-n}}{ r^n \omega_n} \int_{B_{r} (y)} u d \mu = 2^{-n} u (y)
    \]
    holds for all $x,y \in \Omega^\prime$ with $\| x-y \| <r$.\\
    As we have required $\bar{\Omega}^\prime$ to be compact, i.e. meaning that there exists a cover of finite many balls $B_1,...,B_N$ with radii $\frac{r}{2}$ with
    \[
    \forall k=1,...,N-1: B_{k+1} \cap B_k \neq \emptyset.
    \]
    Let $B_k := B_{r/2} (x_k)$, then $\forall z_k \in B_{k+1} \cap B_k$ holds
    \[
    \| x_k - z_k \| + \| z_k - x_{k+1} \| < \frac{r}{2} + \frac{r}{2} =r,
    \] 
    which implies that $B_{r} (x_{k+1} ) \subset B_{2r} (x_k)$. Thus, for all $k=1,...,N-1$:
    \[
    u(x_k) = \frac{1}{2^n r^n \omega_n} \int_{B_{2 r} (x_k)} u d \mu \geq \frac{2^{-n}}{ r^n \omega_n} \int_{B_{ r} (x_{k+1})} u d \mu = 2^{-n} u(x_{k+1})
    \]
    which is equivalent to $2^n u(x_k) \geq u(x_{k+1})$. Doing this $N$ times yields
    \[
    u(x_N) \leq ... \leq 2^{n(N-1)} u(x_1).
    \]
    Now choose $x,y \in \Omega^\prime$ arbitrary and the cover in such a way that $x \in B_{r/2} (x_1)$ and $y \in B_{r/2} (x_N)$. Because $\Omega^\prime$ is path connected there exist a sequence of open balls $B_{k_1},...,B_{k_n}$ that connect these points. For ease of notation let $k_1 =1$ and $k_n := N$. Then it follows that  
    \[
    \| x - x_1 \| < \frac{r}{2} < r \implies B_{r/2} (x_1) \subset B_r (x) \implies 2^n u(x) \geq u(x_1).
    \]
    and
    \[
    \| y - x_N \| < \frac{r}{2} < r \implies B_{r/2} (y) \subset B_r (x_N) \implies 2^n u (x_N) \geq u(y)
    \]
    which finally leads to 
    \[
    u(y) \leq 2^n u(x_N) \leq ... \leq 2^{nN} u(x_1) \leq 2^{n(N+1)} u(x).
    \]
    As the above holds for arbitrary $x,y \in \Omega^\prime$ and its an open set the following immediatly follows
    \[
    \sup_{x \in \Omega^\prime } u(x) \leq 2^{n(N+1)} \inf_{x \in \Omega^\prime} u(x).
    \]

}

\lem{Harnack's Principle}{
    On an open and path connected domain $\Omega \subset \mathbb{R}^n$ a monotone sequence of harmonic functions $(u_n)_{n \in \mathbb{N}}$ converges uniformly on all compact subsets $\Omega^\prime \subset \Omega$, i.e.
    \[
    \exists u \forall \epsilon >0 \exists N \in \mathbb{N} \forall n \geq N, x \in \Omega^\prime: \quad |u_n (x) - u(x) |< \epsilon,
    \]
    if and only if 
    \[
    \exists x \in \Omega: (|u_n (x) |)_{n \in \mathbb{N}} \text{ is bounded.}
    \]
}
\pf{
    "$\Rightarrow$": \\
    Let $(u_n)_{n \in \mathbb{N}}$ be uniformly convergent on every compact subset $\Omega^\prime \subset \Omega$. Then with analysis it follows $(u_n(x))_{n \in \mathbb{N}}$ converges for all $x \in \Omega$. Pointwise convergence implies boundedness.\\
    "$\Leftarrow$": \\
    Let $(|u_n (x)|)_{n \in \mathbb{N}}$ be bounded for a $x \in \Omega$. By assumption it is monotone. Boundedness an monotonicity imply pointwise convergence, i.e. $(u_n (x))_{n \in \mathbb{N}}$ converges. To show uniform convergence on $\Omega^\prime$, we need to show that $(u_n)_{n \in \mathbb{N}}$ is uniformly a chauchy sequence on $\Omega^\prime$. Because $\Omega$ is a domain 
    \[
    \exists \Omega^{\prime \prime}: \Omega^\prime \subset \Omega^{\prime \prime} \subset \Omega, \text{ with } x \in \Omega^{\prime \prime}.
    \]
    Define $v_{n,m} (x) := u_n (x) - u_m (x)$, which is harmonic and non negative, because $(u_n)_{n \in \mathbb{N}}$ is non-negative. Thus Harnacks inequality implies that 
    \[
    \sup_{y \in \Omega^{\prime \prime}} v_{n,m} (y) \leq C \inf_{y \in \Omega^{\prime \prime}} v_{n,m} (y).
    \]
    which implies for all $y \in \Omega^{\prime \prime}$:
    \[
    v_{n,m} (y) \leq C \inf_{y \in \Omega^{\prime \prime}} v_{n,m} (y).
    \]
    Due to the fact that $x \in \Omega^{\prime \prime}$ it follows also that for all $y \in \Omega^{\prime \prime}$:
    \[
    v_{n,m} (y) \leq C  v_{n,m} (x).
    \]
    Finally, due to $\Omega^\prime \subset \Omega^{\prime \prime}$ it follows 
    \[
    \sup_{y \in \Omega^{\prime}} v_{n,m} (y) \leq C  v_{n,m} (x).
    \]
    Now due to the fact that $(u_n (x))_{n \in \mathbb{N}}$ is a convergent sequence, it is a cauchy sequence, i.e. 
    \[
    \forall \epsilon >0 \exists N \in \mathbb{N} \forall n \geq m \geq N: \quad u_n (x) - u_m (x) = v_{n,m} (x) < \frac{\epsilon}{C}.
    \]
    Thus 
    \[
   \forall \epsilon >0 \exists N \in \mathbb{N} \forall n \geq m \geq N: \quad \sup_{y \in \Omega^{\prime}} v_{n,m} (y) \leq C  v_{n,m} (x) < \epsilon,
    \]
    which is the uniform cauchy criterion on $\Omega^\prime$.
}


\section{Maximum Principle}
\thm{Strong Maximum Principle}{
    Let $u$ be harmonic on a path-connected open domain $\Omega \subset \mathbb{R}^n$ and taking its maximum. Then $u$ is constant.
}
\pf{
Let $u$ be a harmonic function that takes its maximum at $x \in \Omega \subset \mathbb{R}^n$ on an open path connected domain. The MVP implies 
\[
\forall y \in B_r (x) \subset \Omega: \quad \frac{1}{r^n \omega_n} \int_{B_r (x)} |u(x) - u (y)| d^n y \stackrel{Max.}{=}\frac{1}{r^n \omega_n} \int_{B_r (x)} u(x) - u (y) d^n y \stackrel{MVP}{=} 0.
\]
Hence $u$ is constant on $B_r (x)$, i.e. $\forall y \in B_r (x): \max_{z \in \Omega} u(z) = u(y)=:M$.\\
Define $A:= \{ z \in \Omega \mid u(z) = M \}$. We have shown in the above that $A \neq \emptyset $ because $B_r (x) \subset A$. We will show that $A$ is closed and open and non-empty. This implies due to (*) that $A = \Omega$. \\
Closed: Because the preimage of closed sets for continuous functions is again closed it follows that $u^{-1} (\{M\})=A$ is closed.\\
Open:  Let $a \in A$ be arbitrary. Since $\Omega$ is open there exists $r>0$ such that $B_r (a) \subset \Omega$. Due to the fact that $a \in A$ it follows that $u(a)=M$ is the global maximum. With the arguments above it follows that 
\[
\forall y \in B_r (a) \subset \Omega: \quad \frac{1}{r^n \omega_n} \int_{B_r (a)} |u(a) - u (y)| d^n y \stackrel{Max.}{=}\frac{1}{r^n \omega_n} \int_{B_r (a)} u(a) - u (y) d^n y \stackrel{MVP}{=} 0.
\]
Hence $u$ is constant on $B_r (a)$. As $a \in A$ was arbitrary it follows that $A$ is open.\\
All the above arguments imply that $u$ is constant on $\Omega$ where it takes its maximum.\\
(*): $\Omega$ is path connected implies $\Omega$ is connected, which is defined as 
\[
\nexists B,C \neq \emptyset \text{ open with } B \cap C = \emptyset \text{ and } \Omega = B \cup C.
\]
Since $A$ is closed it follows that $A^C$ is open. Because $\Omega = A \cup A^C$ and $\Omega$ is connected one of the sets has to be empty. As $A \neq \emptyset$ it follows $A^C = \emptyset$.
}
\thm{Weak Maximum Principle}{
    Let $u$ be harmonic on a bounded open domain $\Omega \subset \mathbb{R}^n$ that extends continuously to $\partial \Omega$. THen maximum of $u$ is then taken on $\partial \Omega$.
}
\pf{
Because $\Omega$ is bounded it follows that $\bar{\Omega} = \Omega \cup \partial \Omega$ is closed and bounded, which implies with Heine Borel that $\bar{\Omega}$ is compact. A continuous function on a compact set attains its maximum value $M$ at some point $x \in \bar{\Omega}$. There are now two cases:
\begin{itemize}
    \item Case 1: If $x \in \partial \Omega$ the assertion is shown.
    \item Case 2: If $x \in \Omega$ the strong Maximum Principle can be applied an yields that $\forall z \in \Omega: u(z) =M$. Because $U$ extends continuously to $\partial \Omega$ it follows that also $\forall y \in \partial \Omega$: $u(y) = M$. 
\end{itemize}
In both cases the maximum is attained on $\partial \Omega$.
}
Since $-u$ is again harmonic if $u$ is, the strong and weak minimum principle immediatly follows. We will now generalise the Maximum principle.
\thm{}{
    Let $L$ be an elliptic differntial operator on a bounded open domain $\Omega \subset \mathbb{R}^n$ with coefficients $a_{i,j},b_i$ extending continuously and ellipticly to $\partial \Omega$. Then every twice differentiable solution $u\in C^2$ of $L u \geq 0$ that extends continuously to $\partial \Omega$ takes its maximum on $\partial \Omega$.
}
\pf{
    Because the coefficients are continuos the function $g: (x,k) \mapsto \sum_{i,j=1}^n a_{ij} (x) k_i k_j$ is contious on the compact set $\bar{\Omega} \times S^{n-1} \subset \bar{\Omega}\times \mathbb{R}^n$. A continuous function attains its minimum on compact sets. Thus $g$ attains its minimum $\lambda >0$, as $L$ is elliptic, this minimum is positve. This implies uniform ellipticity.\\
    Define $v(x) := e^{x_1 \alpha}, \alpha >0, x=(x_1,...,x_n)$, then with uniform ellipticity we get that 
    \[
    Lv = \alpha (\alpha a_{11} (x) + b_1 (x)) v(x) \geq \alpha (\alpha \lambda + b_1 (x)) v >0,
    \]
    for $\alpha>0$ large enough, because $b_i$ are bounded and continuous on $\bar{\Omega}$ and $\lambda >0$. With linearity it follows for all $\epsilon >0$ that 
    \[
    L (u+ \epsilon v) = \underbrace{L u}_{\geq 0} + \underbrace{\epsilon Lv}_{>0} >0, \text{ on } \Omega \forall \epsilon >0.
    \]
    To show: $w_\epsilon := u + \epsilon v$ cannot have an interior maximum.\\
    Assume $w_\epsilon$ attains its maximum at some $x \in \Omega$. Since $w_\epsilon \in C^2$ it clearly holds that 
    \begin{itemize}
        \item $\nabla w_\epsilon (x_0)=0$
        \item The Hessian $H w_\epsilon (x_0)$ is negative semi-definit, i.e. all eigenvalues $\mu_1,...,\mu_n$ are non-positive.
    \end{itemize}
    Then there exists $B \in O(n)$ orthogonal such that $H W_\epsilon (x_0) = B^T \begin{pmatrix}
        \mu_1 &&\\
        &\ddots &\\
        && \mu_n
    \end{pmatrix} B$. Using this we can now reformulate the differential operator.
    \begin{align*}
        L w_\epsilon (x_0) &= \sum_{i,j=1}^n a_{ij} (x_0) \frac{\partial^2 }{\partial x_i \partial x_j} w_\epsilon (x_0)  + \sum_{i=1}^n b_i (x_0) \cdot 0 \\
        &= trace (A(x_0) Hw_\epsilon (x_0)) = trace (A(x_0) B^T \begin{pmatrix}
        \mu_1 &&\\
        &\ddots &\\
        && \mu_n
    \end{pmatrix} B) \\
    &= \sum_{i,j=1}^n a_{ij} (x_0) \sum_{k=1}^n \mu_k b_{ki} b_{kj} \\
    &= \sum_{k=1}^n  \underbrace{\mu_k}_{\leq 0}  \underbrace{\sum_{i,j=1}^n a_{ij} (x_0)  b_{ki} b_{kj}}_{ \geq \lambda >0} \leq 0
    \end{align*}
    which is a contradiction. Thus $L w_\epsilon$ attains its maximum on $\partial \Omega$. Then 
    \begin{align*}
       & \sup_{x \in \bar{\Omega}} u(x) + \epsilon \inf_{x \in \bar{\Omega}} v(x) \leq \sup_{x \in \bar{\Omega}} (u(x) + \epsilon v(x)) \stackrel{above}{=} \max_{x \in \partial \Omega} (u(x) + \epsilon v(x)) \leq \max_{x \in \partial \Omega} u(x) + \epsilon \max_{x \in \partial \Omega} v(x) \\
       & \iff \sup_{x \in \bar{\Omega}} u(x)  \leq  \max_{x \in \partial \Omega} u(x) + \epsilon (\underbrace{\max_{x \in \partial \Omega}v(x) -\inf_{x \in \bar{\Omega}} v(x)}_{= const. } ).
    \end{align*}
    Due to the fact that $\epsilon >0$ was chosen arbitrary it follows that 
    \[
    \sup_{x \in \bar{\Omega}} u(x) = \max_{x \in \partial \Omega} u(x) .
    \]
}
With the same proof idea one can show that $Lu \leq 0$ implies that $u$ takes its minima on the boundary. Note that if $Lu =0$ holds then both minima and maxima are on the boundary.

\section{Green's Function}
Now we want to find conditions that ensure the existence and uniqueness of harmonic functions on path-connected, open and bounded domains $\Omega \subset \mathbb{R}^n$. We will introduce boundary value problems, that means the harmonic function or some of its derivatives extend continuously to the boundary and coincide with some function on $\partial \Omega$.
\defn{}{
    We call $u$ m-times differentiable on $\bar{\Omega}$ if it is m-times continuousyl differentiable on $\Omega$ and all partial derivates of order of at most $m$ extend continuously to $\partial \Omega$.
}

\lem{Greens First Formula}{
    Let the divergence theorem hold true on an open and bounded domain $\Omega \subset \mathbb{R}^n$. Then for two $u,v \in C^2 (\bar{\Omega})$ it holds
    \[
    \int_\Omega v(y) \Delta u(y) d^n y + \int_\Omega \nabla v(y) \nabla u(y) d^n y= \int_\Omega (v(y) \nabla u(y))^\prime d^n y= \int_{\partial \Omega} v(z) \nabla u(z) \cdot N d \sigma (z).
    \]
}
If we subtract the above by itself, while exchanging the role of $u$ and $v$ we get the second Formula.
\lem{Greens Second Formula}{
    Let the divergence theorem hold true on an open and bounded domain $\Omega \subset \mathbb{R}^n$. Then for two $u,v \in C^2 (\bar{\Omega})$ it holds
    \begin{align*}
        &\int_\Omega v(y) \Delta u (y) d^n y + \int_\Omega \nabla v (y) \nabla u(y) d^n y - \int_\Omega \Delta v(y) u (y) d^n y - \int_\Omega \nabla v(y) \nabla u(y) d^n y \\
        &= \int_{\partial \Omega } v(z) \nabla (z) N d\sigma (z) - \int_{\partial \Omega} u (z) \nabla v(z) N d \sigma (z) \\
        & \iff \int_\Omega v(y) \Delta u (y)-\Delta v(y) u (y) d^n y =  \int_{\partial \Omega } (v(z) \nabla (z) - u (z) \nabla v(z) )N d \sigma (z) 
    \end{align*}
}
\thm{Greens Representation Theorem}{
Let the divergence theorem hold true on an open and bounded domain $\Omega \subset \mathbb{R}^n$. THen for two $u,v \in C^2 (\bar{\Omega})$ it holds
\[
 u(x) = -\int_{\Omega }  \Phi (x-y) \Delta u(y) d^n y + \int_{\partial \Omega} (  \Phi (x-y) \nabla u(y) - u(y) \nabla_y \Phi (x-y)) N d\sigma (y) 
\]
}
\pf{
With the second Greens Identity it holds 
\[
\int_{\Omega \setminus B_\epsilon (x)} u(y) \Delta \Phi (x-y) - \Phi (x-y) \Delta u(y) d^n y= \int_{\partial (\Omega \setminus B_\epsilon (x))} (u(y) \nabla_y \Phi (x-y) - \Phi (x-y) \nabla u(y)) N d\sigma (y).
\]
Because $\Phi (x-\cdot)$ was constructed to be the solution of $-\Delta u =0$ for $x \neq y$ it follows that the above is equivalent to
\begin{align*}
&- \int_{\Omega \setminus B_\epsilon (x)}  \Phi (x-y) \Delta u(y) d^n y= \int_{\partial (\Omega \setminus B_\epsilon (x))} (u(y) \nabla_y \Phi (x-y) - \Phi (x-y) \nabla u(y)) N d\sigma (y) \\
&= \int_{\partial \Omega} (u(y) \nabla_y \Phi (x-y) - \Phi (x-y) \nabla u(y)) N d\sigma (y) + \underbrace{\int_{\partial B_\epsilon (x)} (u(y) \nabla_y \Phi (x-y) - \Phi (x-y) \nabla u(y)) N d\sigma (y)}_{=: K_\epsilon}.
\end{align*}
Due to construction it follows $\Phi (x-y) \in \mathcal{O}(|x-y|^{2-n}), y \to x$, $\nabla u \cdot N$ is bounded and $\int_{\partial B_\epsilon (x)} d\sigma (y) \in \mathcal{O}(\epsilon^{n-1})$ which yields
\[
\lim_{\epsilon \to 0} \int_{\partial B_\epsilon (x)} \Phi (x-y) \underbrace{\nabla (y) N}_{\leq const.} d \sigma (y) \leq \lim_{\epsilon \to 0} \epsilon^{2-n} const. \int_{\partial B_\epsilon (x)} d \sigma (y) = \lim_{\epsilon \to 0} \epsilon =0.
\]
Using this and the fact that $\nabla \Phi (y) = - \frac{1}{n \omega_n} \frac{y}{|y|^n}$ and $N= - \frac{x-y}{|x-y|}$ we get that 
\begin{align*}
    \lim_{\epsilon \to 0} K_\epsilon &= \lim_{\epsilon \to 0} \int_{\partial B_\epsilon (x)} u(y) \nabla_y \Phi (x-y) N d \sigma (y) \\
    &= - \lim_{\epsilon \to 0} \int_{\partial B_\epsilon (x)} u(y) \frac{1}{n \omega_n} \frac{x-y}{|x-y|^n} N d \sigma (y) \\
    &=  \lim_{\epsilon \to 0} \frac{1}{n \omega_n} \frac{\epsilon }{|\epsilon |^n} \int_{\partial B_\epsilon (x)} u(y)  \frac{x-y}{|x-y|} d \sigma (y) \\
    &= \lim_{\epsilon \to 0} \frac{1}{n \omega_n} \frac{\epsilon^2 }{|\epsilon |^{n+1}} \int_{\partial B_\epsilon (x)} u(y)   d \sigma (y) \\
    &=  \lim_{\epsilon \to 0} \frac{1}{n \omega_n} \frac{1 }{|\epsilon |^{n-1}} \int_{\partial B_\epsilon (x)} u(y)   d \sigma (y)= \lim_{\epsilon \to 0} S_x (\epsilon) = u(x).
\end{align*}
Thus in total we have 
\begin{align*}
& u(x) = -\int_{\Omega }  \Phi (x-y) \Delta u(y) d^n y - \int_{\partial \Omega} (u(y) \nabla_y \Phi (x-y) - \Phi (x-y) \nabla u(y)) N d\sigma (y) \\
& \iff u(x) = -\int_{\Omega }  \Phi (x-y) \Delta u(y) d^n y + \int_{\partial \Omega} (  \Phi (x-y) \nabla u(y) - u(y) \nabla_y \Phi (x-y)) N d\sigma (y) 
\end{align*}
}
\defn{Greens Function}{
    A function 
    \[
    G_\Omega : \{ (x,y) \in \Omega \times \Omega \mid x \neq y \} \to \mathbb{R},
    \]
    is called Greens function on the open domain $\Omega \subset \mathbb{R}^n$ if the following are satisfied 
    \begin{itemize}
        \item $\forall x \in \Omega$ the function $y \mapsto G_\Omega (x,y) - \Phi (x-y)$ is harmonic on $\Omega$
        \item $\forall x \in \Omega$ the function $y \mapsto G_\Omega (x,y)$ extends continuously to $\partial \Omega$ and vanishes on $\partial \Omega$.
    \end{itemize}
}
Note that if we use the Greens Representation theorem, the second Greens formula and define $v(y) :=   G_\Omega (x,y)-\Phi (x-y)$ (which is by definition a harmonic function) we get 
\begin{align*}
    u(x) &= - \int_\Omega \Phi (x-y) \Delta u(y) d^n y + \int_{\partial \Omega} (\Phi (x-z) \nabla u(z)- u (z) \nabla_z \Phi (x-z)) \cdot N d \sigma (z) \\
    &= - \int_\Omega (G_\Omega (x,y)-v(y) )\Delta u(y) d^n y + \int_{\partial \Omega} ((G_\Omega (x,z)-v(z) ) \nabla u(z)- u (z) \nabla_z (G_\Omega (x,z)-v(z) )) \cdot N d \sigma (z) \\
    &= - \int_\Omega \underbrace{\Delta v(y) u (y)}_{=0,v \text{ harmonic}} - v(y) \Delta u(y) d^n y - \int_{\partial \Omega} (u(z) \nabla v(z) - \nabla u (z) v(z)) N d \sigma (z) \\
    &-\int_{\Omega} G_\Omega (x,y) \Delta u (y) d^n y + \int_{\partial \Omega} (G_\Omega (x,z) \nabla u (z) - u (z) \nabla_z G_\Omega (x,z)) \cdot N d \sigma (z) \\
    &\stackrel{2.Greens}{=} 0 -\int_{\Omega} G_\Omega (x,y) \Delta u (y) d^n y + \int_{\partial \Omega} (G_\Omega (x,z) \nabla u (z) - u (z) \nabla_z G_\Omega (x,z)) \cdot N d \sigma (z) \\
    &\stackrel{Def.}{=} -\int_{\Omega} G_\Omega (x,y) \Delta u (y) d^n y - \int_{\partial \Omega} u (z) \nabla_z G_\Omega (x,z) \cdot N d \sigma (z) \\
    &\stackrel{Dirichlet}{=} \int_{\Omega} G_\Omega (x,y) f (y) d^n y - \int_{\partial \Omega} g (z) \nabla_z G_\Omega (x,z)  \cdot N d \sigma (z).
\end{align*}
Thus the solution of the Dirichlet problem satisfies for $f: \bar{\Omega} \to \mathbb{R}$ and $g: \partial \Omega \to \mathbb{R}$ sufficiently regular 
\[
u(x) = \int_{\Omega} G_\Omega (x,y) f (y) d^n y - \int_{\partial \Omega} g (z) \nabla_z G_\Omega (x,z)  \cdot N d \sigma (z).
\]
\rmkb{
    The homogeneous Dirichlet problem uniquely solves the inhomogenous Dirichelt problem up to translation: Let $u_1$ be the solution of the homogenuous Dirchletproblem and $u$ of the???\\
    The Dirichlet Problem reduces to the search of the Greens function.???
}
For $x \in \Omega$ the function $y \mapsto G_\Omega (x,y) - \Phi (x-y)$ is harmonic on $\Omega$ and on $\partial \Omega$ is equal to $- \Phi (x-y)$. This function is the solution of the Dirichlet Problem $f=0$ on $\Omega$ and $g(x) =- \Phi (x-y)$ on $\partial \Omega$. 
\thm{Symmetry}{
    If there exists a Greens function $G_\Omega$ for the domain $\Omega$ then 
    \[
    \forall x \neq y: \quad G_\Omega (x,y) = G_\Omega (y,x).
    \]
}
\pf{
    For $x \neq y \in \Omega$ and $\epsilon >0$ sufficiently small such that the balls $B_\epsilon (x), B_\epsilon (y) \subset \Omega$ are disjoint, the Greens function $G_\Omega$ is by definition harmonic on $\Omega_\epsilon := \Omega \setminus (B_\epsilon (x) \cup B_\epsilon (y))$. Note that in the definition of $\Omega_\epsilon$ the normal vector for the balls $\partial B_\epsilon (x)$ and $\partial B_\epsilon (y)$ respectively, is inward facing. To apply the Greens second Identiy, we need an outward facing vector. This is why we always need to multiply by $(-1)$ when we apply it in the following! Using Greends second Identity we get 
    \begin{align*}
        & \int_{\Omega_\epsilon} G_\Omega (x,z) \Delta G_\Omega (y,z) - G_\Omega (y,z) \Delta G_\Omega (x,z) d^n z =  \int_{\partial \Omega_\epsilon } ( G_\Omega (x,z) \nabla G_\Omega (y,z)-G_\Omega (y,z)\nabla G_\Omega (x,z))  \cdot N d \sigma (z) \\
        & \iff 0= \int_{\partial \Omega_\epsilon } (G_\Omega (y,z)\nabla G_\Omega (x,z) -G_\Omega (x,z) \nabla G_\Omega (y,z)) \cdot N d \sigma (z) \\
         & \iff 0= \int_{\partial \Omega \cup \partial B_\epsilon (x) \cup B_\epsilon (y) } (G_\Omega (y,z)\nabla G_\Omega (x,z)-G_\Omega (x,z) \nabla G_\Omega (y,z)) \cdot N d \sigma (z) \\
         & \stackrel{(*) }{\iff} 0= \int_{\partial B_\epsilon (x) \cup B_\epsilon (y) } (G_\Omega (y,z)\nabla G_\Omega (x,z)-G_\Omega (x,z) \nabla G_\Omega (y,z)) \cdot N d \sigma (z) \\
         & \iff -\int_{\partial B_\epsilon (y)} (G_\Omega (y,z)\nabla G_\Omega (x,z)-G_\Omega (x,z) \nabla G_\Omega (y,z)) \cdot N d \sigma (z) = \int_{\partial B_\epsilon (x)} (G_\Omega (y,z)\nabla G_\Omega (x,z)-G_\Omega (x,z) \nabla G_\Omega (y,z)) \cdot N d \sigma (z)
    \end{align*}
    Although we used in (*) that by definition the Greens function vanishes on $\partial \Omega$. Applying Greens second formula again yields 
     \begin{align*}
       & \lim_{\epsilon \to 0} \int_{\partial B_\epsilon (x)} \left(   G_\Omega(y,z) \nabla_z G_\Omega(x,z)-G_\Omega (x,z) \nabla_z G_\Omega(y,z) \right) N d \sigma (z) \\
       &= -\lim_{\epsilon \to 0} \int_{B_\epsilon (x)} G_\Omega(y,z) \Delta_z G_\Omega(x,z)- G_\Omega (x,z) \Delta_z G_\Omega(y,z)   d^n z \\
       &= -\lim_{\epsilon \to 0} \int_{B_\epsilon (x)}  G_\Omega(y,z) \Delta_z G_\Omega(x,z)  d^n z =-  \lim_{\epsilon \to 0} \int_{B_\epsilon (x)}  G_\Omega(y,z) (-\delta (x-z))  d^n z =  G_\Omega(y,x) 
     \end{align*}
     and in a similiar fashion 
     \begin{align*}
       &- \lim_{\epsilon \to 0} \int_{\partial B_\epsilon (y)} (G_\Omega (y,z)\nabla G_\Omega (x,z)-G_\Omega (x,z) \nabla G_\Omega (y,z)) \cdot N d \sigma (z)\\
       &= \lim_{\epsilon \to 0} \int_{ B_\epsilon (y)} G_\Omega (y,z)\Delta G_\Omega (x,z)-G_\Omega (x,z) \Delta G_\Omega (y,z)  d^n z\\
       &=- \lim_{\epsilon \to 0} \int_{B_\epsilon (y)} G_\Omega (x,z) \Delta G_\Omega (y,z)  d^n z \\
       &= - \lim_{\epsilon \to 0} \int_{B_\epsilon (y)}  G_\Omega(x,z) (-\delta (y-z))  d^n z =  G_\Omega(x,y) 
     \end{align*}
     Thus the assertion is shown.
}

We will now calculate Greens functions for $B_\epsilon (x) = \Omega \subset \mathbb{R}^n$. For now only consider the unit ball. Define the inversion in the unit spehre as 
\[
\tilde{x} : B_1 (0) \to \partial B_1 (0), x \mapsto \tilde{x}(x) := \frac{x}{|x|^2}.
\]
Later it will help us to solve the Dirichlet problem for $f=0$ and $g(x) = \Phi (x-y)$ ???.
\lem{Greens function on the unit Ball}{
    The Greens function on the unit Ball is given by 
    \[
    G_{B_1 (0)} (x,y) = \Phi (x-y) - \Phi (|x| (\tilde{x}(x)-y))= \begin{cases}
        \Phi (x-y) - |x|^{2-n} \Phi (\tilde{x}(x) -y), & n >2 \\
        \Phi (x-y) - \Phi (\tilde{x}(x)-y) - \Phi (x), & n =2
    \end{cases}
    \]
}
\pf{
    We want to show that $v(y) := G_\Omega (x,y) - \Phi (x-y)$ is harmonic. Define $v(y) := -\Phi (|x| (\tilde{x}(x)-y))$. Now the conditions of the Green function need to be shown under that definition. We first show that $y \mapsto G_{B_1 (0)} (x,y)$ vanishes on the boundary, i.e. for $y \in \partial B_1 (0)$:
    \begin{align*}
        |x|^2 |\tilde{x}(x) -y |^2 &=  |x|^2 \sum_{i=1}^n \left( \frac{x_i}{|x|^2} - y_i \right)^2 = \sum_{i=1}^n \left( \frac{x_i}{|x|^2} - 2 x_i y_i + y_i^2 |x|^2 \right) \\
        &= \frac{|x|^2}{|x|^2} - 2\sum_{i=1}^n x_i y_i + \underbrace{|y|}_{=1} |x|^2 = 1 -  2\sum_{i=1}^n x_i y_i+|x|^2  \\
        &= |y|^2 -  2\sum_{i=1}^n x_i y_i+|x|^2 = |x-y|^2 \\
        & \iff |x| |\tilde{x}(x) -y| = |x-y|
    \end{align*}
    Which implies that 
    \[
    \forall y \in \partial B_1 (0): \quad  G_{B_1 (0)} (x,y) = \Phi (x-y) - \Phi (|x| (\tilde{x}(x)-y)) =0.
    \]
    Next, in distribution it needs to be shown that $\Delta_y \Phi (|x| (\tilde{x}(x)-y))=0$ on $x,y \in B_1 (0)$. Note that 
    \begin{align*}
        \Phi (|x| (\tilde{x}(x)-y)) &= \begin{cases}
            - \frac{1}{2 \pi} (\log (|\tilde{x}(x)-y|) + \log (|x|) )&, n =2\\
            \frac{1}{n(n-2) \omega_n |\tilde{x}(x) -y|^{n-2}} \frac{1}{|x|^{n-2}} &,n >2
        \end{cases}
        \\
        &= \begin{cases}
            \Phi (\tilde{x}(x) - y) + \Phi (|x|) &,n=2 \\
            \Phi (\tilde{x}(x) -y) \frac{1}{|x|^{n-2}} &, n>2
        \end{cases}.
    \end{align*}
    We already have shown that $\Delta_y \Phi (x-y) = - \delta (x-y)$ and $\Delta_z \Phi (z) = - \delta (z)$. We will now show that $\Phi (|\cdot| (\tilde{x}(\cdot ) - y))$ has its singularity outside of $B_1 (0)$. This is the case because first for $x \in B_1 (0)$ it holds that $|x| <1$ which implies that 
    \[
    | \tilde{x}(x) | = |\frac{x}{|x|^2}| = \frac{1}{|x|} >1
    \]
    and second because 
    \[
    \Phi (|x| (\tilde{x}(x) -y)) \text{ singular } \iff y = \tilde{x}(x).
    \]
   Because by construction $\Phi$ has only on singularity and because $\tilde{x}(x) \notin B_1 (0)$ for $x \in B_1 (0)$ it follows that $-\Phi (|x| (\tilde{x}(x)-y)) = G_\Omega (x,y) - \Phi (x-y)$ is harmonic on $B_1 (0)$.
}


\thm{Poisson Represation Formula}{
    For $f \in C^2 (\overline{B_r (z)})$ and $g \in C(\partial B_r (z))$ the unique solution of the Dirichlet Problem on $\Omega = B_r (z)$ is given by 
    \[
    u(x) = \frac{1}{r^{n-2}} \int_{B_r (z)} G_{B_1 (0)} \left( \frac{x-z}{r}, \frac{y-z}{r} \right) f(y) d^n y + \frac{1- \frac{|x-z|^2}{r^2}}{n \omega_n} \int_{\partial B_1 (0)} \frac{g(z+ry)}{|\frac{x-z}{r}-y|^n} d \sigma (y).
    \]
}
\pf{
    Remember that we can decompose the Dirichlet probelm into two subproblem. 
    \begin{itemize}
        \item [1.] $- \Delta u =f $ on $\Omega $ and $u=0$ on $\partial \Omega$ (Poisson equation with homogeneuous boundary data)
        \item [2.] $\Delta u =0$ on $\Omega$ and $u=g$ on $\partial \Omega$ (Laplace equation with inhomogenous boundary data).
    \end{itemize}
    The affine map $\psi: \overline{B_r (z)} \to \overline{B_1 (0)}, x \mapsto \frac{x-z}{r}$ is a homomorphism from $B_r (z) $ to $B_1 (0)$ and also from $\partial B_r (z) $ onto $\partial B_1 (0)$. Further note that 
    \begin{align*}
        &r^{2-n} \Phi \left( \frac{x-z}{r} - \frac{y-z}{r} \right) - \Phi (x-y) \\
        &= r^{2-n} \frac{1}{n (n-2) \omega_n |\frac{x-z}{r}-\frac{y-z}{r}|^{n-2}}  - \frac{1}{n(n-2) \omega_n |x-y|^{n-2}} =0 
    \end{align*}
    vanishes for $n>2$ and for $n=2$ it is constant: 
    \begin{align*}
        &r^{2-n} \Phi \left( \frac{x-z}{r} - \frac{y-z}{r} \right) - \Phi (x-y) \\
        &= \frac{1}{2 \pi} \log (|\frac{x-z}{r}-\frac{y-z}{r}|) + \frac{1}{2 \pi} \log (|x-y|) \\
        &= \frac{1}{2 \pi} \left( \log (|x-y|) - \log (|r|) \right) + \frac{1}{2 \pi } \log (|x-y|) =\frac{1}{2 \pi} \log (|r|).
    \end{align*}
    Due to the fact $\Phi (rx) = r^{2-n} \Phi (x)$ we can write for $x,y \in B_r (z)$ the Greens function as 
    \begin{align*}
        G_{B_1 (0)} (\psi (x),\psi (y)) &= \Phi (\psi (x)-\psi (y)) - \Phi ( |\psi (x)| (\tilde{x}(\psi (x)) -\psi (y))) \\
        &= \frac{1}{r^{2-n}}  \Phi (x-z+z-y) - \frac{1}{r^{2-n}} \Phi ( |x-z| (\frac{x-z}{r|\psi (x)|^2} -y-z)) \\
        &= \frac{1}{r^{2-n}}  \Phi (x-y) -  \Phi ( |\frac{x-z}{r}| (\tilde{x}(\frac{x-z}{r}) -\frac{y-z}{r})) \\
        &= \frac{1}{r^{2-n}}  \Phi (x-y) -  \Phi (  |\frac{x-z}{r}| (\frac{x-z}{r|\frac{x-z}{r}|^2} -\frac{y-z}{r})) \\
        &= \frac{1}{r^{2-n}}  \Phi (x-y) -  \Phi ( |\frac{x-z}{r}| (r \frac{x-z}{|x-z|^2} -\frac{y-z}{r})) \\
        &= \frac{1}{r^{2-n}}  \Phi (x-y) -  \Phi ( \frac{1}{r} |\frac{x-z}{r}| (\underbrace{r^2 \frac{x-z}{|x-z|^2} + z}_{=: \tilde{x}_z^r (x) \in \partial B_r (z)}-y)) \\
        &= \frac{1}{r^{2-n}} \left( \Phi (x-y) - \Phi ( |x-z| (\tilde{x}_z^r (x-z) -y))  \right) = \frac{1}{r^{2-n}} G_{B_r (z)} (x,y).
    \end{align*}
    The above is equivalent to 
    \[
    G_{B_r (z)} (x,y) = r^{2-n} G_{B_1 (0)} ( \frac{x-z}{r}, \frac{y-z}{r} ).
    \]
    We now do the first subproblem. Here the solution of the Poisson equation $-\Delta u =f$ is given by 
    \[
    u(x) = \int_{B_r (z)} G_{B_r (z)} (x,y) f(y) d^n y -\underbrace{ \int_{\partial B_r (z)}  g(z) \nabla_z G_{B_r (z)} (x,z) N d \sigma (z)}_{=0},
    \]
    i.e. the solution of the homognenous possion equation differs by a constant term from the solution of the solution of the inhmomogenous Poission equation (???). By definition of the Greens function the limit to the boundary of the second term vanishes. By symmetry we can thus show that for all $x_0 \in \partial B_r (z)$:
    \[
        \lim_{x \to x_0} u(x)=  \lim_{x \to x_0}\int_{B_r (z)} G_{B_r (z)} (x,y) f(y) d^n y = \int_{B_r (z)} \lim_{x \to x_0} G_{B_r (z)} (y,x) f(y) d^n y =0.
    \]
    Therefore, the solution on $B_r (z)$ extends continuosly to $\partial B_r (z)$ and is equal to $g=0$. Now we focus on the second problem. Note that for $x \in B_r (z)$ the solution then is given by 
    \begin{align*}
    u(x) &= \underbrace{\int_{B_r (z)} G_{B_r (z)} (x,y) f(\bar{y}) d^n y}_{=0} - \int_{\partial B_r (z)} g(y) \nabla_{y} G_{B_r (z)}  (x,y) \cdot N d \sigma (y) \\
    &= - r^{2-n} \int_{\partial B_r (z)} g(y) \nabla_{\frac{y-z}{r}} G_{B_1 (0)}  ( \frac{x-z}{r},\frac{y-z}{r}) \cdot N d \sigma (y) \\
    &= - r^{2-n} \int_{\partial B_r (z)} g(y) \nabla_{\psi(y)} G_{B_1 (0)}  ( \psi (x),\psi (y) ) \cdot N d \sigma (y) \\
    &= - r^{2-n} \int_{\partial B_r (z)}  g(y) \nabla_{y} (G_{B_1 (0)}\circ \psi)  ( x,y ) \cdot N d \sigma (y) \\
    &= - r^{2-n} \int_{\partial B_r (z)}  g(y) \nabla_{y} G_{B_1 (0)}  ( \psi (x),\psi (y) ) r^{-1} \cdot N d \sigma (y) \\
    &= - r^{2-n} \int_{\partial B_1 (0)}  g(yr+z) \nabla_{y} G_{B_1 (0)}  ( \psi (x),\psi (yr+z) ) r^{-1} r^{n-1} \cdot N d \sigma (y) \\
    &= -  \int_{\partial B_1 (0)}  g(yr+z) \nabla_{y} G_{B_1 (0)}  ( \psi (x),y )  \cdot N d \sigma (y) 
    \end{align*}
    In the following we will write $x := \psi (x) \in B_1 (0)$ (a little crude definition) and analyze for $y \in \partial B_1 (0)$ the term $K (x,y) :=  \nabla_y G_{B_r (z)}  (x,y) \cdot N$. We will show that this term is harmonic. Clearly it holds 
    \begin{align*}
        &\nabla_y |x-y|^{2-n} = (2-n) |x-y|^{1-n} \nabla_y |x-y| = (2-n) |x-y|^{1-n} \nabla_y \left( \sum_{i=1}^n (x_i - y_i)^2 \right)^{1/2} \\
        &= (2-n) |x-y|^{1-n} \frac{1}{2} \frac{1}{|x-y|} \nabla (x-y)^2 \\
        &=  (2-n) |x-y|^{1-n} \frac{(-1) (x-y)}{|x-y|}.
    \end{align*}
    Using the above and the fact that $|y|=1$  we get for $n >2$ (not done for $n=2$) 
    \begin{align*}
        K(x,y) &:=- \nabla_y \left( \Phi(x-y) - |x|^{2-n} \Phi (\tilde{x}(x) -y) \right) \frac{y}{|y|} \\
        &= - \frac{1}{n(n-2) \omega_n } \nabla_y \left( \frac{1}{|x-y|^{n-2}} - |x|^{2-n} \frac{1}{|\tilde{x}(x) -y |^{n-2}} \right) y \\
        &= - \frac{y}{n(n-2) \omega_n  } \nabla_y \left( |x-y|^{2-n} - |x|^{2-n} |\tilde{x}(x) -y |^{2-n} \right) \\
        &= - \frac{y}{n (n-2)\omega_n  }\left( (2-n) |x-y|^{1-n} \frac{(-1) (x-y)}{|x-y|} - |x|^{2-n} (2-n) |\tilde{x}(x)-y|^{1-n} \frac{(-1)(\tilde{x}(x)-y)}{|\tilde{x}(x)-y|}  \right) \\
        &=  \frac{y}{n \omega_n  }\left(  |x-y|^{1-n} \frac{(-1) (x-y)}{|x-y|} - |x|^{2-n}  |\tilde{x}(x)-y|^{1-n} \frac{(-1)(\tilde{x}(x)-y)}{|\tilde{x}(x)-y|}  \right) \\
        &=  \frac{y}{n \omega_n  }\left(  \frac{y-x}{|x-y|^n} - |x|^{2-n}  \frac{y-\tilde{x}(x)}{|\tilde{x}(x)-y|^n}  \right) \\
        &=  \frac{y(y-x) }{n \omega_n |x-y|^n }- \frac{y(y-\tilde{x}(x)) }{n \omega_n |\tilde{x}(x)-y|^n }|x|^{2-n}   \\
        &=  \frac{y(y-x) }{n \omega_n |x-y|^n }- \frac{y(y-\tilde{x}(x)) }{n \omega_n |\tilde{x}(x)-y|^n }|x|^{2-n}   \\
    \end{align*}
    Due to the fact that 
    \begin{align*}
        &|\tilde{x}(x) -y|^2 |x|^2 = \sum_{i=1}^n |x|^2 \left( \frac{x_i}{|x|^2} - y_i \right)^2 \\
        &= \sum_{i=1}^n |x|^2 \left( \frac{x_i^2}{|x|^4}- 2 \frac{x_i}{|x|^2} y_i + y_i^2 \right) \\
        &= \sum_{i=1}^n  \left( \frac{x_i^2}{|x|^2}- 2 x_i y_i +|x|^2 y_i^2 \right) \\
        &=  \frac{\sum_{i=1}^n x_i^2}{|x|^2}- \sum_{i=1}^n 2 x_i y_i +|x|^2 \sum_{i=1}^n y_i^2  \\
        &=  1- \sum_{i=1}^n 2 x_i y_i +|x|^2  = |y|^2 -\sum_{i=1}^n 2 x_i y_i +|x|^2 = |x-y|^2\\
        & \iff |\tilde{x}(x) -y| |x| = |x-y|
    \end{align*}
    we get that the above is 
    \begin{align*}
        K(x,y) &= \frac{y(y-x) }{n \omega_n |x-y|^n }- \frac{y(y-\tilde{x}(x)) }{n \omega_n |\tilde{x}(x)-y|^n }|x|^{2-n}   \\
        &= \frac{y(y-x) }{n \omega_n |x-y|^n }- \frac{y(y-\tilde{x}(x)) }{n \omega_n |x-y|^n }|x|^{2} \\
        &= \frac{yy-yx) }{n \omega_n |x-y|^n }- \frac{y y|x|^2 -y x  }{n \omega_n |x-y|^n } \\
        &= \frac{ \overbrace{yy}^{= |y|=1} }{n \omega_n |x-y|^n }- \frac{y y|x|^2  }{n \omega_n |x-y|^n } = \frac{1-|x|^2  }{n \omega_n |x-y|^n } \\
    \end{align*}
    Because $y \in \partial B_1 (0)$ it follows for all $x \in B_1 (0)$ that 
    \[
    \Delta_x K(x,y) = - \Delta_x \nabla_y G_{B_1 (0)} (x,y) \frac{y}{|y|} = - \nabla_y \underbrace{\Delta_x G_{B_1 (0)} (x,y)}_{= \Delta_x G_{B_1 (0) } (x,y) = - \delta_0 (x-y) =0} \frac{y}{|y|} =0.
    \]
    Thus due to symmetry $x \mapsto K(x,y) $ is harmonic.\\
    We now want to show that $u$ extends continuously to $\partial B_r (z)$ and is there equal to $1$. For $x \in B_1 (0)$ and $x_0 \in \partial B_1 (0)$ it holds with symmetry 
    \[
    \lim_{x \to x_0} u(z+rx) = \int_{\partial B_1 (0)} g(z+ry) \lim_{x \to x_0} K(x,y) d \sigma (y) = \int_{\partial B_1 (0)} g(z+ry) \lim_{x \to x_0} K(y,x) d \sigma (y) \text{ exists.}
    \]
    Next, observe that 
    \begin{itemize}
        \item $\forall (x,y) \in B_1 (0) \times \partial B_1 (0): $ $K(x,y) = \frac{1-|x|^2}{n \omega_n |x-y|^n}>0$. 
        \item The mapping $y \mapsto K(\lambda x,y )$ is uniform convergent as $\lambda \to 1$ for $x \in \partial B_1 (0)$. This is due to the following: Choose $x \in \partial B_1 (0)$ and $y \in \partial B_1 (0) \setminus \partial B_\epsilon (x)$ for $\epsilon >0$ arbitary. Then 
\begin{align*}
    K(x \lambda ,y ) = \frac{1-|\lambda x|^2}{n \omega_n |\lambda x-y|^n} = \frac{1-\lambda^2}{n \omega_n |\lambda x-y|^n} \leq \frac{1-\lambda^2}{n \omega_n ( \epsilon- (1-\lambda) )^n}  \to 0, \lambda \to 1,
\end{align*}
although we used that $|\lambda x - y| \geq |x-y| - |  x-\lambda x |   \geq \epsilon - | x-\lambda x |  =  \epsilon-(1-\lambda) $. 
\item Now choose $x \in \partial B_1 (0)$ and $y=x$, then 
\[
K(\lambda x,y) = \frac{1-|\lambda x|^2}{n \omega_n |\lambda x -x|^n} = \frac{1-\lambda^2}{n \omega_n (1-\lambda)^n} =\frac{(1-\lambda) (1+\lambda)}{n \omega_n (1-\lambda)^n} = \frac{ 1+\lambda}{n \omega_n (1-\lambda)^{n-1}} \to \infty, \lambda \to 1. 
\]
    \end{itemize}
    We now want to show that for $x_0 \in \partial B_r (z)$ and $x \in B_r (z)$ that 
    \[
    \lim_{x \to x_0} u(x) = g(x_0).
    \]
    For that define $w \equiv 1$ on $\overline{B_1 (0)}$, then it holds 
    \begin{align*}
        &\int_{\partial B_1 (0)} K(x,y) d \sigma (y) = \int_{\partial B_1 (0)} w(y) \nabla_y G_{B_1 (0)} (x,y) \cdot N d \sigma (y)\\
        &= \int_{\partial B_1 (0)} ( w(y) \nabla_y G_{B_1 (0)} (x,y) -  G_{B_1 (0)} (x,y) \nabla_y w(y) ) \cdot N d \sigma (y) \\
        &\stackrel{Greens2}{=} \int_{ B_1 (0) }  w(y) \Delta_y G_{B_1 (0)} (x,y) -  G_{B_1 (0)} (x,y) \Delta_y w(y)  d^n y \\
        &= \int_{ B_1 (0) }  \Delta_y G_{B_1 (0)} (x,y) d^n y =\int_{ B_1 (0) }  \delta_x (y) d^n y = 1.
    \end{align*}
    Using that it follows for all $\epsilon >0$ and $\delta >0$ such that $|x-y|< \delta$ it follows with continuity that $g(y)-g(x_0)< \frac{\epsilon}{2}$. Due to the fact that $\int_{\partial B_1 (0) \setminus \partial B_\delta (x_0) } K(x,y) d \sigma (y) \to 0$ as $x \to x_0$ for $|y-x_0|< \delta$ such that 
    \[
    \int_{\partial B_1 (0) \setminus \partial B_\delta (x_0) } K(x,y) d \sigma (y) \leq \frac{\epsilon}{4 \| g \|_\infty}
    \]
    it follows
    \begin{align*}
        | u(x) - g(x_0 )| &\leq \int_{\partial B_1 (0)} K(x,y) |g(y) -g(x_0)| d \sigma (y) \\
        & \leq \int_{\partial B_1 (0) \setminus \partial B_\delta (x_0) } K(x,y) |g(y) -g(x_0)| d \sigma (y) + \int_{\partial B_\delta (x_0) } K(x,y) |g(y) -g(x_0)| d \sigma (y) \\
        &\leq 2 \| g \|_\infty \int_{\partial B_1 (0) \setminus \partial B_\delta (x_0) } K(x,y) d \sigma (y) + \int_{\partial B_\delta (x_0) } K(x,y) \frac{\epsilon}{2}  d \sigma (y) \\
        &\leq 2 \| g \|_\infty \underbrace{\int_{\partial B_1 (0) \setminus \partial B_\delta (x_0) } K(x,y) d \sigma (y)}_{\to 0, x \to x_0} + \frac{\epsilon}{2} \underbrace{ \int_{\partial B_1 (0) } K(x,y)   d \sigma (y)}_{=1} \\
        &\leq 2 \| g \|_\infty  \frac{\epsilon}{4 \| g \|_\infty}  +  \frac{\epsilon}{2} =\epsilon .
    \end{align*}
    Because $\epsilon>0$ was chosen arbitrary the assertion follows.\\
    Finally, we have shown in this proof that the solution of $1.$ is 
    \[
    u_1(x) = \int_{B_r (z)} G_{B_r (z)} (x,y) f(y) d^n y = \frac{1}{r^{n-2}} \int_{B_r (z)} G_{B_1 (0)} (\psi (x),\psi (y)) f(y) d^n y
    \]
    and for $2.$ is 
    \[
    u_2(x) = \int_{\partial B_r (z)} g(yr+z) \nabla_y G_{B_1 (0)} (\psi (x),y) \cdot N d \sigma (y) = \frac{1- |\psi (x)|^2}{n \omega_n} \int_{\partial B_r (z)} \frac{g(yr+z)}{|\psi (x) -y|^n} d \sigma (y).
    \]
    Thus in total the solution of the Dirichlet problem is 
    \[
    u(x) =\frac{1}{r^{n-2}} \int_{B_r (z)} G_{B_1 (0)} (\frac{x-z}{r},\frac{y-z}{r}) f(y) d^n y + \frac{1- |\frac{x-z}{r}|^2}{n \omega_n} \int_{\partial B_r (z)} \frac{g(yr+z)}{|\frac{x-z}{r} -y|^n} d \sigma (y).
    \]
}
\cor{
    Harmonic functions on an open domain $\Omega \subset \mathbb{R}^n$ are analytic.
}
\pf{
    Let $u$ be harmonic on $B_r (z)$ and extend continuously to $\partial B_r (z)$ where $u \equiv g$, for some $g \in C^2(\partial B_r (z))$. This can be represented as a Dirichlet problem. Its solution is the given by the result of the last theorem:
    \begin{align*}
     u(x) &= \frac{1}{r^{n-2}} \int_{B_r (z)} G_{B_1 (0)} \left( \frac{x-z}{r}, \frac{y-z}{r} \right) \underbrace{f(y)}_{=-\Delta u=0} d^n y + \frac{1- \frac{|x-z|^2}{r^2}}{n \omega_n} \int_{\partial B_1 (0)} \frac{g(z+ry)}{|\frac{x-z}{r}-y|^n} d \sigma (y) \\
     &=  \frac{1- \frac{|x-z|^2}{r^2}}{n \omega_n} \int_{\partial B_1 (0)} \frac{u(z+ry)}{|\frac{x-z}{r}-y|^n} d \sigma (y) \\
     &=  \frac{1- \frac{|x-z|^2}{r^2}}{n \omega_n} \int_{\partial B_r (z)} \frac{u(y)}{|\frac{x-z}{r}-\frac{y-z}{r}|^n} r^{1-n} d \sigma (y) \\
     &=  \frac{r^2- |x-z|^2}{n r^2 \omega_n} \int_{\partial B_r (z)} \frac{u(y)}{|x-y|^n} r^{n} r^{1-n} d \sigma (y) \\
     &=  \frac{r^2- |x-z|^2}{n r \omega_n} \int_{\partial B_r (z)} \frac{u(y)}{|x-y|^n} d \sigma (y) \\
    \end{align*}
    Note that for $x=z$ it follows that $|x-y|=r$ and 
    \[
    u(x) = \frac{r^2}{n r \omega_n} \int_{\partial B_r (z)} \frac{u(y)}{r^n} d \sigma (y) = \frac{1}{n r^{n-1} \omega_n} \int_{\partial B_r (z)} u(y) d \sigma (y),
    \] 
    which is exactly the mean value property.\\
    Remember for a sequence of the form $(\sum_{i=1}^n a_i x^i)_{n \in \mathbb{N}}$ the radius of convergence is defined as $R:= \frac{1}{\overline{\lim_{i \to \infty}} \sqrt[n]{|a_i|}}$. A function is called analytic in $x_0$ if there exists a Taylor series $\sum_{k=1}^n \frac{f^{(k)} (x_0)}{k !} (x-x_0)^k$ that converges to $f(x_0)$ as $n \to \infty$ and its convergence radius $R$ is positive. ...?
}

\lem{}{
    Let $\Omega \subset \mathbb{R}^n$ be an open neighborhood of $0$ and $u$ a bounded harmonic function on $\Omega \setminus \{ 0\}$. Then $u$ extends as a harmonic function to $\Omega$.
}
\pf{
    Let $B_r (0) \subset \Omega$ have compact closure in $\Omega$. With the theorem before the solution for the Dirichlet Problem where $f=0$ on $B_r (0)$ and $g=u$ on $\partial B_r (0)$ there exists a unique $\tilde{u} \in C^2  (B_r (0)) \cap C^0 (\overline{ B_r (0)})$. Note that $u$ is as defined in the lemma. We define 
    \[
    u_\epsilon (x) := \tilde{u}(x) - u(x) + \epsilon G_{B_r (0)} (x,0), \quad x \in B_r (0) \setminus \{ 0 \}, \quad \epsilon \in \mathbb{R}.
    \]
    By definition of the Greens function it holds in distribution that $- \Delta G_{B_r (0)} (x,0) = \delta_0$, $G_{B_r (0)} (x,0)$ vanishes on $\partial B_r (0)$ and it has a singularity in $x=0$, due to the fact that $G_{B_r (x,0)}$ is singular iff $\tilde{x}(x)=0$, which is equivalent to $x=0$.\\
    Due to the fact that $G_{B_r (0)} (x,0)$ vanishes on $\partial B_r (0)$ and that for $x_0 \in \partial B_r (0)$ $\tilde{u}(x_0)= u(x_0)$, it follows $u_\epsilon (x_0) =0$. Further, as stated before, $G_{B_r (0)}(x,0)$ is singular in $x=0$. Due to the fact that $\tilde{u}$ and $u$ are bounded it follows for every $\epsilon >0$ that $u_\epsilon (x) \to \infty, x \to 0$. Note that $u_\epsilon$ is a harmonic function on $B_r (0) \setminus \{0\}$ (linear combination of harmonic functions).\\
    We now want to show that for $\epsilon >0$ the function $u_\epsilon$ is non-negative. For that assume that $u_\epsilon$ takes a negative value on $B_r (0) \setminus \{0\}$. Due to the fact that there is a pole in $x=0$ with $u_\epsilon (0)=\infty$ and on the boundary we have $u_\epsilon(x)=0$ it follows that there exists a negative minimum value in the interior.  With the strong minimum principle it follows that $u_\epsilon$ is constant. This a contradiction to the fact that the pole in $x=0$ is equal to $+ \infty$.\\
    The argument is analougous for $\epsilon< 0$ and $u_\epsilon$ non-positive.\\
    In total it holds
    \[
    0 \leftarrow \lim_{\epsilon \nearrow 0} u_\epsilon (x) =\tilde{u}(x)-u(x)=  \lim_{\epsilon \searrow 0} u_\epsilon (x) \rightarrow 0, \quad x \in B_r (0) \setminus \{0\}.
    \]
    Thus $\tilde{u}$ is a harmonic extension of $u$ on $\Omega$.
}
In the above lemma we used the condition that the harmonic function $u$ is bounded. This condition could be weakend and we still would get the same result: For every $u$ harmonic on $\Omega \setminus \{0\}$ with 
\[
\forall \epsilon >0 \exists \delta_\epsilon >0 \forall x \in B_{\delta_\epsilon} (0) \setminus \{0\}: \quad |u(x)| \leq \epsilon G_{B_{\delta_\epsilon}} (x,0),
\]
has a harmonic extension to $\Omega$.
\section{Dirichlet Principle}
\thm{}{
    Let $\Omega \subset \mathbb{R}^n$ be bounded, open domain and $\partial \Omega$ a $n-1$ dimensional submanifold. Let $f : \bar{\Omega} \to \mathbb{R}$ and $g: \partial \Omega \to \mathbb{R}$ be continuous and $u$ the solution of the respective Dirichlet Problem, that is given by the minimizer of the following functional
    \[
    I: \{w \in C^2 (\bar{\Omega}) \mid w\big|_{\partial \Omega }=g  \} \to \mathbb{R}, \quad w \to I(w):= \int_\Omega \frac{1}{2} \nabla w \cdot \nabla w - wf d^n x.
    \]
}
\pf{
    We show the equivalence of $u$ being the solution of the Dirichlet Problem and $u$ being a minimizer. \\
    "$\Rightarrow$"\\
    Let $u,w \in \{w \in C^2 (\bar{\Omega}) \mid w\big|_{\partial \Omega }=g  \} $ where $u$ is the solution of the Dirichlet problem and $w$ just any function in this set. Due to the fact that $u$ is the solution of the Dirichlet problem we have on $\Omega$ that $- \Delta u =f$, i.e.
    \begin{align*}
        &0= \int_\Omega (-\Delta u -f) d^n x =\int_\Omega (-\Delta u -f) (u-w) d^n x \\
        &= \int_\Omega -\Delta u u + \Delta u w - fu +fw d^n x\\
        &= \int_{\partial \Omega} \underbrace{(w-u)}_{=0} \nabla u \cdot N d \sigma (z) - \int_\Omega \nabla u \nabla (w-u) - f (w-u) d^n x\\
        &= \int_\Omega \nabla u \nabla (u-w) - f (u-w) d^n x.
    \end{align*}
    This is now equivalent to 
    \[
    \int_\Omega \nabla u \nabla u - f u d^n x = \int_\Omega \nabla u \nabla w - f w d^n x.
    \]
    Using this if follows 
    \begin{align*}
        \int_{\Omega } \nabla u \nabla u - f u d^n x &= \int_\Omega \nabla u \nabla w - fw d^n x \\
        &= \int_\Omega \nabla u \nabla w d^n x - \int_\Omega fw d^n x \\
        & \stackrel{CS}{\leq } \int_\Omega \nabla u \nabla w + \frac{1}{2} (\nabla u - \nabla w) (\nabla u - \nabla w) d^n x - \int_\Omega fw d^n x \\
        &= \int_\Omega \nabla \frac{1}{2} \nabla u \nabla u + \frac{1}{2} \nabla w \nabla w  - fw d^n x = \int_\Omega \frac{1}{2} \nabla u \nabla u d^n x + I(w), 
    \end{align*}
    which is equivalent to 
    \[
    I(u) \leq I(w).
    \]
    "$\Leftarrow$"\\
    Let $u$ be a minum of that function $I(\cdot)$ then for every $v \in C^2 (\bar{\Omega})$ that vanish on $\partial \Omega$ satisfy 
    \begin{align*}
        0 &= \frac{d}{dt} I(u+ tv) \big|_{t=0} = \frac{d}{dt} \left( \int_\Omega \frac{1}{2} \nabla (u+tv) \nabla (u+tv) - (u+tv) f d^n x \right) \big|_{t=0} \\
        &= \frac{d}{dt}\left(  I(u)+ \int_\Omega \nabla u t \nabla v + \frac{1}{2} t^2 \nabla u \nabla v - t v f d^n x \right) \big|_{t=0} \\
        &=  \int_\Omega \nabla u  \nabla v d^n x + \int_\Omega t \nabla u \nabla v d^n x \big|_{t=0} - \frac{d}{dt}\left( \int_\Omega t v f d^n x \right) \big|_{t=0} \\
        &=  \int_\Omega \nabla u  \nabla v  -  v f d^n x = \int_\Omega (-\Delta u - f) v d^n x \\
        & \iff - \; \int_\Omega \Delta u v d^n x = \int_\Omega f v d^n x.
    \end{align*}
Because $v$ was chosen arbitrary, it follows that $-\Delta u =f $ on $\Omega$.
}

Remember from numerics of PDEs that this last equation in the proof was called variational equation of the Poission equation, that was formulted to find a weak solution.

\rmkb{
Let $u,v$ be two solutions of the Dirchlet problem, then 
\[
\Delta (u-v) = \text{on } \Omega \text{ and } u-v=g-g=0 \text{ on } \partial \Omega.
\]
This implies $I(u-v)=0$??? and larger set of functions???
}

\section{A PDE with no solutions}
Skipped for now ???

\chapter{Heat Equation}
We now focus on $\frac{\partial}{\partial t} u - \Delta u=0$ the heat eqaution and is inhomogenous form $\dot{u} - \Delta u=f$, where $u$ is defined on the open domain $\Omega \subset \mathbb{R}^n \times \mathbb{R}$ and $f$ on $\Omega$. We will extend statements about harmonic function to solution of the heat equation. This equation models the diffusion of some quantity. (The heat equation follows from the scalar conservation law???)\\
\section{Fundamental Solution of the Heat Equation}
Since in the heat equation there are only first order derivatives in time and second order in space it holds that 
\[
u(x,t) \text{ is solution } \Rightarrow \forall \lambda\in \mathbb{R}: \quad u(\lambda, x , \lambda^2 t) \text{ is solution.}
\]
This is because 
\[
\frac{\partial}{\partial t} u(\lambda x, \lambda^2 t) + \sum_{i,j=1}^n \frac{\partial^2}{\partial x_i \partial x_j} u(\lambda x, \lambda^2 t) = \lambda^2 \frac{\partial}{\partial (\lambda^2 t)} u(\lambda x, \lambda^2 t) - \lambda^2 \sum_{i,j=1}^n \frac{\partial^2}{\partial (\lambda x_i) \partial (\lambda x_j)} u(\lambda x, \lambda^2 t) =0.
\]
This suggests that the ratio $\frac{x^2}{t}$ is of interest. We invoke 
\[
u(x,t) = \frac{1}{t^\alpha}  v\left( \frac{x}{t^\beta} \right), x \in \mathbb{R}^n, t \in \mathbb{R}^+, \alpha,\beta \in \mathbb{R}
\]
and $v: \mathbb{R}^n \to \mathbb{R}$ an unknown function. Using this it now holds 
\[
\lambda^\alpha u(\lambda^\beta x, \lambda t) = \lambda^\alpha \frac{1}{(\lambda t)^\alpha} v \left( \frac{\lambda^\beta x}{(\lambda t)^\beta} \right) = \frac{1}{t^\alpha} v \left( \frac{x}{t^\beta} \right) = u(x,t).
\]
With the choice $\lambda = \frac{1}{t}$ we have 
\[
u(\frac{x}{t^\beta},1) = t^\alpha u(x,t) = v\left(\frac{x}{t^\alpha}\right)
\]
Then it follows with $y := \frac{x}{t^\beta}$ that
\begin{align*}
   0&= \frac{\partial}{\partial t} u(x,t) + \sum_{i,j=1}^n \frac{\partial^2}{\partial x_i \partial x_j} u(x,t) = \frac{\partial}{\partial t} \left( \frac{1}{t^\alpha}  v\left( \frac{x}{t^\beta} \right) \right) + \frac{1}{t^\alpha} \sum_{i,j=1}^n \frac{\partial^2}{\partial x_i \partial x_j} \left(   v\left( \frac{x}{t^\beta} \right) \right)\\
    &= -\frac{\alpha}{t^{\alpha+1}}v\left( \frac{x}{t^\beta} \right)- \frac{1}{t^\alpha} \sum_{i=1}^n \frac{x_i}{t^\beta} \frac{\partial}{\partial y}   v\left( y \right) - \frac{1}{t^{2 \alpha + \beta}} \sum_{i,j=1}^n \frac{\partial^2}{\partial y_i \partial y_j}  v\left( y \right)\\
    &= - \alpha t^{-(\alpha+1)} v(y) - \beta t^{- (\alpha+1)} y^T \nabla v(y) - t^{-( \alpha +2 \beta)} \Delta v(y).
\end{align*}
If we set $\beta = \frac{1}{2}$ then 
\begin{align*}
     &- \alpha t^{-(\alpha+1)} v(y) - \frac{1}{2} t^{- (\alpha+1)} y^T \nabla v(y) - t^{-( \alpha +1)} \Delta v(y) =0  \\
     &\iff \alpha  v(y) + \frac{1}{2} y^T \nabla v(y) +  \Delta v(y) =0.
\end{align*}
Define $r:= |y| = \sqrt{y^T y}$ and $v(y) := w(r)$ then 
\[
\Delta v(y) ) \nabla_y \cdot \nabla_y w (|y|) = \nabla_y \cdot \left( w^\prime (r) \frac{y}{|y|}\right) = w^{\prime \prime }(r) + \frac{n-1}{r} w^\prime (r) 
\]
that gives us 
\begin{align*}
0=\alpha w(r)+ \frac{1}{2} y^T w^\prime (r) \frac{y}{|y|} + w^{\prime \prime} (r) + \frac{n-1}{r} w^\prime (r) = \alpha w(r)+ \frac{1}{2} r w^\prime (r) + w^{\prime \prime} (r) + \frac{n-1}{r} w^\prime (r) .
\end{align*}
This with $\alpha = \frac{n}{2}$ it follows  
\begin{align*}
    &0= r^{n-1} \left( \frac{n}{2} w(r)+ \frac{1}{2} r w^\prime (r) + w^{\prime \prime} (r) + \frac{n-1}{r} w^\prime (r) \right)\\
    \iff 0&=   r^{n-1} \frac{n}{2} w(r)+  r^{n-1}\frac{1}{2} r w^\prime (r) +  r^{n-1} w^{\prime \prime} (r) +  r^{n-1}\frac{n-1}{r} w^\prime (r) \\
    \iff 0&= \frac{1}{2} \left( r^n w (r) \right)^\prime + (r^{n-1} w^\prime (r))^\prime \\
    \iff 0&= \frac{d}{dt} \left( \frac{1}{2} r^n w (r)  + r^{n-1} w^\prime (r) \right) \\
    \iff \int_{\mathbb{R}} 0 dr&= \int_\mathbb{R} \frac{d}{dt} \left( \frac{1}{2} r^n w (r)  + r^{n-1} w^\prime (r) \right) dr = \frac{1}{2} r^n w (r)  + r^{n-1} w^\prime (r)\\
    &\iff a = \frac{1}{2} r^n w (r)  + r^{n-1} w^\prime (r),
\end{align*}
where $a \in \mathbb{R}$ is an arbitrary constant. Due to the fact that $w$ and $w^\prime$ for $r \to \infty$ it follows $a=0$. This gives us the ODE 
\[
 w^\prime (r) = -\frac{1}{2} r w (r) ,
\]
whose solution is given by $w (r) = b e^{- \frac{r^2}{4}}$ and $b \in \mathbb{R}$ is arbitrary. For a special choice of $b$ we get the fundamental solution 
\defn{}{
    The fundamental solution of the heat equation is giveny by 
    \[
    \Phi (x,t) := \begin{cases}
        \frac{1}{(4 \pi t)^{n_2} } e^{- \frac{|x|^2}{4t}} &, t>0 \\
        0&,t < 0
    \end{cases}, x \in \mathbb{R}^n.
 \]
}
For $t=0$ the Fundamental solution is not defined. It is defined as the limit from above, i.e. $\lim_{t \searrow 0 } \Phi (x,t)$.
\lem{}{
    For all $t >0$ the fundamental solution satisfies 
    \[
    \int_{\mathbb{R}^n} \Phi (x,t) d^n x=1.
    \]
}
\pf{
    For $y := \frac{x}{\sqrt{4 t}}$ it holds 
    \[
    \frac{1}{(4 \pi t)^{n/2} } \int_{\mathbb{R}^n} e^{- \frac{|x|^2}{4t}} d^n x = \frac{1}{ \pi^{n_2} } \int_{\mathbb{R}^n} e^{- y^2 } d^n y = \frac{1}{ \pi^{n_2} }\left(\int_{\mathbb{R}^n} e^{- y^2 } d y\right)^n = 1.
    \]
}

\thm{}{
    For $h \in C_b( \mathbb{R}^n, \mathbb{R})$ the function 
    \[
    u(x,t) := \int_{\mathbb{R}^n} \Phi (x-y,t) h(y) d^n y 
    \]
    satisfies 
    \begin{itemize}
        \item $u \in C^\infty (\mathbb{R}^n,\mathbb{R})$ 
        \item $\dot{u}- \Delta u =0$ on $\mathbb{R}^n \times \mathbb{R}^+$
        \item $u$ extends continuously and bounded to $\mathbb{R}^n \times \mathbb{R}^+$ with $\lim_{t \searrow 0} u(x,t) =h(x)$ for all $x \in \mathbb{R}^n$. 
    \end{itemize}
}
\pf{
    i)\\
    Since $\Phi (\cdot, \cdot)$ is smooth on $\mathbb{R}^n \times \mathbb{R}^+$ and $h$ is bounded it follows $u(x,t)$ is well defined, bounded and continuous on $\mathbb{R}^n \times \mathbb{R}^+$. Note that the function 
    \[
    \mathbb{R}^n \times \mathbb{R}^+ \to L^(\mathbb{R}^n) , (x,t) \mapsto D^{|\alpha|}_y \Phi (x-y,t)
    \]
    and the integral is a linear continuous operator from $L^1 (\mathbb{R}^n)$ to $\mathbb{R}$. Thus $u \in C^\infty (\mathbb{R}^n \times \mathbb{R}^+)$ and we can interchange differentiation and integration. \\
    ii)\\
    Because $\Phi$ solves the heat equation it follows 
    \[
    \dot{u}(x,t) - \Delta u(x,t) = \int_{\mathbb{R}^n} \left( \dot{\Phi} (x-y,t) - \Delta_x \Phi (x-y,t) \right) h(y) d^n y =0.
    \]
    iii)\\ 
    The continuity of $h$ implies that it is uniformly continuos on compact subsets of $\mathbb{R}^n$, i.e. 
    \[
    \forall \epsilon \forall x \in K \subset \mathbb{R}^n \text{ compact } \exists \delta >0 \forall y \in B_\delta (x): \quad |h(y)-h(x)| < \epsilon.
    \]
    Furthermore, by construction $\exists T>0$ such that forall $t < T$ it holds 
    \[
    \int_{\mathbb{R}^n \setminus B_\delta (0)} \Phi (y,t) d^n y=\int_{\mathbb{R}^n \setminus B_\delta (0)} \frac{1}{t^{n/2}} \Phi (\frac{y}{\sqrt{t}},t) d^n y = \frac{t^{n/2}}{t^{n/2}} \int_{\mathbb{R}^n \setminus B_{\delta /t } (0) } \Phi (z,1) d^n z < \epsilon ,
    \]
    where we used that 
    \[
    \Phi (y,t) =  \frac{1}{(4 \pi t)^{n_2} } e^{- \frac{|x|^2}{4t}} = \frac{1}{t^{n/2}} \frac{1}{(4 \pi )^{n_2} } e^{- \frac{|x|^2}{4t}} = \frac{1}{t^{n/2}} \Phi ( \frac{y}{\sqrt{t}},1).
    \]
    It then follows that for all $ t < T$:
    \begin{align*}
        |u(x,t) - h(x) | &= \left| \int_{\mathbb{R}^n} \Phi (x-y,t) (h(y) - h(x)) d^n y \right| \\
        & \leq \int_{ B_\delta (x) }  \Phi (x-y,t) \left|h(y) - h(x)\right|  d^n y +\int_{\mathbb{R}^n \setminus B_\delta (x) }\Phi (x-y,t) \left|h(y) - h(x)\right|  d^n y  \\
        & \leq \epsilon \int_{\mathbb{R}^n} \Phi (x-y,t) d^n y + 2 \| h \|_\infty \int_{\mathbb{R}^n \setminus B_\delta (x) }\Phi (x-y,t)  d^n y \\
        &\leq \epsilon + 2 \| h \|_\infty \epsilon = (1 + 2 \| h \|_\infty ) \epsilon.
    \end{align*}
    Because $\epsilon >0$ was chosen arbitrary the assertion follows.
}

\section{Inhomogeneous Initial value problem}
THe homogenuous heat equation can be written as $\dot{u} = \Delta u$. Because the Laplace operator is a linear mapping from $C^2( \mathbb{R}^n) \to C^0 (\mathbb{R}^n)$ the heat equation becomes an ODE on an infinite dimensional Banach space. 
\rmkb{
    Remember that for an inhomogenous linear ODE 
    \[
    u^\prime (t) = a(t) u(t) + b(t), \quad u(0) = \eta 
    \]
    the soltion using variation of constants is given by 
    \[
    u(t) = \eta e^{A(t)} + \int_0^t b(x) e^{A(t) -A(s)} ds 
    \]
    where $A(t) := \int_0^t a(s) ds$.
}
There is the homogeneous initial value problem 
\begin{align*}
    \dot{u} (x,t) - \Delta u(x,t) =0, \quad (x,t) \in \mathbb{R}^n \times \mathbb{R}^+,\\
    u(x,0) = h(x), \quad x \in \mathbb{R}^n
\end{align*}
and the inhomogenous initial value problem 
\begin{align*}
    \dot{u} (x,t) - \Delta u(x,t) =f(x,t), \quad (x,t) \in \mathbb{R}^n \times \mathbb{R}^+,\\
    u(x,0) = 0, \quad x \in \mathbb{R}^n.
\end{align*}
Assume that $u$ is the solution of the inhomegenous initial value problem and $v_t$ the solution of the homogenous inital value problem with $v_t (x,0)=h_t(x)$. Further, assume that $f(x,t)=h_t (x)$, then 
\[
u(x,t)  =\int_0^t v_s(x,t-s)   ds=  \int_0^t \int_{\mathbb{R}^n} \Phi (x-y,t-s) h_s (y ) d^n y ds = \int_0^t \int_{\mathbb{R}^n} \Phi (x-y,t-s) f(y,s) d^n y ds.
\]
Remember the Leipniz rule: For any differentiable function $G(x,t)$ it holds 
\[
\frac{d}{dt} \int_0^t G(t,x) ds = \int_0^t \frac{\partial}{\partial t} G(t,x) ds + G(t,t).
\]
Using this we get 
\begin{align*}
&\dot{u}(x,t) - \Delta u(x,t) \\
&= \int_0^t \int_{\mathbb{R}^n} \left(\dot{\Phi} (x-y,t-s) - \Delta \Phi (x-y,t-s) \right) f(y,s) d^n y ds +\lim_{s \to t} \int_{\mathbb{R}^n} \Phi (x-y,t-s)  f(y,t) d^n y\\
&= \int_{\mathbb{R}^n} \delta (x-y)  f(y,t) d^n y=f(x,t).
\end{align*}
Thus is suffices to study the homogeneous initial value problem as we can just integrate over time and thus get the solution to the non-homogenous problem.
\thm{}{
    If $f$ is twice continuously and bounded differentiable on $\mathbb{R}^n \times \mathbb{R}^+$ then the solution of the inhomogenous initial value problem 
    \[
    \dot{u} - \Delta u = f \text{ on } \mathbb{R}^n \times \mathbb{R}^+, \quad \lim_{t \to 0} u(x,t) =0
    \]
    is given by 
    \[
    u(x,t) = \int_0^t \int_{\mathbb{R}^n} \Phi (x-y,t-s) f(y,s) d^n ds = \int_0^t \int_{\mathbb{R}^n} \Phi (y,s) f(x-y,t-s) d^n y ds.
    \]

}
\pf{
    We have already shown that 
    \[
    v_s (x,t) := \int_{\mathbb{R}^n} \Phi (x-y,t-s) f(y,s) d^n y 
    \]
    solves the homoegenous initial value problem 
\[
\dot{u} - \Delta u = 0 \text{ on } \mathbb{R}^n \times \mathbb{R}^+, \quad \lim_{t \to 0} u(x,t) =f(x,t)
\]
and $v_s \in C^\infty (x,t)$. \\
We can now show that for arbitary $\epsilon>0$ it holds 
\[
u_\epsilon (x,t) := \int_0^{t-\epsilon} v_s (x,t) ds = \int_0^{t-\epsilon} \int_{\mathbb{R}^n} \Phi (x-y,t-s) f(y,s) d^n y ds
\]
satisfies 
\[
    \dot{u}_\epsilon (x,t) - \Delta u_\epsilon (x,t) = \int_{\mathbb{R}^n} \Phi (x-y,t-t+\epsilon) f(y,t-\epsilon) d^n y = \int_{\mathbb{R}^n} \Phi (x-y,\epsilon) f(y,t-\epsilon) d^n y
\]
which satisfies all the conditions from the previous theorem for homogenous initial value problems, giving us
\[
\dot{u}_\epsilon (x,t) - \Delta u_\epsilon (x,t) \to f(x,t) , \quad \epsilon \searrow 0.
\]
Finally, combining the above yields the assertion:
\[
f(x,t) = \lim_{\epsilon \to 0} \left( \dot{u}_\epsilon (x,t) - \Delta u_\epsilon (x,t) \right) = \lim_{\epsilon \to 0} \left( \frac{\partial}{\partial t} - \Delta  \right)u_\epsilon (x,t) = \left( \frac{\partial}{\partial t} - \Delta  \right)u (x,t)= \dot{u} (x,t) - \Delta u (x,t)
\]
and the continuity of $v_s$ gives
\[
u(x,0) = \lim_{\epsilon \to 0} u_\epsilon (x,0)= \lim_{\epsilon \to 0} \int_0^{-\epsilon} \int_{\mathbb{R}^n} \Phi (x-y,-s) f(y,s) d^n y ds???
\]

}

\cor{
    The inhomogenous initial value problem 
    \[
    \dot{u} - \Delta u =f \text{ on } \Omega, \quad u(x,0)=h(x), \text{ on } \partial \Omega,
    \]
    has the solution of the form 
    \[
    u(x,t) = \int_{\mathbb{R}^n} \Phi (x-y,x) h(y) d^n y + \int_0^t \int_{\mathbb{R}^n} \Phi (x-y,t-s) f(y,s) d^n y ds .
    \]
}

\section{Mean Value Property}
We want to use the fundamental solution $\Phi$ to describe the solution $u(x,t)$ as some mean on a smart chosen ball.
\defn{}{
    For every $(x,t) \in \mathbb{R}^n \times \mathbb{R}$ and $r>0$ define 
    \[
    E(x,t,r) := \{ (y,s) \in \mathbb{R}^{n+1} \mid s \leq t, \Phi (x-y, t-s)  \geq \frac{1}{r^n}  \}.
    \]
}
It then holds that 
\begin{align*}
   & \Phi (x-y,t-s) \geq \frac{1}{r^n} \iff e^{-\frac{|x-y|^2}{4 (t-s) }}  \geq \frac{(4 \pi )^{n/2} (t-s)^{n/2} }{r^n} \\
   &\iff  \left( \frac{r^2}{4(t-s)} \right)^{n/2} \frac{1}{\pi^{n/2}}  \geq  e^{\frac{|x-y|^2}{4 (t-s) }}  \\
    & \iff - \frac{n}{2} \log(\pi) + \frac{n}{2} \left( 2 \log (r) - \log(4(t-s)) \right) \iff  \geq  \frac{|x-y|^2}{4 (t-s) }\\
    &\iff 2 (t-s) n \big( 2 \log (r) - \log (t-s) - \log (4 \pi) \big) \geq |x-y|^2
\end{align*}

\thm{Mean Value Property for the Heat Equation}{
    Let $u$ be the solution of the heat equation on an open domain $\Omega \subset \mathbb{R}^n \times \mathbb{R}$. Then $\forall (x,t) \in \Omega $ and $r>0$ with $E(x,t,r) \subset \Omega$: 
    \[
    u(x,t) = \frac{1}{C_n r^n} \int_{E(x,t,r)} u(y,s)  \frac{|x-y|^2}{(t-s)^2} d^n y ds, \quad C_n := \int_{E(0,0,r)} \frac{|y|^2}{s^2} d^n y ds.
    \]
}
\pf{
    Due to translation invariance (???) $(x,t) =(0,0)$, define 
    \begin{align*}
        S_{0,0}(r) &:= \frac{1}{r^n} \int_{E(0,0,r)} u(z,q) \frac{|z|^2}{q^2} d^n z dq =\frac{1}{r^n} \int_{E(0,0,1)} u(ry,r^2 s) \frac{|ry|^2}{(r^2 s)^2} d^n (ry) d (r^2 s) \\
        &=\frac{1}{r^n} \int_{E(0,0,1)} u (ry,r^2 s) \frac{r^2}{r^4} \frac{|y|^2}{s^2} r^n r^2 d^n y ds = \int_{E(0,0,1)} u (ry,r^2 s) \frac{|y|^2}{s^2}  d^n y ds.
    \end{align*}
    The map $T: E(x,t,r) \to E(rx,r^2 t,r), \quad (y,s) \mapsto (ry,r^2 s)$ is bijective, because it is first a isomorphism, due to its linearity and 
    \[
    \det \begin{pmatrix}
        \frac{\partial}{\partial y_1} T_1 (y,s) & &&\\
        & \ddots && \\
        && \frac{\partial}{\partial y_n} T_n (y,s) & \\
        &&& r^2
    \end{pmatrix} = 
    \det \begin{pmatrix}
        r \; Id_{n \times n} &0 \\ 0 & r^2
    \end{pmatrix} =r^n r^2 > 0.
    \]
    Further, because 
    \[
    \Phi (r (x-z), r^2 t) = \frac{1}{(r^2)^{n/2} } \frac{1}{(4 \pi (x-z))^{n/2}} e^{- \frac{|r (x-z)|^2}{4 r^2 t} } = \frac{1}{r^n} \Phi (x-z,t)
    \]
    it follows that 
    \begin{itemize}
        \item $\forall (x,t) \in E(x,t,1) \Rightarrow  T(x,t) \in E(rx,r^2 t,r)$
        \item $\forall (x,t) \in E(rx,r^2 t,r) \Rightarrow  T^{-1}(x,t) \in E(x,t,1)$
    \end{itemize}
    It then follows that 
    \begin{align*}
        S^\prime_{0,0} (r) &= \int_{E(0,0,1)} \frac{|y|^2}{s^2} \left( y^T \nabla u(ry,r^2s) + 2 rs \dot{u}(ry,r^2s) \right) d^n y ds \\
        &= \frac{1}{r^{n+1}} \int_{E(0,0,r)} r^2 \frac{|\frac{y}{r}|^2}{s^2} \left( \frac{y^T}{r} \nabla u(y,s) + 2r \frac{s}{r^2} \dot{u}(y,s) \right) d^n y ds\\
         &= \frac{1}{r^{n+1}} \int_{E(0,0,r)}  \frac{|y|^2}{s^2} \left( y^T \nabla u(y,s) + 2 s \dot{u}(y,s) \right) d^n y ds.
    \end{align*}
    Then for $x,t=0$ it holds
    \begin{align*}
       & |x-y|^2 \leq 2 (t-s) n \big( 2 \log(r) - \log (t-s) -\log (4 \pi) \big) \\
       & \iff |y|^2 \leq - 2 s n \big( 2 \log(r) - \log (-s) -\log (4 \pi) \big) \\
        & \iff |y|^2 \leq - 4 s n \big(  \log(r)  - \frac{1}{2}\log (-4 \pi s) \big) \\
        & \iff 0\leq - |y|^2 - 4 s  \big( n \log(r)  - \frac{n}{2}\log (-4 \pi s) \big) \\
         & \iff 0  \leq  \frac{|y|^2}{4s} +   n \log(r)  - \frac{n}{2}\log (-4 \pi s) 
    \end{align*}
    Define $\psi (y,s) := - \frac{n}{2} \log (- \pi s) + \frac{|y|^2}{4s} + n \log (r)$, then 
    \[
    E(0,0,r) = \{ (y,s) \in \mathbb{R}^{n+1} \mid \psi (y,s) \geq 0, \underbrace{s \leq t}_{???} \}
    \]
    can be written which yields that by definition $\psi$ vanishes on $\partial E(0,0,r)$. Using that 
    \[
    \frac{\partial}{\partial y_i} \psi (y,s) = \frac{1}{4s} 2 y_i= \frac{y_i}{2s} \quad \Rightarrow \quad 2 y^T \nabla \psi (y,s)= \frac{|y|^2}{s}
    \]
    it follows
    \begin{align*}
        &\frac{1}{r^{n+1}} \int_{E(0,0,r)} 2 \dot{u} \frac{|y|^2}{s} d^n y ds = \frac{1}{r^{n+1}} \int_{E(0,0,r)} 4 \dot{u} y^T \nabla \psi  d^n y ds \\
        &=  \frac{1}{r^{n+1}} \left(  \int_{E(0,0,r)} (-4) \nabla \cdot ( \dot{u} y) \psi  d^n y ds +  \int_{\partial E(0,0,r)} 4 \dot{u} y^T \psi N  d \sigma (y,s) \right) \\
        &=  - \frac{1}{r^{n+1}}  \int_{E(0,0,r)} 4   y^T \nabla  \dot{u}  \psi + 4   \dot{u} n \psi  d^n y ds \\
        &=  - \frac{1}{r^{n+1}}  \int_{E(0,0,r)} 4  \frac{\partial}{\partial t} \left(  y^T \nabla u \psi  \right) - 4 y^T \nabla u \dot{\psi}  + 4   \dot{u} n \psi  d^n y ds \\
         &=   \frac{1}{r^{n+1}}  \int_{E(0,0,r)} 4  y^T \nabla u \dot{\psi}  - 4   \dot{u} n \psi  d^n y ds \\
         &=   \frac{1}{r^{n+1}}  \int_{E(0,0,r)}   4y^T \nabla u \left( - \frac{n}{2} \frac{-4 \pi}{-4 \pi s} - \frac{|y|^2}{4} s^{-2} \right) - 4   \dot{u} n \psi  d^n y ds \\
         &=   \frac{1}{r^{n+1}}  \int_{E(0,0,r)}   y^T \nabla u \left( -  \frac{2n}{ s} - \frac{|y|^2}{ s^{2}}  \right) - 4   \dot{u} n \psi  d^n y ds 
    \end{align*}
    Then it follows 
    \begin{align*}
        S^\prime_{0,0} (r)& = \frac{1}{r^{n+1}} \int_{E(0,0,r)}  \frac{|y|^2}{s^2} \left( y^T \nabla u + 2 s \dot{u}(y,s) \right) d^n y ds \\
        &= \frac{1}{r^{n+1}} \int_{E(0,0,r)}  \frac{|y|^2}{s^2} y^T \nabla u  d^n y ds + \frac{1}{r^{n+1}}  \int_{E(0,0,r)}   y^T \nabla u \left( -  \frac{2n}{ s} - \frac{|y|^2}{ s^{2}}  \right) - 4   \dot{u} n \psi  d^n y ds \\
        &=  \frac{1}{r^{n+1}}  \int_{E(0,0,r)}  (-1)  y^T \nabla u   \frac{2n}{ s} - 4   \dot{u} n \psi  d^n y ds \\
        &\stackrel{HeatEq}{=}  - \frac{1}{r^{n+1}}  \int_{E(0,0,r)}    y^T \nabla u   \frac{2n}{ s} + 4   \Delta u n \psi  d^n y ds \\
        &=  - \frac{1}{r^{n+1}}  \int_{E(0,0,r)}    y^T \nabla u   \frac{2n}{ s} - 4 n  \nabla u^T  \nabla \psi  d^n y ds \\
        &= - \frac{1}{r^{n+1}}  \int_{E(0,0,r)}    y^T \nabla u   \frac{2n}{ s} - 4 n  \nabla u^T  \frac{y}{2s}  d^n y ds \\
         &= - \frac{1}{r^{n+1}}  \int_{E(0,0,r)} \nabla u^T \left(    y  \frac{2n}{ s} -    2 \frac{y}{s} \right) d^n y ds  =0.
    \end{align*}
    This shows that $S_{0,0}$ is constant. Further, it holds 
    \begin{align*}
        C_n &:= \int_{E(0,0,1)} \frac{|y|^2}{s^2} d^n y ds = \frac{1}{r^{n+1}} \int_{E(0,0,1)} \frac{1}{r} \frac{|y|^2}{s^2} r^n r^2 d^n y ds\\
        &=\frac{1}{r^{n+1}} \int_{E(0,0,1)}  \frac{|ry|^2}{(rs)^2} r^n r^2 d^n y ds = \frac{1}{r^{n+1}} \int_{E(0,0,1)}  \frac{|z|^2}{q^2}  d^n z dq.
    \end{align*}
    Finally, 
    \begin{align*}
       &\lim_{r \to 0} \frac{1}{C_n} \int_{E(0,0,1)} u(ry,r^2 s) \frac{|y|^2}{s^2} d^n y ds = \frac{1}{C_n} \int_{E(0,0,1)} \lim_{r \to 0}  u(ry,r^2 s) \frac{|y|^2}{s^2} d^n y ds \\
        &=u(0,0) \frac{1}{C_n} \int_{E(0,0,1)} \frac{|y|^2}{s^2} d^n y ds= u(0,0).
    \end{align*}
    Because $S_{0,0}(r)$ is constant and equalt to $u(0,0)$ for $r \to 0$ it follows it is equal to that point for every choice of $r>0$.
    
}


\section{Maximumsprinciple}

For any open domain $\Omega \subset \mathbb{R}^n$ we define the parabolic cyclinder $\Omega_T := \Omega \times (0,T]$ and $\partial \Omega_T (\partial \Omega \times (0,T]) \cup (\bar{\Omega} \times \{0\})$.
\thm{}{
    Let $\Omega$ be a path connected and $u$ twice continuous differentiable solution of the heat equation on $\Omega_T$ with continuous extension to $\bar{\Omega}_T$. If $u$ takes the maximum in $\Omega_T$ then $u$ is constant $\Omega_T$.
}
\pf{
    Let $(x_0,t_0) \in \Omega_T$ be the point where $u$ takes its maximum. Define 
    \[
    (x_0,t_0) \in A := \{ (x,t) \in \Omega_T \mid u(x,t) = \max_{(z,q) \in \bar{\Omega}_T} u(z,q) \}.
    \]
    Because $\Omega_T$ is an open domain 
    \[
    \exists r_0 >0: \quad E(x_0,t_0,r_0) \subset \Omega_T.
    \]
    Due to the path connectedness 
     \[
    \forall (x,t) \in \Omega \times (0,t_0) \exists n \in \mathbb{N} \text{ finite and } E(x_1,t_1,r_1),...,E(x_n,t_n,r_n) \subset \Omega \times (0,t_0)
    \]
    where $t_0 >...>t_n$, $(x_{i},t_i) \in E(x_{i-1},t_{i-1},r_{i-1})$ and $(x,t) \in E(x_n,t_n,r_n)$. This implies $u(x,t)$ is also the maximum. Thus $A= \mathring{ \Omega}_{t_0}$. Because $u$ is continuous in the interior and extends contiusly to the closure, it follows that $u$ is also equal to the maximum on $\overline{\Omega_{t_0}}$.\\
    In order to show that the solution is constant on $\Omega_T$ we need analiticity.??? Not done here.
}


\thm{Weak Maximum Principle}{
Let $\Omega \subset \mathbb{R}^n$ be open and bounded and $u$ a twice differntiable solution of the heat equation on $\Omega_T$ that continuously extends to $\bar{\Omega}_T$, then the maximum of $u$ is taken on $\partial \Omega_T$.
}

\thm{}{
    On an open and bounded domain $\Omega \subset \mathbb{R}^n$ there exists at most one solution $u$ of the inhomogenous heat equation that extends continuously to $\bar{\Omega}_T$ and coincides on $\partial \Omega_T$ with a given function.
}
\pf{
    Assume $u_1,u_2$ are tow solution of this problem and define $w:= u_1 - u_2$ then $(\partial_t - \Delta) w=0$ and $w\big|_{\partial_P \Omega_T} =0$. With the weak maximum priciple it follows that $\max_{(x,t) \in \bar{\Omega}_T} w(x,t)=0$ implies
    \[
    \forall (x,t) \in \Omega_T: \quad  w(x,t) \leq 0 .
    \]  
    Conversely, using the minimum principle it follows that 
    \[
    \forall (x,t) \in \Omega_T: \quad  w(x,t) \geq 0 .
    \] 
    Thus in total $\forall (x,t) \in \Omega_T: \quad  w(x,t) = 0 .$
}
In order to prove uniqueness of the initial value problem on $\mathbb{R}^n \times \mathbb{R}^+$ we need a bound on the growth of the solution at infinity.
\thm{Maximum Principle for the Cauchy Problem}{
For a bounded and continuous initial value $h$ on $\mathbb{R}^n$ and $u$ a solution on $\mathbb{R}^n \times (0,T]$ of 
\[
\dot{u}-\Delta u =0 \text{ on } \mathbb{R}^n \times (0,T) \text{ and } u(x,0)= h(x) \text{ on } \mathbb{R}^n \times \{ 0 \},
\]
which is bounded by 
\[
u(x,t) \leq A e^{a |x|^2}, \quad (x,t) \in \mathbb{R}^n \times [0,T] \text{ for } A,a >0,
\]
follows that $u$ is bounded by 
\[
\sup_{(x,t) \in \mathbb{R}^n \times [0,T]} u(x,t) = \sup_{x \in \mathbb{R}^n} h(x).
\]
}
\pf{
    Case $4aT < 1$:\\
    There exists $\epsilon >0$ such that $4a (T+ \epsilon) <1$. For all $y \in \mathbb{R}^n$ and $\mu >0$
    \[
    v(x,t) := u(x,t) - \mu \cdot (T+\epsilon -t)^{-\frac{n}{2}} e^{\frac{|x-y|^2}{4(T+\epsilon -t) } }
    \]
    is a sultion to the heat equation. This can be seen when plugging this into the differential operator $(\partial_t - \Delta_x)(\cdot)$. Because the second summand is of the form of the fundamental solution, this works. Consider the parabolic boundary $\partial_P \Omega_T := B_r (y) \times \{0\} \cup \partial B_r (y) \times (0,T]$. Then due to $\frac{1}{4(t+\epsilon)} > a$
    \begin{itemize}
        \item For $x \in B_r (y)$ it holds 
        \[
             A e^{a |x|^2} \geq v(x,0) \geq u(x,0) - \underbrace{ \mu (T+\epsilon)^{- n/2} e^{\frac{|x-y|^2}{4 (T +\epsilon)}}}_{\geq 0}
        \]
        and thus $v(x,0) < u(x,0) = h(x) \leq \sup_{x \in \mathbb{R}^n} h(x).$
        \item For $(x,t) \in  \partial B_r (y) \times (0,T]$ we want to find an upper bound that eventually drops beneath $\sup_{x \in \mathbb{R}^n} h(x)$. First, notice that 
        \[
        |x| = |x+y-y| \leq |x-y| + |y| = r + |y|.
        \] 
        Then we can show:
        \begin{align*}
            v(x,t) & \leq A e^{a |x|^2} - \mu (T+ \epsilon -t )^{-n/2} e^{\frac{r^2}{4 (t+ \epsilon -t)}} \leq A e^{a (|y|+r)^2} - \mu (T+ \epsilon -t )^{-n/2} e^{\frac{r^2}{4 (t+ \epsilon -t)}} 
        \end{align*}
        the second summand will drop underneath the first due to the fact that $\frac{1}{4 (t+ \epsilon -t)}> a$. Thus, on that intervall $v(x,t) \to - \infty$ as $r \to \infty$, as constants are neglegible in the limit.
    \end{itemize} 
    Both cases yield that on $\partial_P \Omega_T$ $v(x,t)$ is bounded by $\sup_{x \in \mathbb{R}^n} h(x)$ and $\mu >0$ arbitary. Because the second summand can be written as $\mu w(x,t)$ we can take the limit $\mu \searrow 0$ wich leads to $u$ being bounded by $\sup_{x \in \mathbb{R}^n} h(x)$. This implies 
    \[
    \sup_{(x,t) \in \mathbb{R}^n \times [0,T)} u(x,t) \leq \sup_{x \in \mathbb{R}^n} h(x).
    \]
    The verse trivially holds because 
    \[
   \sup_{x \in \mathbb{R}^n} h(x)= \sup_{x \in \mathbb{R}^n} u(x,0) \leq \sup_{(x,t) \in \mathbb{R}^n \times [0,T)} u(x,t). 
    \]
    Case $4aT>1$:\\
    Decompose the intervall $[0,T] = [0,T_1] \cup .. \cup [T_M,T]$, although $4a (T_{m+1}-T_m)<1$. Then on the intevervall $[0,T_1]$ we can use the first proof part. The second intervall is treated as a new initial value property. On this intervall we can again use the first proof. This is then condinued $M$ times.
}

\thm{Existence and uniqueness of the Initial Value Problem}{
    For $h\in C(\mathbb{R}^n)$ and $f \in C(\mathbb{R}^n \times [0,T])$ there exists at most one solution to the initial value problem 
    \[
    \dot{u} - \Delta u =f \text{ on } \mathbb{R}^n \times (0,T), \quad u=h \text{ on } \mathbb{R}^n \times \{0\},
    \]
    on $\mathbb{R}^n \times [0,T_0]$ which is bounded by $|u(x,t)| \leq A e^{a |x|^2}$, $a,A>0$ and $0 < T_0 \leq T$.\\
    Additionally, if $h$ and $f$ are also bounded by $A e^{a|x|^2}$ on $\mathbb{R}^n \times [0,T]$, $a,A,T>0$, then the unique solution is given by 
    \[
    u(x,t) = \int_{\mathbb{R}^n} \Phi (x-y,t) h(y) d^n y + \int_0^t \int_{\mathbb{R}^n} \Phi (x-y,t-s) f(y,s) d^n y ds.
    \]
    This solution (might???) explode at some finite time $t \nearrow T_0 \geq \frac{1}{16 a}$.
}
\pf{
    Using the maximum principle for the Cauchy problem we can again show that the vanishing of the difference of two solutions imply uniqueness.\\
    To show existence we use that the solution can be written as 
    \[
    u(x,t) = \int_{\mathbb{R}^n} \Phi (x-y,t) h(y) d^n y + \int_0^t \int_{\mathbb{R}^n} \Phi (x-y,t-s) f(y,s) d^n y ds.
    \]
    and need to show boundedness. Choose $0 \leq t-s \leq \frac{1}{16 a}$, then 
    \[
    - \frac{|x-y|^2}{4 (t-s)} = -\frac{2+2}{4}\frac{|x-y|^2}{4 (t-s)}\leq -2 a |x-y|^2 - \frac{|x-y|^2}{8(t-s)},
    \]
    implies 
    \begin{align*}
        e^{-2 a |x|^2} e^{a|y|^2} \Phi (x-y, t-s) &= e^{-2 a |x|^2} e^{a|y|^2} \frac{1}{(4 \pi (t-s))^{n/2}} e^{-\frac{|x-y|^2}{4(t-s)}}\\
        & \leq e^{-2 a |x|^2} e^{a|y|^2} \frac{1}{(4 \pi (t-s))^{n/2}} e^{-2 a |x-y|^2 - \frac{|x-y|^2}{8(t-s)}} \\
        &= e^{-2 a |x|^2-2 a |x-y|^2  +a|y|^2} \frac{1}{(4 \pi (t-s))^{n/2}} e^{- \frac{|x-y|^2}{8(t-s)}}
    \end{align*}
    Now due to 
    \[
    -2 a |x-y|^2 = -2a \left( |x|^2 -2 x^T y + |y|^2 \right) \iff 2 x^T y = |x|^2 - |x-y|^2 + |y|^2
    \]
    it follows that the above is equal to 
    \begin{align*}
        e^{-2 a |x|^2-2 a |x-y|^2  +a|y|^2} \frac{1}{(4 \pi (t-s))^{n/2}} e^{- \frac{|x-y|^2}{8(t-s)}} &= e^{- a\left(  2|x|^2+2  |x-y|^2  -|y|^2 \right) } \frac{1}{(4 \pi (t-s))^{n/2}} e^{- \frac{|x-y|^2}{8(t-s)}} \\
        &= e^{- a\left(  2|x|^2+  (2|x|^2- 4 x^T y +2|y|^2)  -|y|^2 \right) } \frac{1}{(4 \pi (t-s))^{n/2}} e^{- \frac{|x-y|^2}{8(t-s)}} \\
         &= e^{- a\left(  2|x|^2+ ( 2|x|^2 - (|y|^2+ 4|x|^2 - |2x-y|^2)  +2|y|^2 ) -|y|^2 \right) } \frac{1}{(4 \pi (t-s))^{n/2}} e^{- \frac{|x-y|^2}{8(t-s)}} \\
         &= e^{- a |2x-y|^2 } \frac{1}{(4 \pi (t-s))^{n/2}} e^{- \frac{|x-y|^2}{8(t-s)}} \\
         &= 2^{n/2} e^{- a |2x-y|^2 } \frac{1}{(8 \pi (t-s))^{n/2}} e^{- \frac{|x-y|^2}{8(t-s)}}\\
        &= 2^{n/2} e^{- a |2x-y|^2 } \frac{1}{(4 \pi 2(t-s))^{n/2}} e^{- \frac{|x-y|^2}{4 \cdot 2(t-s)}}.
    \end{align*}
    Due to the fact that $e^{- a |2x-y|^2} \leq e^{0} =1$ it follows 
    \[
    \Phi (x-y, t-s) \leq 2^{n/2}  e^{2 a |x|^2} e^{-a|y|^2} \Phi (x-y,2(t-s)).
    \]
    Then it follows 
    \begin{align*}
        u(x,t) &= \int_{\mathbb{R}^n} \Phi (x-y ,t) h(y) d^n y + \int_0^t \int_{\mathbb{R}^n} \Phi (x-y,t-s) f(y,s) d^n y ds \\
        & \leq \int_{\mathbb{R}^n} 2^{n/2} \Phi (x-y,2t) e^{2 a |x|^2} e^{-a|y|^2} A e^{a |y|^2} d^n y \\
        &+ \int_0^t \int_{\mathbb{R}^n} 2^{n/2} \Phi (x-y,2(t-s)) e^{2 a |x|^2} e^{-a|y|^2} A e^{a |y|^2} d^n y ds \\
        &\leq  2^{n/2} e^{2 a |x|^2} A \int_{\mathbb{R}^n }\Phi (x-y,2t) d^n y +  e^{2 a |x|^2} A  2^{n/2}  \int_0^t \int_{\mathbb{R}^n} \Phi (x-y,2(t-s)) d^n y ds \\
        &\leq  2^{n/2} e^{2 a |x|^2} A  +  e^{2 a |x|^2} A  2^{n/2}  t \\
        &\leq  2^{n/2} e^{2 a |x|^2} A  (1+t).
    \end{align*}
    Thus $u$ is bounded if and only if $t-s \leq \frac{1}{16a}$. To incorporate the case that this constant may be larger than $T$ we require that $t -s \in [0, \min \{T,\frac{1}{16a}\}]$.\\
    ??? Something with 
    \[
    \tilde{u}(x,t) = \frac{1}{(T_0-t)^{n/2}} e^{\frac{|x|^2}{4(T_0-t)}} u(\frac{x}{T_0-t}, \frac{1}{T_0-t})
    \]
    is again a solution??? THis implIES the existence up to time $T_0$.
}


\exm{}{
    We want to show here that if we have no bound for the initial value problem for the heat equation, then the solution is not unique. For $n=1$ define 
    \[
    u(x,t)= \sum_{l=0}^\infty g_l (t) x^l
    \]
    then 
    \begin{align*}
       0= (\frac{\partial}{\partial t} - \frac{\partial^2}{ \partial x^2}) u(x,t) &= \sum_{l=0}^\infty \dot{g}_l (t) x^l - l(l-1)g_l (t) x^{l-2} \\
        &= \sum_{l=0}^\infty \dot{g}_l (t) x^l - \sum_{l=2}^\infty  l(l-1)g_l (t) x^{l-2} \\
        &= \sum_{l=0}^\infty (\dot{g}_l (t) - (l+2)(l+1)g_{l+2} (t) ) x^{l} 
    \end{align*}
    Then we have for all even $l \in \mathbb{N}$  that 
    \[
    \dot{g}_l (t) - (l+2)(l+1)g_{l+2} (t)=0 \quad \iff \quad g_{l+2} (t) = \frac{\dot{g}_l (t)}{(l+2) (l+1)} = \frac{\ddot{g}_{l-2} (t)}{(l+2) (l+1) l (l-1) } =...= \frac{{g}_0^{((l+2)/2)} (t)}{(l+2)!}
    \]
    Thus for all $l \in \mathbb{N}$ the relation holds 
    \[
    g_{2l} (t) = \frac{{g}_0^{(l)} (t)}{(2l)!}
    \]
    We choose now all $g_l$ with odd $l \in \mathbb{N}$ as zero and then get 
    \[
    u(x,t) =\sum_{l=0}^\infty g_{l} (t) x^{l}= \sum_{l=0}^\infty g_{2l} (t) x^{2l} = \sum_{l=0}^\infty \frac{ g^{(l)}(t) }{(2l)! } x^{2l}.
    \]
    Thus, we have shown that the solution can be written as a series of an arbitrary function $g_0 \in C^\infty$. If this series exists and converges to $0$ as $t \searrow 0$, then we have found another solutition. A specific example is: 
    \[
    g_0 (t) =: g(t) =: e^{-t^{-2}} \textbf{1}_{t >0},\quad u(x,t) = \sum_{l=0}^\infty \frac{g^{(l) } (t)}{(2l)!} x^{2l} =: \sum_{l=0}^\infty g_l (t) x^l.
    \]
    For $t>0$ it then holds 
    \begin{align*}
        & g^\prime (t) = \frac{2}{t^3} e^{-t^{-2}} = t^{-1} 2 t^{-2} e^{-t^{-2}} =: t^{-1} p_1 (t^{-2}) e^{-t^{-2}},\\
        &g^{\prime \prime} (t) = (-6) t^{-4} e^{-t^{-2}} + 2 t^{-3} 2t^{-3} e^{-t^{-2}} = \left( -6 t^{-4} + 4 t^{-6} \right) e^{-t^{-2}} = t^{-2} \underbrace{\left( -6 t^{-2} + 4 t^{-4} \right)}_{=: p_2 (t^{-2}) } e^{-t^{-2}} \\
        &\vdots\\
        &g^{(l)} (t) = t^{-l} p_l (t^{-2}) e^{-t^{-2}}
    \end{align*}
    where $p_l$ is of polynomial Degree $l$. Using the chain rule it then holds 
    \begin{align*}
       & g^{(l+1)} (t) = \frac{d}{dt} g^{(l)} (t) = - l t^{-(l+1)} p_l (t^{-2}) e^{-t^{-2}} - 2 t^{-(l+3)} p^\prime_l (t^{-2}) e^{-t^{-2}} + 2 t^{-(l+3)} p_l (t^{-2}) e^{-t^{-2}} \\
        &= t^{-(l+1)} e^{-t^{-2}} \left( (-l) p_l (t^{-2}) - 2 t^{-2} p_l^\prime (t^{-2}) + 2 t^{-2} p_l (t^{-2}) \right) \\
        &\iff t^{-l} p_l (t^{-2}) e^{-t^{-2}}=  t^{-(l+1)} e^{-t^{-2}} \left( (-l) p_l (t^{-2}) - 2 t^{-2} p_l^\prime (t^{-2}) + 2 t^{-2} p_l (t^{-2}) \right) \\
        &\iff p_{l+1} (t^{-2})= 2 t^{-2} p_l (t^{-2})  -l p_l (t^{-2}) - 2 t^{-2} p_l^\prime (t^{-2}) 
    \end{align*}
    For $z:= t^{-2}$ we have 
    \[
     p_{l+1} (z)= 2 z p_l (z)  -l p_l (z) - 2 z p_l^\prime (z) .
    \]
    We set $p_0(z)=1$ then with the above $p_1(z) = 2z$. Because $p_l$ is a polynomial we can write it as 
    \[
    p_l (z) = \sum_{k=0}^l a_{l,k} z^k 
    \]
    We now want to show that $|a_{l,k}| \leq \frac{l! z^l}{2^k k!}$ for all $l,k \in \mathbb{N}$. \\
    Induction start: $l=0,k=0$ is trivial\\
    Induction step: Note that 
    \begin{align*}
        &p_{l+1} (z) = 2 z p_l (z)  -l p_l (z) - 2 z \sum_{k=0}^{l} a_{l,k} k z^{k-1}  \\
        &=2  \sum_{k=0}^l a_{l,k} z^{k+1}   -l \sum_{k=0}^l a_{l,k} z^k  - 2  \sum_{k=0}^{l} a_{l,k} k z^{k} \\
        &=2  \sum_{k=0}^l a_{l,k} z^{k+1}   -l \sum_{k=0}^l a_{l,k} z^k  - 2  \sum_{k=0}^{l} a_{l,k} k z^{k} \\
        &=2  \sum_{k=1}^{l+1} a_{l,k-1} z^{k}   -l \sum_{k=0}^l a_{l,k} z^k  - 2  \sum_{k=0}^{l} a_{l,k} k z^{k} \\
        &= \sum_{k=1}^l z^k (2 a_{l,k-1} -la_{l,k} - 2ka_{l,k})  + 2 a_{l,l} z^{l+1} - l a_{l,0} - 2 a_{l,0} \cdot 0 \\
        &= \sum_{k=1}^l z^k (2 a_{l,k-1} -la_{l,k} - 2ka_{l,k})  + 2 a_{l,l} z^{l+1} - l a_{l,0} \\
        &= \sum_{k=0}^{l+1} z^k (2 a_{l,k-1} -la_{l,k} - 2ka_{l,k})
    \end{align*}
    This the yields with the induction hypothethis that 
    \begin{align*}
        |a_{l+1,k}| &\leq 2 |a_{l,k-1}| + l |a_{l,k}| + 2k|a_{l,k}| \\
        & \leq 2 \frac{l! 7^l}{2^{k-1} (k-1)!} + l \frac{l! 7^l}{2^{k} k!} + 2 k \frac{l! 7^l}{2^{k} k!} \\
        & \leq 2 \cdot 2k \frac{l! 7^l}{2^{k} k!} + l \frac{l! 7^l}{2^{k} k!} + 2 k \frac{l! 7^l}{2^{k} k!} \\
        & = \frac{(l+1)! 7^{l+1}}{2^{k} k!} \frac{2 \cdot 2k + l  + 2 k }{(l+1) 7} = \frac{(l+1)! 7^{l+1}}{2^{k} k!} \frac{  l  + 6 k }{(l+1) 7} 
    \end{align*}
    Since $k \leq k+1$ it follows 
    \[
    |a_{l+1,k}| \leq \frac{(l+1)! 7^{l+1}}{2^{k} k!} \frac{  l  + 6 (l+1) }{(l+1) 7}  \leq \frac{(l+1)! 7^{l+1}}{2^{k} k!} \frac{  7l + 7 }{(l+1) 7} =  \frac{(l+1)! 7^{l+1}}{2^{k} k!} .
    \]
    We can use this bound and the fact that $\frac{l!}{(2l)!} \leq \frac{1}{2^l l!}$ to find a bound for $u$:
    \begin{align*}
        |u(x,t)| &\leq \sum_{l=0}^\infty \left| \frac{t^{-l} p_l (t^{-2}) e^{-t^{-2}} }{(2l)!} x^{2l} \right| \leq \sum_{l=0}^\infty  \frac{t^{-l}  e^{-t^{-2}} }{(2l)!} |x^{2l}|  \sum_{k=0}^l |a_{l,k} | t^{-2k} \\
        & \leq \sum_{l=0}^\infty  \frac{t^{-l}  e^{-t^{-2}} }{(2l)!} |x^{2l}|  \sum_{k=0}^l \frac{l!7^l}{2^k k!} t^{-2k} \\
        & \leq \sum_{l=0}^\infty  \frac{t^{-l}  e^{-t^{-2}} }{2^l l!} |x^{2l}|  \sum_{k=0}^l \frac{7^l}{2^k k!} t^{-2k} \\
        & \leq \sum_{l=0}^\infty \frac{1}{l!} \left( \frac{7|x|^2}{2t} \right)^l    e^{-t^{-2}}   \sum_{k=0}^\infty \frac{1}{k!}  \left( \frac{1}{2t^2} \right)^k \\
        & =  e^{-t^{-2}} e^{\frac{7|x|^2}{2t}+ \frac{1}{2t^2}} =  e^{\frac{7|x|^2}{2t}- \frac{1}{2t^2}}
    \end{align*}
    For every $t>0$ this series is finitely bounded and thus absolutely convergent. Further, as $t \searrow 0$ it follows that on every compact subset $K \subset \mathbb{R}$ this series converges to zero, because 
    \[
    0 \leq |u(x,t)| \leq e^{\frac{7|x|^2}{2t}- \frac{1}{2t^2}} \leq e^{\frac{7 \sup_{x \in K} |x|^2 }{2t} - \frac{1}{2t^2} } \to 0.
    \] 
    In the theorem of the uniqueness of the solution we required that $|u(x,t)|$ be bounded independent of $t$ on $\mathbb{R}\times [0,T_0]$. However, our bound depends on time. Assume that there exists $a,C \in \mathbb{R}$ such that 
    \[
    e^{\frac{7|x|^2}{2t}- \frac{1}{2t^2}}  \leq e^{\frac{7|x|^2}{2t}}  \leq e^{ax^2+C}.
    \]
    This would imply that $\frac{7}{2t} \leq a $. But as $t \searrow 0$ $\frac{7}{2t} \to \infty$, which is a contradiction. Thus, we have found another solution of the heat equation that does not satify these upper bound conditions.\\
    This example show that we found a solution that is zero on $\mathbb{R}$ at $t=0$ and then as soon as $t>0$ there is infinite heat at $+\infty$ and $-\infty$ that propagate into the center at infinite speed and result in a value of the solution at time $t>0$ and point $x \in \mathbb{R}$ of $u(x,t) = \sum_{l=0}^\infty \frac{g^{(l) } (t)}{(2l)!} x^{2l} $.
}

An alternative to using the maximum principle is using the yet to be defined Energy functional. There we cannot use an unbounded domain $\mathbb{R}$ but instead have to focus on a bounded domain $\Omega /subset \mathbb{R}$. The energy function is given by 
\[
e(t) := \int_\Omega u^2 (x,t) d^n x.
\]
Now using $\dot{u}= \Delta u$ it follows 
\begin{align*}
\dot{e}(t) &= \int_\Omega \frac{d}{dt} u^2 (x,t) d^n x = 2 \int_\Omega u(x,t) \dot{u}(x,t) d^n x= 2 \int_\Omega u(x,t) \Delta u(x,t) d^n x \\
&=-  2 \underbrace{\int_\Omega (\nabla u(x,t) )^2  d^n x }_{\geq 0} \leq 0.
\end{align*}
This implies that $e(\cdot)$ is monotonically decreasing. To show uniqueness of the solution, take two solutions $u_1,u_2$ from the heat eqaution and define their difference $w:= u_1-u_2$. Then $w$ is zero at $t=0$. Further, 
\[
\int_\Omega w^2 (x,0) d^n x =0
\]
and the fact that $e(\cdot)$ is monotonically decreasing it follows that 
\[
\forall t >0: \int_\Omega w^2 (x,t) d^n x =0
\]
which itself implies that $w(x,t)=0$ for all $(x,t) \in \Omega \times [0,T]$.


\section{Heat Kernel}
In analogy to Greens functions for the Laplace equation we define on open subsets $\Omega \subset \mathbb{R}^n$ the heat kernel $H_\Omega$:
\defn{}{
    For all $\Omega \subset \mathbb{R}^n$ open domain the heat kernel $H_\Omega: \Omega \times \Omega \times \mathbb{R}^+ \to \mathbb{R}$ of $\Omega$ is characterized by the two properties 
    \begin{itemize}
        \item For $(x,t) \in \Omega \times \mathbb{R}^+$ the function $y \mapsto H_\Omega (x,y,t)$ extends continuously to $\bar{\Omega}$ with value $0$ on $\partial \Omega$.
        \item For $x \in \Omega$ the function $(y,t) \mapsto H_\Omega (x,y,t) - \Phi (x-y,t)$ solves the homogeneuous heat equation and extends continuously to $\bar{\Omega} \times \mathbb{R}^+_0$ with value $0$ on $\bar{\Omega} \times \{0\}$.
    \end{itemize}

}

\lem{}{
    If $u,v$ are two functions on $\Omega \times \mathbb{R}^+$ with an open domain $\Omega \subset \mathbb{R}^n$, then under sufficient regularity we have 
    \begin{align*}
        &\qquad \int_0^T \int_\Omega u(x,t) \left( \dot{v}(x,T-t) + \Delta v(x,T-t) \right) d^n x dt + \int_0^T \int_\Omega \left( \dot{u}(x,t) - \Delta u(x,t) \right) v(x,T-t) d^n x dt \\
        &= \int_0^T \int_{\partial \Omega } \left( u(y,t) \nabla v(y,T-t) - \nabla u (y,t) v(y,T-t) \right) \cdot N d \sigma (y) dt + \int_\Omega u(x,T) v(x,0) - u(x,0) v(x,T) d^n x
    \end{align*}
}

\pf{
    \begin{align*}
        &\int_0^T \int_\Omega u(x,t) \left( \dot{v}(x,T-t) + \Delta v(x,T-t) \right) d^n x dt + \int_0^T \int_\Omega \left( \dot{u}(x,t) - \Delta u(x,t) \right) v(x,T-t) d^n x dt \\
       &=\int_0^T \int_\Omega u(x,t)  \dot{v}(x,T-t) +\dot{u}(x,t) v(x,T-t)   d^n x dt + \int_0^T \int_\Omega  u(x,t) \Delta v(x,T-t) - \Delta u(x,t)  v(x,T-t) d^n x dt \\
       &=\int_0^T \int_\Omega  \frac{d}{dt} (v(x,T-t) u(x,t) )   d^n x dt + \int_0^T \int_\Omega \nabla( u(x,t) \nabla v(x,T-t) )- \nabla (\nabla u(x,t)  v(x,T-t) )d^n x dt \\
       &=\int_\Omega  v(x,0) u(x,T)- v(x,T) u(x,0)    d^n x + \int_0^T \int_\Omega \big(  u(y,t) \nabla v(y,T-t) - \nabla u(y,t)  v(y,T-t) \big) \cdot N \; d \sigma (y)  dt 
    \end{align*}
}
Because $\Phi$ has a singularity at $(0,0)$ and $(y,t) \mapsto H_\Omega (x,y,t)- \Phi (x-y,t)$ is zero on $ \bar{\Omega} \times \{0\}$ it must follow that $H_\Omega (x,y,t)$ has a singularity at $(x,x,0)$.\\
This is why we only integrate on $[0,T-\epsilon]$ and then take the limit $\epsilon \to 0$. We then get with the above 
\begin{align*}
    &\int_0^T \int_\Omega \left( \dot{u}(y,t) - \Delta u(y,t) \right) H_\Omega (x,y,T-t) d^n y dt \\
    &= \int_0^T \int_{\partial \Omega} \left( u(y,t) \nabla_y H_\Omega (x,y,T-t) - \nabla_y u(y,t) H_\Omega (x,y,T-t) \right) \cdot N d \sigma (y) dt \\
    &+ \int_\Omega u(y,T) H_\Omega (x,y,0) - u(y,0) H_\Omega (x,y,T) d^n y \\
   & - \int_0^T \int_\Omega u(y,t) \left( \partial H_\Omega (x,y,T-t) + \Delta H_\Omega (x,y,T-t) \right) d^n y dt \\
    &= \int_0^T \int_{\partial \Omega}  u(y,t) \nabla_y H_\Omega (x,y,T-t)  \cdot N d \sigma (y) dt \\
    &+ \int_\Omega u(y,T) H_\Omega (x,y,0) d^n y - u(y,0)  H_\Omega (x,y,T) d^n y \\
    &= \int_0^T \int_{\partial \Omega}  u(y,t) \nabla_y H_\Omega (x,y,T-t)  \cdot N d \sigma (y) dt +  u(x,T) -\int_\Omega u(y,0) H_\Omega (x,y,T) d^n y \\
\end{align*}

Although we used that 
\begin{align*}
    &\int_\Omega u(y,T) H_\Omega (x,y,0) d^n y = \int_\Omega u(y,T) \lim_{t \searrow 0} H_\Omega (x,y,t) d^n y\\
    &=\int_\Omega u(y,T) \lim_{t \searrow 0} \Phi (x-y,t) d^n y= \lim_{t \searrow 0} \int_\Omega u(y,T)  \Phi (x-y,t) d^n y \\
    &= \lim_{t \searrow 0} (u(\cdot,T) *  \Phi (\cdot,t))(x) = u(x,T).
\end{align*}
Thus, it holds 
\begin{align*}
    u(x,T)= &\int_0^T \int_\Omega \left( \dot{u}(y,t) - \Delta u(y,t) \right) H_\Omega (x,y,T-t) d^n y dt +\int_\Omega u(y,0) H_\Omega (x,y,T) d^n y \\
    &-\int_0^T \int_{\partial \Omega}  u(y,t) \nabla_y H_\Omega (x,y,T-t)  \cdot N d \sigma (y) dt 
\end{align*}

\lem{}{
    For all $T>0$ and $x,y \in \bar{\Omega}$: $H_\Omega (x,y,T) = H_\Omega (y,x,T)$
}
\pf{
    \begin{align*}
        &H_\Omega(x,y,T) - H_\Omega(y,x,T) = \lim_{ t\searrow 0} (H_\Omega (x,\cdot,T) * \Phi (\cdot,t) )(y) -  \lim_{ t\searrow 0} (H_\Omega (y,\cdot,T) * \Phi (\cdot,t) )(x) \\
        &= \int_\Omega H_\Omega (x,z,T) \lim_{ t\searrow 0} \Phi (y-z,t) d^n z - \int_\Omega H_\Omega (y,z,T) \lim_{ t\searrow 0} \Phi (x-z,t) d^n z \\
        &= \int_\Omega H_\Omega (x,z,T) \lim_{ t\searrow 0} H_\Omega (y,z,t) d^n z - \int_\Omega H_\Omega (y,z,T) \lim_{ t\searrow 0} H_\Omega (x,z,t) d^n z \\
        &= \int_\Omega H_\Omega (x,z,T)  H_\Omega (y,z,0) d^n z - \int_\Omega H_\Omega (y,z,T)  H_\Omega (x,z,0) d^n z \\
       &= \int_0^T \int_\Omega H_\Omega (y,z,t) \left( \dot{H_\Omega }(x,z,T-t) + \Delta H_\Omega (x,z,T-t) \right) d^n z dt \\
       & + \int_0^T \int_\Omega \left( \dot{H_\Omega }(y,z,t) - \Delta H_\Omega (y,z,t) \right) H_\Omega (x,z,T-t) d^n z dt \\
        &- \int_0^T \int_{\partial \Omega } \left( H_\Omega (y,z,t) \nabla H_\Omega (x,z,T-t) - \nabla H_\Omega  (y,z,t) H_\Omega (x,z,T-t) \right) \cdot N d \sigma (z) dt \\
        &=0
    \end{align*}
}


\thm{}{
    Consider the initial value problem 
    \[
    \dot{u} - \Delta u=f \text{ on } \Omega \times (0,T),\quad u=g \text{ on } \partial \Omega \times [0,T],\quad u(x,0)=h(x) \text{ on } \Omega,
    \]
    where $f$ is on $\Omega \times (0,T)$, $g$ on $\partial \Omega \times [0,T]$ and $h$ on $\Omega$ all have appropiate regularity, then the unique solution is given by 
    \begin{align*}
        u(x,T) &= \int_0^T \int_\Omega f(y,t) H_\Omega (x,y,T-t) d^n y dt - \int_0^T \int_{\partial \Omega} g(z,t) \nabla_z H_\Omega (x,z,T-t) N d \sigma (z) dt\\
        &+ \int_\Omega h(y) H_\Omega (x,y,T) d^n y.
    \end{align*}
}
\pf{
    Because $(\partial_t - \Delta)(\cdot) $ is a linear operator, we can split the full problem into three simpler subproblems $u= u_f + u_h+u_g$ where 
    \begin{itemize}
        \item $u_f$ solves $\dot{u} - \Delta u=f$, $u(x,0)=0$ and $u=0$ on $\partial \Omega \times [0,T]$
        \item $u_h$ solves $\dot{u} - \Delta u=0$, $u(x,0)=h(x)$ and $u=0$ on $\partial \Omega \times [0,T]$
         \item $u_g$ solves $\dot{u} - \Delta u=0$, $u(x,0)=0$ and $u(x,t)=g(x,t)$ on $\partial \Omega \times [0,T]$.
    \end{itemize}
    This is is possible, because $(\partial_t - \Delta)(u_f + u_h+u_g)= f+0+0=f(x)$, $(u_f + u_h+u_g)(x,0)= 0+h(x)+0=h(x)$ and $(u_f + u_h+u_g)(x,t)=0+0+g(x)= g(x)$ on $\partial \Omega \times [0,T]$.\\
    Remembering that we have shown that 
    \begin{align*}
    u(x,T)= &\int_0^T \int_\Omega \left( \dot{u}(y,t) - \Delta u(y,t) \right) H_\Omega (x,y,T-t) d^n y dt +\int_\Omega u(y,0) H_\Omega (x,y,T) d^n y \\
    &-\int_0^T \int_{\partial \Omega}  u(y,t) \nabla_y H_\Omega (x,y,T-t)  \cdot N d \sigma (y) dt ,
\end{align*}
we can plug in for the the three solutions in the above 
\begin{align*}
    & u_f (x,T) = \int_0^T \int_\Omega f(y,t) H_\Omega (x,y,T-t) d^n y dt \\
    & u_h (x,T) = \int_\Omega h(y) H_\Omega (x,y,T) d^n y \\
    & u_g (x,T) = - \int_0^T \int_{\partial \Omega }g(y) \nabla_y H_\Omega (x,y,T-t) \cdot N d \sigma (y) dt.
\end{align*}
Thus, $u= u_f+u_h+u_g$ yields the form of the theorem.
}
The appropiate regularity condition depend on the heat kernel and thus also on the domain???
\lem{}{
    For all $\Omega \subset \mathbb{R}^n$ bounded connected open domain the corresponding heat kernel $H_\Omega$ is positive on the corresponding parabolic cyclinder, if it exists.
}
\pf{
    Define $w(x,t):= \Phi (x-y,t) - H_\Omega(x,y,t)$ on $\bar{\Omega} \times (0,T]$. Both summands solve the heat equation on $\Omega \times (0,T]$ and satisfy the weak maximum princple, i.e. the maximum is taken on the parabolic boundary. This is why we want to consider the difference on the parabolic boundary $\partial (\Omega \times (0,T])= (\partial \Omega \times [0,T])\cup (\bar{\Omega}\times \{0\})$.
    \begin{itemize}
        \item For $(x,t) \in \partial \Omega \times [0,T]:$ We have $w(x,t) = \Phi (x-y,t)-0$, because by definition $H_\Omega$ is on this set zero.
        \item For $\bar{\Omega}\times \{0\}$, it is by definition equal to zero, as $ t \searrow 0$.
    \end{itemize}
    $ w- \Phi$ is again a solution and with the above satisfies on $\partial (\Omega \times (0,T])$ that $w- \Phi \leq 0$. Thus, for $x \neq y$
    \[
    w (x,t) - \Phi (x-y,t) \leq \max_{x \in \partial (\Omega \times (0,T])} (w(x,t) - \Phi (x-y,t)) = 0 \quad \Rightarrow \quad \forall (x,t) \in \Omega \times (0,T]: \quad  w(x,t) \leq \Phi (x-y,t) 
    \]
    which is equivalent to $H_\Omega (x,y,t) \geq 0$.
}


\end{document}
